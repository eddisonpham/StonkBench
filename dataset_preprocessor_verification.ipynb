{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ” Dataset Preprocessor Verification\n",
        "\n",
        "This notebook verifies that the modified preprocessing pipeline with PyTorch Dataset support creates the correct data structures and handles batching properly with seed support.\n",
        "\n",
        "## Key Features to Verify:\n",
        "- âœ… Time series data shape `(R, l, N)` where R=sequences, l=length, N=variables\n",
        "- âœ… Seed-based reproducible shuffling\n",
        "- âœ… Proper PyTorch Dataset implementation\n",
        "- âœ… Efficient DataLoader batching\n",
        "- âœ… Dynamic seed changing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\tslearn\\bases\\bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
            "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
            "  warn(h5py_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Add the project root to the path\n",
        "sys.path.append(str(Path.cwd()))\n",
        "\n",
        "from data.preprocess import (\n",
        "    preprocess_data, \n",
        "    load_preprocessed_data,\n",
        "    create_dataset_from_preprocessed,\n",
        "    TimeSeriesDataset,\n",
        "    create_dataloaders\n",
        ")\n",
        "\n",
        "print(\"ğŸ“¦ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Basic Preprocessing with Seed Support\n",
        "\n",
        "Let's preprocess the GOOG stock data and verify the output shapes and properties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "EXAMPLE 1: Basic Preprocessing with Seed Support\n",
            "============================================================\n",
            "Configuration: {'original_data_path': 'data/GOOG/GOOG.csv', 'output_ori_path': './preprocessed/', 'dataset_name': 'goog_stock_long', 'seq_length': 125, 'valid_ratio': 0.1, 'do_normalization': True, 'seed': 42}\n",
            "\n",
            "ğŸ”„ Starting preprocessing...\n",
            "====================\n",
            "Data preprocessing with settings:{'original_data_path': 'data/GOOG/GOOG.csv', 'output_ori_path': './preprocessed/', 'dataset_name': 'goog_stock_long', 'seq_length': 125, 'valid_ratio': 0.1, 'do_normalization': True, 'seed': 42}\n",
            "Data shape: (1132, 125, 5)\n",
            "Preprocessing done. Preprocessed files saved to ./preprocessed/goog_stock_long.\n",
            "====================\n",
            "\n",
            "\n",
            "âœ… Preprocessing successful!\n",
            "ğŸ“Š Data shapes:\n",
            "  Train shape: (1018, 125, 5) (R_train, l, N)\n",
            "  Valid shape: (114, 125, 5) (R_valid, l, N)\n",
            "  Sequence length (l): 125\n",
            "  Number of variables (N): 5\n",
            "  Total sequences (R): 1132\n",
            "\n",
            "ğŸ“ˆ Data statistics:\n",
            "  Train data range: [0.0000, 1.0000]\n",
            "  Valid data range: [-0.0265, 1.2043]\n",
            "  Train data mean: 0.3676\n",
            "  Valid data mean: 0.3695\n",
            "  âœ… Normalization successful: data in range [0, 1]\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"EXAMPLE 1: Basic Preprocessing with Seed Support\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Configuration for preprocessing\n",
        "config = {\n",
        "    'original_data_path': 'data/GOOG/GOOG.csv',\n",
        "    'output_ori_path': './preprocessed/',\n",
        "    'dataset_name': 'goog_stock_long',\n",
        "    'seq_length': 125,\n",
        "    'valid_ratio': 0.1,\n",
        "    'do_normalization': True,\n",
        "    'seed': 42  # Reproducible shuffling\n",
        "}\n",
        "\n",
        "print(f\"Configuration: {config}\")\n",
        "print(\"\\nğŸ”„ Starting preprocessing...\")\n",
        "\n",
        "# Preprocess the data\n",
        "train_data, valid_data = preprocess_data(config)\n",
        "\n",
        "if train_data is not None and valid_data is not None:\n",
        "    print(f\"\\nâœ… Preprocessing successful!\")\n",
        "    print(f\"ğŸ“Š Data shapes:\")\n",
        "    print(f\"  Train shape: {train_data.shape} (R_train, l, N)\")\n",
        "    print(f\"  Valid shape: {valid_data.shape} (R_valid, l, N)\")\n",
        "    print(f\"  Sequence length (l): {train_data.shape[1]}\")\n",
        "    print(f\"  Number of variables (N): {train_data.shape[2]}\")\n",
        "    print(f\"  Total sequences (R): {train_data.shape[0] + valid_data.shape[0]}\")\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ Data statistics:\")\n",
        "    print(f\"  Train data range: [{train_data.min():.4f}, {train_data.max():.4f}]\")\n",
        "    print(f\"  Valid data range: [{valid_data.min():.4f}, {valid_data.max():.4f}]\")\n",
        "    print(f\"  Train data mean: {train_data.mean():.4f}\")\n",
        "    print(f\"  Valid data mean: {valid_data.mean():.4f}\")\n",
        "    \n",
        "    # Verify normalization (should be in range [0, 1])\n",
        "    if train_data.min() >= 0 and train_data.max() <= 1:\n",
        "        print(f\"  âœ… Normalization successful: data in range [0, 1]\")\n",
        "    else:\n",
        "        print(f\"  âŒ Normalization issue: data outside [0, 1] range\")\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ Preprocessing failed!\")\n",
        "    train_data, valid_data = None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.47557037, 0.47165297, 0.47788017, 0.46474319, 0.17043306],\n",
              "        [0.48311123, 0.46869546, 0.47961651, 0.47177834, 0.09925507],\n",
              "        [0.48554872, 0.48377848, 0.4852786 , 0.48765914, 0.11875418],\n",
              "        ...,\n",
              "        [0.497312  , 0.49946982, 0.50381775, 0.5124269 , 0.13112273],\n",
              "        [0.47778405, 0.49603285, 0.4881448 , 0.50893736, 0.14110308],\n",
              "        [0.50853663, 0.50626576, 0.51454327, 0.5063988 , 0.13100184]],\n",
              "\n",
              "       [[0.70811699, 0.70506906, 0.70285367, 0.68793972, 0.20236996],\n",
              "        [0.71184935, 0.70299886, 0.7088178 , 0.70934109, 0.11244571],\n",
              "        [0.73371007, 0.71275847, 0.70345764, 0.71253679, 0.17537653],\n",
              "        ...,\n",
              "        [0.46718258, 0.46241755, 0.47315681, 0.47842256, 0.06544322],\n",
              "        [0.47491751, 0.47516889, 0.4850016 , 0.48617178, 0.08524785],\n",
              "        [0.50262891, 0.49347529, 0.48701452, 0.48512853, 0.15439812]],\n",
              "\n",
              "       [[0.24319135, 0.24470398, 0.24468707, 0.24561606, 0.3416926 ],\n",
              "        [0.25011139, 0.26252666, 0.25432582, 0.26380721, 0.25803396],\n",
              "        [0.27858368, 0.29145594, 0.28499171, 0.29536621, 0.25403346],\n",
              "        ...,\n",
              "        [0.0689431 , 0.07616636, 0.08142449, 0.08861209, 0.16495327],\n",
              "        [0.08028785, 0.07411108, 0.07881722, 0.0833188 , 0.1995861 ],\n",
              "        [0.07118802, 0.07054184, 0.07010013, 0.05551607, 0.13064355]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.71184935, 0.70299886, 0.7088178 , 0.70934109, 0.11244571],\n",
              "        [0.73371007, 0.71275847, 0.70345764, 0.71326591, 0.17537653],\n",
              "        [0.73127269, 0.71312806, 0.72542656, 0.71877305, 0.09163875],\n",
              "        ...,\n",
              "        [0.47176112, 0.47626056, 0.48783106, 0.4929453 , 0.08524785],\n",
              "        [0.50599183, 0.49401114, 0.48832271, 0.49403199, 0.15439812],\n",
              "        [0.4955101 , 0.50085305, 0.50407882, 0.5017182 , 0.24295628]],\n",
              "\n",
              "       [[0.22954171, 0.23011121, 0.23635061, 0.22639556, 0.22574427],\n",
              "        [0.21354988, 0.22663254, 0.21365693, 0.22860972, 0.29166447],\n",
              "        [0.21995574, 0.23357143, 0.22728749, 0.23567227, 0.19954324],\n",
              "        ...,\n",
              "        [0.31009629, 0.30890959, 0.31445812, 0.3272094 , 0.12342398],\n",
              "        [0.31330693, 0.306603  , 0.31632157, 0.31330717, 0.15894484],\n",
              "        [0.30487087, 0.30337118, 0.31239452, 0.2968954 , 0.08928791]],\n",
              "\n",
              "       [[0.10523248, 0.11768403, 0.1146761 , 0.12054384, 0.12606936],\n",
              "        [0.10778416, 0.11372848, 0.11497808, 0.11891471, 0.1360662 ],\n",
              "        [0.12656007, 0.13383909, 0.13000147, 0.12387565, 0.15308148],\n",
              "        ...,\n",
              "        [0.1909966 , 0.19642433, 0.19959441, 0.20969362, 0.2243342 ],\n",
              "        [0.19298818, 0.2040552 , 0.20252881, 0.21886464, 0.14225157],\n",
              "        [0.20428898, 0.2010943 , 0.21006256, 0.19877949, 0.12867188]]],\n",
              "      shape=(1018, 125, 5))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: PyTorch Dataset and DataLoader Creation\n",
        "\n",
        "Now let's create PyTorch datasets and dataloaders to verify proper batching and seed support.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXAMPLE 2: PyTorch Dataset and DataLoader Creation\n",
            "============================================================\n",
            "ğŸ”§ Creating TimeSeriesDataset objects...\n",
            "âœ… Created datasets:\n",
            "  Train dataset length: 1018\n",
            "  Valid dataset length: 114\n",
            "  Sample shape: torch.Size([125, 5])\n",
            "  Sample dtype: torch.float32\n",
            "  âœ… Sample is PyTorch tensor: <class 'torch.Tensor'>\n",
            "\n",
            "ğŸ”§ Creating DataLoaders...\n",
            "âœ… Created dataloaders:\n",
            "  Train batches: 31\n",
            "  Valid batches: 4\n",
            "  Batch size: 32\n",
            "\n",
            "ğŸ“Š Batch Information:\n",
            "  Batch 1: shape torch.Size([32, 125, 5]), dtype torch.float32\n",
            "    Range: [0.0000, 1.0000]\n",
            "  Batch 2: shape torch.Size([32, 125, 5]), dtype torch.float32\n",
            "    Range: [0.0000, 1.0000]\n",
            "  Batch 3: shape torch.Size([32, 125, 5]), dtype torch.float32\n",
            "    Range: [0.0000, 1.0000]\n",
            "    ... and 28 more batches\n",
            "\n",
            "âœ… Batch shapes are correct: torch.Size([32, 125, 5]) == (32, 125, 5)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXAMPLE 2: PyTorch Dataset and DataLoader Creation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if train_data is None or valid_data is None:\n",
        "    print(\"âŒ Cannot proceed - no preprocessed data available\")\n",
        "else:\n",
        "    # Create datasets with different seeds for reproducible shuffling\n",
        "    print(\"ğŸ”§ Creating TimeSeriesDataset objects...\")\n",
        "    train_dataset = TimeSeriesDataset(train_data, seed=42)\n",
        "    valid_dataset = TimeSeriesDataset(valid_data, seed=123)\n",
        "    \n",
        "    print(f\"âœ… Created datasets:\")\n",
        "    print(f\"  Train dataset length: {len(train_dataset)}\")\n",
        "    print(f\"  Valid dataset length: {len(valid_dataset)}\")\n",
        "    print(f\"  Sample shape: {train_dataset[0].shape}\")\n",
        "    print(f\"  Sample dtype: {train_dataset[0].dtype}\")\n",
        "    \n",
        "    # Verify the sample is a PyTorch tensor\n",
        "    sample = train_dataset[0]\n",
        "    if isinstance(sample, torch.Tensor):\n",
        "        print(f\"  âœ… Sample is PyTorch tensor: {type(sample)}\")\n",
        "    else:\n",
        "        print(f\"  âŒ Sample is not PyTorch tensor: {type(sample)}\")\n",
        "    \n",
        "    # Create dataloaders\n",
        "    print(f\"\\nğŸ”§ Creating DataLoaders...\")\n",
        "    batch_size = 32\n",
        "    train_loader, valid_loader = create_dataloaders(\n",
        "        train_data, valid_data,\n",
        "        batch_size=batch_size,\n",
        "        train_seed=42,\n",
        "        valid_seed=123,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    \n",
        "    print(f\"âœ… Created dataloaders:\")\n",
        "    print(f\"  Train batches: {len(train_loader)}\")\n",
        "    print(f\"  Valid batches: {len(valid_loader)}\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    \n",
        "    # Demonstrate batching\n",
        "    print(f\"\\nğŸ“Š Batch Information:\")\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        print(f\"  Batch {i+1}: shape {batch.shape}, dtype {batch.dtype}\")\n",
        "        print(f\"    Range: [{batch.min():.4f}, {batch.max():.4f}]\")\n",
        "        if i >= 2:  # Show only first 3 batches\n",
        "            print(f\"    ... and {len(train_loader) - 3} more batches\")\n",
        "            break\n",
        "    \n",
        "    # Verify batch shapes are correct\n",
        "    first_batch = next(iter(train_loader))\n",
        "    expected_shape = (batch_size, train_data.shape[1], train_data.shape[2])\n",
        "    if first_batch.shape == expected_shape:\n",
        "        print(f\"\\nâœ… Batch shapes are correct: {first_batch.shape} == {expected_shape}\")\n",
        "    else:\n",
        "        print(f\"\\nâŒ Batch shape mismatch: {first_batch.shape} != {expected_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Reproducible Training with Seed Control\n",
        "\n",
        "Let's verify that seeds produce reproducible and different shuffling patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXAMPLE 3: Reproducible Training with Seed Control\n",
            "============================================================\n",
            "ğŸ”„ Testing reproducibility with same seeds...\n",
            "âœ… Datasets with same seed produce identical order: True\n",
            "  First 10 indices (dataset1): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "  First 10 indices (dataset2): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "\n",
            "ğŸ”„ Testing different seeds produce different orders...\n",
            "âœ… Datasets with different seeds produce different order: True\n",
            "  First 10 indices (seed=42): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "  First 10 indices (seed=123): [936, 244, 526, 469, 573, 712, 847, 257, 635, 672]\n",
            "\n",
            "ğŸ”„ Testing dynamic seed changing...\n",
            "âœ… Seed change produces different order: True\n",
            "  Original (seed=42): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "  New (seed=999):     [700, 859, 964, 373, 390, 946, 156, 416, 352, 107]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXAMPLE 3: Reproducible Training with Seed Control\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if train_data is None:\n",
        "    print(\"âŒ Cannot proceed - no preprocessed data available\")\n",
        "else:\n",
        "    # Test reproducibility with same seeds\n",
        "    print(\"ğŸ”„ Testing reproducibility with same seeds...\")\n",
        "    dataset1 = TimeSeriesDataset(train_data, seed=42)\n",
        "    dataset2 = TimeSeriesDataset(train_data, seed=42)\n",
        "    \n",
        "    # Check if the order is identical\n",
        "    indices1 = dataset1.get_original_indices()\n",
        "    indices2 = dataset2.get_original_indices()\n",
        "    \n",
        "    print(f\"âœ… Datasets with same seed produce identical order: {indices1[:10] == indices2[:10]}\")\n",
        "    print(f\"  First 10 indices (dataset1): {indices1[:10]}\")\n",
        "    print(f\"  First 10 indices (dataset2): {indices2[:10]}\")\n",
        "    \n",
        "    # Test different seeds produce different orders\n",
        "    print(f\"\\nğŸ”„ Testing different seeds produce different orders...\")\n",
        "    dataset3 = TimeSeriesDataset(train_data, seed=123)\n",
        "    indices3 = dataset3.get_original_indices()\n",
        "    \n",
        "    print(f\"âœ… Datasets with different seeds produce different order: {indices1[:10] != indices3[:10]}\")\n",
        "    print(f\"  First 10 indices (seed=42): {indices1[:10]}\")\n",
        "    print(f\"  First 10 indices (seed=123): {indices3[:10]}\")\n",
        "    \n",
        "    # Test dynamic seed changing\n",
        "    print(f\"\\nğŸ”„ Testing dynamic seed changing...\")\n",
        "    original_indices = dataset1.get_original_indices()[:10]\n",
        "    dataset1.set_seed(999)\n",
        "    new_indices = dataset1.get_original_indices()[:10]\n",
        "    \n",
        "    print(f\"âœ… Seed change produces different order: {original_indices != new_indices}\")\n",
        "    print(f\"  Original (seed=42): {original_indices}\")\n",
        "    print(f\"  New (seed=999):     {new_indices}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
