
\documentclass[sigconf]{acmart}
\usepackage{enumitem}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

% \setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
% \acmDOI{XXXXXXX.XXXXXXX}
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation email}{June 03--05,
%   2018}{Woodstock, NY}
% \acmISBN{978-1-4503-XXXX-X/2018/06}



\begin{document}


\title{Stonk Bench: Unified Benchmark for Synthetic Data Generation for Financial Time Series}



\author{Uyen Lam Ho}
\authornote{Both authors contributed equally to this research.}
\email{uyenlam.ho@mail.utoronto.ca}
\author{Eddison Pham}
\authornotemark[1]
\email{eddison.pham@mail.utoronto.ca}
\affiliation{%
  \institution{University of Toronto}
  \city{Toronto}
  \state{Ontario}
  \country{Canda}
}



\renewcommand{\shortauthors}{Ho and Pham}

\begin{abstract}
  The ever emerging field of Synthetic Data Generation (SDG) has gain traction 
  within many financial domains, including Finacial Time Series (FTS) data. 
  However, there has been discorse and lack in universal agreement in what determines a better SDGFTS 
  (Synthetic Data Generation for Financial Time Series), which maybe hindering progress 
  in the field. 
  In this paper, we propose and contribute a comprehensive benchmark for SDGFTS, 
  covering various aspects such as data quality, privacy, and utility. 
  We evaluate several state-of-the-art SDG methods using our benchmark and 
  provide insights into their strengths and weaknesses. 
  Our first-of-its-kind benchmark aims to facilitate the development of more effective SDG 
  methods for FTS data, incorperating both classical statistical measures
  and utility benefits, and test over (insert number) to decicively determine what is the 
  best SDGFTS model right now and for the future.
\end{abstract}



\keywords{
    Synthetic Data Generation, 
    Financial Time Series,
    Benchmarking
}
\begin{teaserfigure}
  \centering
  \includegraphics[width=\textwidth,height=5.5cm,keepaspectratio,trim=0 150 0 150,clip]{tse-1981.png}
  \caption{Toronto Stock Exchange, Toronto, 1981}
  \Description{A panoramic view of the Toronto Stock Exchange building in 1981.}
  \label{fig:teaser}
\end{teaserfigure}


\maketitle

\section{Introduction}
  Synthetic Data Generation (SDG) has emerged as a crucial tool in financial technology, 
  particularly for Financial Time Series (FTS) data \cite{Potluru24}. The ability to generate high-quality 
  synthetic financial data addresses several critical challenges in the field, 
  including data privacy concerns, limited data availability, and the need for diverse training 
  datasets in machine learning applications \cite{Stenger24}.

  Despite the growing importance of SDGFTS (Synthetic Data Generation for 
  Financial Time Series), there is a notable lack of standardization in evaluating 
  the quality and effectiveness of these generative models \cite{Stenger24}. Current evaluation methods 
  vary widely across studies, making it difficult to compare different approaches objectively 
  and determine their relative strengths and weaknesses.

  Our research addresses this gap by introducing a comprehensive benchmark framework that 
  encompasses:
  \begin{itemize}
      \item Statistical fidelity measures for comparing synthetic and real FTS
      \item Privacy preservation metrics to ensure sensitive financial information 
      remains protected
      \item Utility metrics that assess the practical value of synthetic data in 
      downstream tasks
      \item Performance evaluation across multiple SDGFTS models and datasets
  \end{itemize}

  By analyzing the results from our MLflow experiments and applying our unified benchmark, 
  we aim to provide clear guidelines for evaluating SDGFTS models and establish a standard 
  for future research in this domain.

  \subsection{Limitations in the SDGFTS Literature}
    Among other things, we observed that there is currently no universal, generally accepted approach 
    to evaluating synthetic time series\cite{Stenger24}; this issue extends beyond FTS to generative 
    frameworks like GANs as a whole \cite{Wang20}. 
    Many evaluation measures are insufficiently defined and lack public implementations, making reuse 
    and reproduction troublesome and error-prone \cite{Stenger24}. This presents a challenge 
    unique to the generation task compared to areas like time series forecasting or classification 
    \cite{Stenger24}. 
    Hence, future research would immensely benefit from a widely accepted, reasonably sized set of 
    qualified measures for the central evaluation criteria.
  \subsection{Our Contributions}
    To put it in simple terms, we are adopting the time series evaluation taxonomy outlined from 
    Stenger et al. \cite{Stenger24}, develop a comprehensive and unified SDG benchmark expanded from 
    the works of Ang et al. \cite{Ang23} in specifics to FTS by incorporating a utility evaluation 
    framework inspired by Boursin et al. \cite{Boursin22} through portfolio evaluations generated by 
    a deep hedger.
    Our key contributions include:
    \begin{enumerate}[label=\textbf{[C\arabic*]}]
      \item \label{contribute:1} \textbf{Consolidated Evaluation Framework:}
        We systematically review and consolidate evaluation methods from leading papers (models and surveys)
        in SDG and financial time series \cite{Stenger24, Ang23, Boursin22}, creating a 
        comprehensive assessment toolkit based on established practices.

      \item \label{contribute:2} \textbf{Unified Statistical and Utility Measures:}
        For the first time, we integrate both statistical fidelity metrics and practical 
        utility measures in a single SDGFTS benchmark, providing a more complete 
        evaluation of synthetic data quality.

      \item \label{contribute:3} \textbf{Open Benchmark Platform:}
        We deliver an open-source benchmark framework for the research community, 
        aiming to establish a gold standard for SDGFTS model evaluation and 
        comparison.
    \end{enumerate}


\section{Preliminaries}
  \subsection{Problem Definition}
  Let us formally define the Synthetic Data Generation (SDG) problem for Financial Time Series (FTS). 
  Given a financial time series $X$ with $N$ individual series of length $T$, we represent it as a matrix:

  $X = (x_1, ..., x_n)^T$

  where each individual series $x_i$ is a $T$-dimensional vector:

  $x_i = (x_{i,1}, ..., x_{i,t})$

  and each $x_{i,t}$ corresponds to a single time point $t$ of $x_i$.

  Let $P(x_1, ..., x_n)$ denote the real distribution of the given time series $X$. The objective of SDG for FTS 
  is to generate a synthetic time series:

  $\hat{X} = (\hat{x}_1, ..., \hat{x}_n)$

  such that its distribution $P(\hat{x}_1, ..., \hat{x}_n)$ approximates $P(x_1, ..., x_n)$, while preserving key statistical 
  properties and financial characteristics of the original data. These properties include:

  \subsection{Scope of Project}
    \subsubsection{Scope of Methods}
      Our benchmark encompasses a diverse range of SDGFTS methods, from traditional parametric approaches 
      to modern deep learning architectures. We selected models based on three main criteria:
      (1) proven industry adoption, (2) research community acceptance, and (3) recent methodological innovations.

      Our evaluation includes classical parametric models, which rely on predefined statistical distributions 
      and assumptions about the underlying data generation process. These models have been extensively used 
      in financial institutions for their interpretability and theoretical foundations. 

      We also evaluate modern non-parametric approaches, particularly deep learning-based models that learn 
      the data distribution directly from observations without assuming a specific form. These include 
      generative adversarial networks, variational autoencoders, and diffusion models, representing the 
      cutting edge in synthetic data generation.

      \subsubsection{Scope of Datasets}
      We evaluate models on diverse financial datasets spanning:
      \begin{itemize}
        \item Stock market indices (S\&P 500, NASDAQ, TSX)
        \item Individual stock prices from major exchanges
        \item Forex trading pairs
      \end{itemize}

      \subsubsection{Scope of Evaluation Taxonomical Criteria}
      Our evaluation framework follows the taxonomy structure proposed by Stenger et al. \cite{Stenger24}, 
      incorporating various evaluation measures from different papers in the field.

      We systematically integrate evaluation metrics from multiple sources while maintaining this 
      structured taxonomical approach, ensuring comprehensive coverage of all critical aspects of 
      SDGFTS evaluation and setting a standard for future research in time series SDG as a whole.

\section{Overview of Financial Time Series (FTS) Methods}
  Financial time series (FTS) methods refer to statistical and machine learning approaches used to model, 
  forecast, or simulate financial data such as prices, returns, and volatility. These methods aim to 
  reproduce key empirical properties including non-stationarity, heavy tails, volatility clustering, 
  leverage effects, and long-memory in absolute returns. 
  
  We group them into two main families: 
  classical parametric (stochastic) methods with explicit data-generating assumptions, and modern 
  non-parametric (deep learning) methods that learn complex dependencies directly from data.
  A detailed overview of the methods considered in our benchmark is provided in the following to sub-sections.

  \subsection{Classical Statistical (Parametric) Methods}
    Parametric models assume a specific functional form for the data-generating process, characterised by 
      a finite set of parameters. These models are interpretable and analytically tractable, allowing for 
      closed-form solutions in many cases. However, they may struggle to capture complex stylised facts 
      or high-dimensional dependencies beyond their structural assumptions. Below we outline several 
      widely-used parametric models in FTS.

      \textbf{Common notation and variables.} \(S_t\) – asset price, \(X_t = \ln S_t\) – log-price, 
      \(r_t = \ln(S_t/S_{t-1})\) – log-return, \(\mu\) – drift, \(\sigma\) – volatility, \(W_t\) – 
      standard Brownian motion, \(\Delta t\) – discrete time step.

      \begin{enumerate}[label=\textbf{[A\arabic*]}]
        \item \label{alg:gbm} \textbf{Geometric Brownian Motion (GBM).} 
        The price process follows a continuous-time stochastic process with constant drift and volatility. 
        Model-specific parameters are \(\mu\) and \(\sigma\).
        \begin{equation}
        dS_t = \mu S_t\,dt + \sigma S_t\,dW_t.
        \end{equation}

        \item \label{alg:ou} \textbf{Ornstein–Uhlenbeck (OU).} 
        A mean-reverting Gaussian process for log-prices or spreads. Model-specific parameters are 
        \(\theta>0\) (reversion rate), \(\mu\) (long-term mean), and \(\sigma\) (volatility).
        \begin{equation}
        dX_t = \theta(\mu - X_t)\,dt + \sigma\,dW_t.
        \end{equation}

        \item \label{alg:mjd} \textbf{Merton Jump Diffusion (MJD).} Extends GBM by incorporating 
        normally-distributed jumps. Model-specific parameters are \(\lambda\) (jump intensity), 
        \(\mu_j\) and \(\sigma_j\) (mean and standard deviation of jump sizes).
        \begin{equation}
        \frac{dS_t}{S_t} = \mu\,dt + \sigma\,dW_t + J\,dN_t,\\
        \end{equation}
        where $J \sim \mathcal N(\mu_j, \sigma_j^2),\quad N_t\sim\mathrm{Poisson}(\lambda t)$.


        \item \label{alg:dejd} \textbf{Double-Exponential Jump Diffusion (DEJD/Kou).} 
        A jump-diffusion model with asymmetric double-exponential jump sizes. Model-specific 
        parameters are \(p\) (probability of upward jump) and \(\eta_1, \eta_2\) 
        (exponential parameters for upward/downward jumps).
        \begin{align}
        \frac{dS_t}{S_t} &= \mu\,dt + \sigma\,dW_t + Y\,dN_t,\\
        Y &=
        \begin{cases}
        \mathrm{Exp}(\eta_1), &\text{with probability } p,\\[4pt]
        -\mathrm{Exp}(\eta_2), &\text{with probability } 1-p.
        \end{cases} \nonumber
        \end{align}

        \item \label{alg:garch} \textbf{GARCH(1,1).} 
        A discrete-time conditional heteroskedastic model for returns. Model-specific parameters 
        are \(\omega>0,\ \alpha\ge0,\ \beta\ge0\) (GARCH coefficients) and \(\mathcal D\) 
        (innovation distribution, usually standard Normal or Student-t). Captures volatility clustering 
        via time-varying conditional variance.
        \begin{align}
        r_t &= \sigma_t z_t,\quad z_t\sim\mathcal D,\\
        \sigma_t^2 &= \omega + \alpha r_{t-1}^2 + \beta \sigma_{t-1}^2 \nonumber
        \end{align}

        \item \label{alg:blockbootstrap} \textbf{Block Bootstrap (non-parametric).} 
        A resampling technique that preserves short-range dependence by sampling contiguous blocks of returns. 
        Although not parametric, it is included here for completeness and baseline comparison.
      \end{enumerate}


  \subsection{Deep Learning–based (Non-parametric) Methods}
    Non-parametric models (in this context) refer to generative (and often implicit) models that do *not* assume 
    a fixed parametric form for the data‐generating process; rather they learn, from data, latent structures 
    via flexible architectures (e.g., neural networks) and can model highly nonlinear, high-dimensional, 
    and multi-modal dependencies (for example multivariate FTS with interactions across assets, time horizons, 
    features). While these models sacrifice direct parametrisation / interpretability, they offer 
    greater freedom and expressive power — at the cost of larger data/training requirements, 
    more hyper-parameter tuning, and less analytic tractability.  
    Below we subdivide into three major deep learning generative model families: GANs, VAEs, Diffusion Models.

  \subsubsection{GANs (Generative Adversarial Networks)}  
    Generative Adversarial Networks (GANs) pit a generator network \(G(\cdot)\) (which attempts to mimic the data 
    distribution) against a discriminator (or critic) network \(D(\cdot)\) (which attempts to distinguish real 
    from synthetic). The generator is trained to fool the discriminator, and the discriminator is trained to 
    detect the fakes. In the time-series context, one must additionally capture temporal dynamics and 
    cross-feature dependencies.

    % is this meant to be footer?
    * Example: the TimeGAN model \cite{Yoon19} combines adversarial training 
    with supervised latent-space losses to ensure realistic temporal transitions and feature‐level realism. 
    * In such models the loss typically is  
    \begin{equation}
      \min_{G}\;\max_{D}\; \mathbb E_{x\sim p_{\rm data}} [\log D(x)] 
      \;+\; \mathbb E_{z\sim p_z} [\log(1 - D(G(z)))]
    \end{equation}
    with additional terms for supervised embedding, feature-matching, or temporal-consistency.  
    * These models are very flexible but can suffer from mode collapse, unstable training, and require 
    careful architecture/hyper-parameter tuning.

  \subsubsection{VAEs (Variational Autoencoders)}  
    Variational Autoencoders (VAEs) are generative latent-variable models that learn to map data \(x\) 
    into a latent distribution (encoder) \(q_\phi(z|x)\), and from latent \(z\) reconstruct \(x\)

    \begin{equation}
      \mathcal L(\theta,\phi;x) = \mathbb E_{z\sim q_\phi(z|x)} \bigl[\ln p_\theta(x|z)\bigr] 
      \;-\; D_{\!KL}\bigl(q_\phi(z|x)\;\|\;p(z)\bigr).
    \end{equation}

    In the time‐series generation context, e.g., TimeVAE (Desai et al., 2021-22) uses a VAE architecture with 
    temporal encoder/decoder and latent structure capturing sequence‐level variability. 
    :contentReference[oaicite:3]{index=3}  
    * Pros: more stable to train than GANs, latent space admits interpolation, can incorporate domain knowledge 
    (e.g., trend/seasonality components) as in TimeVAE.  
    * Cons: may under-represent heavy tails or complex multi-modal behaviour (latent distribution is often 
    Gaussian, decoder may produce over-smoothed samples).

  \subsubsection{Diffusion Models}  
    Diffusion models are a newer class of generative models that define a forward “noising” process 
    (often a Gaussian Markov chain or SDE) gradually mapping data into noise, and then train a neural network 
    to reverse this process (denoising) to sample from the data distribution. 
    :contentReference[oaicite:4]{index=4}  
    In time‐series generation (or forecasting/imputation) contexts, diffusion models have begun to show 
    strong performance. :contentReference[oaicite:5]{index=5}  
    A canonical forward discrete-time chain (DDPM style) might be  
  
    \begin{equation}
    q(x_{1:T} \mid x_0) = \prod_{t=1}^T \mathcal N\bigl(x_t; \sqrt{1-\beta_t}\,x_{t-1},\;
    \beta_t I\bigr), \quad x_0 \sim p_{\mathrm{data}}
    \end{equation}
  
    and the learned reverse process  
    \begin{equation}
      p_\theta(x_{t-1}\mid x_t) = \mathcal N\!\left(x_{t-1};\,\mu_\theta(x_t,t),\,\Sigma_\theta(x_t,t)\right)
    \end{equation}
 
    In the FTS-generation setting, recent work 
    %(e.g., “A diffusion-based generative model for financial time 
    %series via GBM”) 
    shows that one can incorporate financial SDE structure (e.g., heteroskedastic 
    noise proportional to price) into the forward process. 
    %:contentReference[oaicite:6]{index=6}  
    * Pros: very high fidelity and diversity, less mode collapse than GANs, stable training.  
    * Cons: high computational cost (many denoising steps), less interpretability, often large 
    memory/training requirements.\\

    In summary, parametric models offer interpretability, analytic tractability and fast simulation 
    (once calibrated), but may fail to reproduce complex stylised facts, interactions, or high-dimensional 
    dynamics beyond their structural assumptions. Deep generative models (GANs, VAEs, Diffusions) 
    increase expressive capacity and can generate diverse realistic synthetic sequences, but they bring 
    heavier data/training demand, more hyper-parameter tuning, less direct interpretability, and often 
    slower simulation or sampling times.

\section{Stonk Bench Architechture}
  \subsection{Datasets and Preprocessing}
    \subsubsection{Data type.} We use equity price data (e.g., AAPL) at daily frequency with four channels 
    (Open, High, Low, Close). Let \(X \in \mathbb{R}^{T \times N}\) denote a univariate stream with \(N=4\) 
    channels and length \(T\).

    \subsubsection{Transformations.} We standardize to \emph{log-returns} per channel via

    \[ r_t = \log P_t - \log P_{t-1} \,, \quad r_t \in \mathbb{R}^N. \]
  
    For parametric models, we use contiguous \(T_{train}\) historical segments. 
    For deep models, we construct 3D windows \(\mathcal{W} \in \mathbb{R}^{A \times L \times N}\) 
    by sliding window extraction of length \(L\) and sample \(A\) windows for train/validation/test, 
    preserving temporal order in splits.

    \subsubsection{Data loaders.} For deep models, we create mini-batches from \(\mathcal{W}\) with fixed 
    seeds for reproducibility (train/valid/test), enabling epoch-wise training and stable evaluation. 
    For fair comparison across model families, parametric models generate sequences of the same length 
    \(L\) and number of samples \(A\) as the deep models.

    \subsubsection{Visual diagnostics.} We compute per-channel histograms, Q--Q plots, ACF/PACF on returns 
    and absolute returns, rolling-volatility traces, and 2D embeddings (t-SNE/UMAP) of window-level features 
    to validate preprocessing and detect leakage or anomalies prior to training.

  \subsection{Statistical Evaluation Measures}
    \subsubsection{Feature-based Distance Measures}
    These metrics quantify how well synthetic data captures key marginal and second-order properties of real data.

    \begin{enumerate}[label=\textbf{[M\arabic*]}]
      \item \label{metric:mdd} \textbf{Marginal Distribution Difference (MDD):}
      Distance between real and synthetic marginals (e.g., average 1-Wasserstein across channels) to assess range and frequency alignment.
      Let \(\widehat{F}^j_{r}\) and \(\widehat{F}^j_{s}\) be empirical CDFs of returns for channel \(j\). We compute
      \[
        \mathrm{MDD} = \frac{1}{N} \sum_{j=1}^{N} W_1\!\left(\widehat{F}^j_{r}, \, \widehat{F}^j_{s}\right),\quad
        W_1(F,G) = \int_{0}^{1} \big| F^{-1}(u) - G^{-1}(u) \big|\,du.
      \]

      \item \label{metric:md} \textbf{Mean Difference (MD):}
      Absolute difference of per-channel means to test central tendency preservation.
      Let \(\mu^j_{r}\) and \(\mu^j_{s}\) be real and synthetic means for channel \(j\). Then
      \[
        \mathrm{MD} = \frac{1}{N} \sum_{j=1}^{N} \big|\mu^j_{r} - \mu^j_{s}\big|.
      \]

      \item \label{metric:sdd} \textbf{Standard Deviation Difference (SDD):}
      Absolute difference of per-channel standard deviations to test volatility level fidelity.
      With \(\sigma^j_{r}\) and \(\sigma^j_{s}\):
      \[
        \mathrm{SDD} = \frac{1}{N} \sum_{j=1}^{N} \big|\sigma^j_{r} - \sigma^j_{s}\big|.
      \]

      \item \label{metric:kd} \textbf{Kurtosis Difference (KD):}
      Difference in excess kurtosis per channel to evaluate heavy-tailedness. Denoting excess kurtosis by
      \(\kappa^{\mathrm{ex}}(x) = \frac{\mathbb{E}[(x-\mu)^4]}{\sigma^4} - 3\), we compute
      \[
        \mathrm{KD} = \frac{1}{N} \sum_{j=1}^{N} \big|\kappa^{\mathrm{ex}}(r^j) - \kappa^{\mathrm{ex}}(s^j)\big|.
      \]

      \item \label{metric:acd} \textbf{AutoCorrelation Difference (ACD):}
      Absolute difference in lag-1 autocorrelation of returns per channel to gauge short-memory dynamics. For channel \(j\):
      \[
        \rho^j(1) = \frac{\sum_{t=2}^{T} (x^j_t - \bar{x}^j)(x^j_{t-1} - \bar{x}^j)}{\sum_{t=1}^{T} (x^j_t - \bar{x}^j)^2},\quad
        \mathrm{ACD} = \frac{1}{N} \sum_{j=1}^{N} \big|\rho^j_{r}(1) - \rho^j_{s}(1)\big|.
      \]
    \end{enumerate}

    \subsubsection{Visualization Methods}
    Visual tools complement numeric metrics for face-validity and communication \cite{Ang23}.
    \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
      \item \label{metric:tsne} \textbf{t-SNE/UMAP of window features:}
      2D embeddings of window-level features (e.g., pooled activations or hand-crafted statistics) for real vs. synthetic overlap and cluster structure.

      \item \label{metric:dist} \textbf{Distribution and Q--Q comparisons:}
      Channel-wise histograms and Q--Q plots for returns (and absolute returns) to visualize tails and skew.
    \end{enumerate}

    \subsubsection{Diversity Metrics}
    Diversity prevents mode collapse and encourages broad coverage.
    \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
      \item \label{metric:ed} \textbf{Intra-Class Euclidean Distance (ICD-ED):}
      Average pairwise Euclidean distance between generated samples in feature space. Given feature embeddings
      \(\phi(X^{(a)}) \in \mathbb{R}^d\) for samples \(a=1,\dots,A\):
      \[
        \mathrm{ICD\text{-}ED} = \frac{2}{A(A-1)} \sum_{1\le a<b\le A} \left\| \phi\big(X^{(a)}\big) - \phi\big(X^{(b)}\big) \right\|_2.
      \]

      \item \label{metric:dtw} \textbf{Intra-Class Dynamic Time Warping (ICD-DTW):}
      Average pairwise DTW distance to capture temporal similarity under local warping. Let \(d_{\mathrm{DTW}}(\cdot,\cdot)\) denote DTW distance between two multivariate sequences:
      \[
        \mathrm{ICD\text{-}DTW} = \frac{2}{A(A-1)} \sum_{1\le a<b\le A} d_{\mathrm{DTW}}\!\left(X^{(a)}, X^{(b)}\right).
      \]
    \end{enumerate}

    \subsubsection{Efficiency Assessment}
      \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
        \item \label{metric:gentime} \textbf{Generation Time:}
        Wall-clock time to generate a fixed number of samples (e.g., 500), measured with identical hardware and sequence length. If \(t_0\) and \(t_1\) are start/end timestamps and \(S\) is the number of samples, then
        \[ T_{\mathrm{gen}} = t_1 - t_0 \quad (\text{seconds for } S \text{ samples}). \]
      \end{enumerate}

    \subsubsection{Stylized Facts Verification}
    We verify canonical stylized facts of financial returns.
      \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
        \item \label{metric:heavytails} \textbf{Heavy Tails:}
        Excess kurtosis of returns \((\kappa-3)\) per channel and the absolute difference to real.
        \[ \kappa^{\mathrm{ex}}(x) = \frac{\mathbb{E}[(x-\mu)^4]}{\sigma^4} - 3,\quad \Delta\kappa^{\mathrm{ex}} = \frac{1}{N}\sum_{j=1}^{N} \big|\kappa^{\mathrm{ex}}(r^j) - \kappa^{\mathrm{ex}}(s^j)\big|. \]

        \item \label{metric:autocorr} \textbf{Return Autocorrelation:}
        Lag-1 autocorrelation of raw returns; should be close to zero for liquid assets. Using \(\rho^j(1)\) as above, report per-channel values and/or their absolute differences to real.

        \item \label{metric:volclustering} \textbf{Volatility Clustering:}
        Autocorrelation of squared or absolute returns (lag-1) to measure volatility persistence.
        \[ \rho^j_{x^2}(1) = \mathrm{Corr}\big((x^j_t)^2, (x^j_{t-1})^2\big), \quad \text{or} \quad \rho^j_{|x|}(1) = \mathrm{Corr}\big(|x^j_t|, |x^j_{t-1}|\big). \]

        \item \label{metric:longmemory} \textbf{Long Memory in Volatility:}
        Decay profile of ACF in absolute returns; summarized as an average over lags \(\mathcal{L} = \{\ell_1,\dots,\ell_L\}\):
        \[ \mathrm{LM} = \frac{1}{N}\sum_{j=1}^{N} \left( \frac{1}{L} \sum_{\ell\in\mathcal{L}} \rho^j_{|x|}(\ell) \right). \]

        \item \label{metric:nonstat} \textbf{Non-Stationarity:}
        Window-wise drift/variance drift statistics (e.g., KPSS/ADF summaries or rolling-moment drift) to ensure realistic non-stationary behavior. Using a partition of the series into windows \(w=1,\dots,W\) with window means \(m_w\) and standard deviations \(s_w\):
        \[ \mathrm{NS} = \mathrm{Var}_w(m_w) + \mathrm{Var}_w(s_w), \quad \Delta\mathrm{NS} = \big| \mathrm{NS}_{\mathrm{real}} - \mathrm{NS}_{\mathrm{synth}} \big|. \]
      \end{enumerate}
  
  \subsection{Utility Evaluation Measures: Deep Hedging}
    Utility measures are critical for evaluating synthetic data beyond statistical metrics, 
    as they assess the practical value of generated data in real-world financial applications \cite{Boursin22}. 
    Our benchmark incorporates deep hedging as a utility measure for several key reasons:

    \begin{enumerate}[label=\textbf{[U\arabic*]}]
      \item \label{utility:application}\textbf{Real-world Application Testing:}
      Deep hedging provides a concrete way to evaluate how synthetic data performs in 
      actual financial tasks, particularly in derivatives pricing and risk management.

      \item \label{utility:industry}\textbf{Industry-relevant Metrics:}
      By comparing hedging strategies trained on synthetic versus real data, we can 
      assess the practical utility of synthetic data through metrics that matter to 
      financial practitioners, such as replication errors and hedging performance.

      \item \label{utility:validation}\textbf{Model Robustness Validation:}
      Deep hedging helps verify if synthetic data maintains the complex relationships 
      and market dynamics necessary for developing reliable trading strategies.
    \end{enumerate}
    \subsubsection{Deep Hedger Problem Defintion}
    \subsubsection{Deep Hedger Architecture}
    \subsubsection{Deep Hedger Portfolio Evaluation}

\section{Results and Analysis}
  \subsection{Statistical Evaluation Results}
  We report per-model, per-channel metrics. Copy values from the generated JSON (e.g., \texttt{complete\_evaluation.json}) into the following templates.

  \begin{table*}[h]
    \centering
    \caption{Fidelity metrics by model and channel (lower is better for differences). Channels C1--C4 correspond to dataset channels (e.g., Open, High, Low, Close).}
    \begin{tabular}{l|cccc|cccc|cccc|cccc}
      \toprule
      & \multicolumn{4}{c|}{MDD} & \multicolumn{4}{c|}{MD} & \multicolumn{4}{c|}{SDD} & \multicolumn{4}{c}{KD} \\
      Model & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 \\
      \midrule
      GBM &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      OU\_Process &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      MJD &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      GARCH11 &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      DEJD &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      BlockBootstrap &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      TimeGAN &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      QuantGAN &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      TimeVAE &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      \bottomrule
    \end{tabular}
  \end{table*}

  \begin{table*}[h]
    \centering
    \caption{Temporal and diversity metrics by model and channel (lower is better for differences; higher is better for diversity distances).}
    \begin{tabular}{l|cccc|cccc|cccc}
      \toprule
      & \multicolumn{4}{c|}{ACD} & \multicolumn{4}{c|}{ICD-ED} & \multicolumn{4}{c}{ICD-DTW} \\
      Model & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 \\
      \midrule
      GBM &  &  &  &  &  &  &  &  &  &  &  &  \\
      OU\_Process &  &  &  &  &  &  &  &  &  &  &  &  \\
      MJD &  &  &  &  &  &  &  &  &  &  &  &  \\
      GARCH11 &  &  &  &  &  &  &  &  &  &  &  &  \\
      DEJD &  &  &  &  &  &  &  &  &  &  &  &  \\
      BlockBootstrap &  &  &  &  &  &  &  &  &  &  &  &  \\
      TimeGAN &  &  &  &  &  &  &  &  &  &  &  &  \\
      QuantGAN &  &  &  &  &  &  &  &  &  &  &  &  \\
      TimeVAE &  &  &  &  &  &  &  &  &  &  &  &  \\
      \bottomrule
    \end{tabular}
  \end{table*}

  \begin{table*}[h]
    \centering
    \caption{Stylized facts by model and channel (differences reported real minus synthetic unless noted).}
    \begin{tabular}{l|cccc|cccc|cccc|cccc}
      \toprule
      & \multicolumn{4}{c|}{Heavy Tails (diff)} & \multicolumn{4}{c|}{Autocorr Raw (diff)} & \multicolumn{4}{c|}{Volatility Clustering (diff)} & \multicolumn{4}{c}{Long Memory (diff)} \\
      Model & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 & C1 & C2 & C3 & C4 \\
      \midrule
      GBM &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      OU\_Process &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      MJD &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      GARCH11 &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      DEJD &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      BlockBootstrap &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      TimeGAN &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      QuantGAN &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      TimeVAE &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
      \bottomrule
    \end{tabular}
  \end{table*}

  \begin{table}[h]
    \centering
    \caption{Non-stationarity (diff) and generation time per model.}
    \begin{tabular}{l|cccc|c}
      \toprule
      & \multicolumn{4}{c|}{Non-stationarity (diff)} & Gen. Time (500) \\
      Model & C1 & C2 & C3 & C4 & seconds \\
      \midrule
      GBM &  &  &  &  &  \\
      OU\_Process &  &  &  &  &  \\
      MJD &  &  &  &  &  \\
      GARCH11 &  &  &  &  &  \\
      DEJD &  &  &  &  &  \\
      BlockBootstrap &  &  &  &  &  \\
      TimeGAN &  &  &  &  &  \\
      QuantGAN &  &  &  &  &  \\
      TimeVAE &  &  &  &  &  \\
      \bottomrule
    \end{tabular}
  \end{table}

  \subsection{Utility Evaluation Results}
  Results of the deep hedging evaluation (replication error, P\&L distribution, risk-adjusted metrics) can be summarized in tables analogous to the above once computed.

  \subsection{Comprehensive Model Comparison}
  Provide radar plots or scorecards that combine normalized metrics (fidelity, diversity, stylized facts, efficiency) into composite ranks per task.

  \subsection{Ranking Analysis}
  Discuss trade-offs: fidelity vs. diversity, training time vs. quality, and sensitivity to window length and sample count.

\section{Conclusion and Future Work}
  In our research, we recognize the existing limitations in the evaluation of synthetic time series, 
  particularly the absence of a universally accepted framework. To address this, we adopt the 
  evaluation taxonomy proposed by Stenger et al. and expand upon it to create a comprehensive benchmark 
  specifically tailored for Synthetic Data Generation for Financial Time Series (SDGFTS). 
  Our contributions include the development of a consolidated evaluation framework that systematically 
  reviews and integrates various assessment methods from leading studies in the field. 
  This approach not only enhances the rigor of evaluations but also facilitates the comparison of 
  different SDGFTS models, ultimately providing a more standardized and reliable means of assessing 
  synthetic data quality.
  \subsection{Summary of Findings}
  \subsection{Implications for SDGFTS Research}
  \subsection{Current Limitations and Shortcomings}
  \subsection{Future Research Directions}


\begin{acks}
To professor Irene Huang, University of Toronto, for her supervision and guidance throughout the project.
\end{acks}


\bibliographystyle{ACM-Reference-Format}
\bibliography{stonk-bench}



\appendix

\section{Preprocessing Diagnostics}
  \subsection{Channel-wise Distributions}
  \begin{figure*}[h]
    \centering
    % \includegraphics[width=0.95\textwidth]{results/evaluation_YYYYMMDD_HHMMSS/GBM/distributions.png}
    \caption{Histograms and Q--Q plots of real vs. synthetic returns per channel. Replace with generated figures from \texttt{VisualAssessmentEvaluator}.}
  \end{figure*}

  \subsection{Autocorrelation Analyses}
  \begin{figure*}[h]
    \centering
    % \includegraphics[width=0.95\textwidth]{results/evaluation_YYYYMMDD_HHMMSS/GBM/acf_pacf.png}
    \caption{ACF/PACF of returns and absolute returns for real vs. synthetic data.}
  \end{figure*}

\section{Embedding Visualizations}
  \begin{figure*}[h]
    \centering
    % \includegraphics[width=0.95\textwidth]{results/evaluation_YYYYMMDD_HHMMSS/GBM/tsne.png}
    \caption{t-SNE/UMAP embeddings of window-level features; color-coded real vs. synthetic for overlap assessment.}
  \end{figure*}

\section{Per-Model Visual Assessments}
  For each model (GBM, OU\_Process, MJD, GARCH11, DEJD, BlockBootstrap, TimeGAN, QuantGAN, TimeVAE), include side-by-side real/synthetic plots and distribution overlays.
  \begin{figure*}[h]
    \centering
    % Example placeholder for one model; duplicate per model and update path
    % \includegraphics[width=0.95\textwidth]{results/evaluation_YYYYMMDD_HHMMSS/GBM/overview.png}
    \caption{Representative visual assessment panels for a selected model.}
  \end{figure*}

\end{document}