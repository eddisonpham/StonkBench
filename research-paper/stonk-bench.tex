%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
\usepackage{enumitem}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Stonk Bench: Unified Benchmark for Synthetic Data Generation for Financial Time Series}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Uyen Lam Ho}
\authornote{Both authors contributed equally to this research.}
\email{uyenlam.ho@mail.utoronto.ca}
% \orcid{1234-5678-9012}
\author{Eddison Pham}
\authornotemark[1]
\email{eddison.pham@mail.utoronto.ca}
\affiliation{%
  \institution{University of Toronto}
  \city{Toronto}
  \state{Ontario}
  \country{Canda}
}

% \author{Uyen Lam Ho}
% \affiliation{%
%   \institution{University of Toronto}
%   \city{Toronto}
%   \province{Ontario}
%   \country{Canada}}
% \email{uyenlam.ho@mail.utoronto.ca}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Ho and Pham}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    The ever emerging field of Synthetic Data Generation (SDG) has gain traction 
    within many financial domains, including Finacial Time Series (FTS) data \cite{Potluru24}. 
    However, there has been discorse and lack in universal agreement in what determines a better SDGFTS 
    (Synthetic Data Generation for Financial Time Series), which maybe hindering progress 
    in the field \cite{Stenger24}. 
    In this paper, we propose and contribute a comprehensive benchmark for SDGFTS, 
    covering various aspects such as data quality, privacy, and utility. 
    We evaluate several state-of-the-art SDG methods using our benchmark and 
    provide insights into their strengths and weaknesses. 
    Our first-of-its-kind benchmark aims to facilitate the development of more effective SDG 
    methods for FTS data, incorperating both classical statistical measures
    and utility benefits, and test over (insert number) to decicively determine what is the 
    best SDGFTS model right now and for the future.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>00000000.0000000.0000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{
    Synthetic Data Generation, 
    Financial Time Series,
    Benchmarking
}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
  \centering
  % trim={<left> <bottom> <right> <top>} (units: pt, bp, mm, etc.) â€” adjust bottom/top to crop into a banner
  \includegraphics[width=\textwidth,height=5.5cm,keepaspectratio,trim=0 150 0 150,clip]{tse-1981.png}
  \caption{Toronto Stock Exchange, Toronto, 1981}
  \Description{A panoramic view of the Toronto Stock Exchange building in 1981.}
  \label{fig:teaser}
\end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
  Synthetic Data Generation (SDG) has emerged as a crucial tool in financial technology, 
  particularly for Financial Time Series (FTS) data \cite{Potluru24}. The ability to generate high-quality 
  synthetic financial data addresses several critical challenges in the field, 
  including data privacy concerns, limited data availability, and the need for diverse training 
  datasets in machine learning applications \cite{Stenger24}.

%%
% need more revision in this section
% to capture the scope of the project, with some shortcomings we faced at the beginning
  Despite the growing importance of SDGFTS (Synthetic Data Generation for 
  Financial Time Series), there is a notable lack of standardization in evaluating 
  the quality and effectiveness of these generative models \cite{Stenger24}. Current evaluation methods 
  vary widely across studies, making it difficult to compare different approaches objectively 
  and determine their relative strengths and weaknesses.

  Our research addresses this gap by introducing a comprehensive benchmark framework that 
  encompasses:
  \begin{itemize}
      \item Statistical fidelity measures for comparing synthetic and real FTS
      \item Privacy preservation metrics to ensure sensitive financial information 
      remains protected
      \item Utility metrics that assess the practical value of synthetic data in 
      downstream tasks
      \item Performance evaluation across multiple SDGFTS models and datasets
  \end{itemize}

  By analyzing the results from our MLflow experiments and applying our unified benchmark, 
  we aim to provide clear guidelines for evaluating SDGFTS models and establish a standard 
  for future research in this domain.
%% 

  \subsection{Limitations in the SDGFTS Literature}

  Among other things, we observed that there is currently no universal, generally accepted approach 
  to evaluating synthetic time series\cite{Stenger24}; this issue extends beyond FTS to generative 
  frameworks like GANs as a whole \cite{Wang20}. 
  Many evaluation measures are insufficiently defined and lack public implementations, making reuse 
  and reproduction troublesome and error-prone \cite{Stenger24}. This presents a challenge 
  unique to the generation task compared to areas like time series forecasting or classification \cite{Stenger24}. 
  Hence, future research would immensely benefit from a widely accepted, reasonably sized set of 
  qualified measures for the central evaluation criteria.
  \subsection{Our Contributions}
    To put it in simple terms, we are adopting the time series evaluation taxonomy outlined from 
    Stenger et al. \cite{Stenger24}, develop a comprehensive and unified SDG benchmark expanded from 
    the works of Ang et al. \cite{Ang23} in specifics to FTS by incorporating a utility evaluation 
    framework inspired by Boursin et al. \cite{Boursin22} through portfolio evaluations generated by 
    a deep hedger.
      Our key contributions include:
      \begin{enumerate}[label=\textbf{[C\arabic*]}]
        \item \label{contribute:1} \textbf{Consolidated Evaluation Framework:}
        We systematically review and consolidate evaluation methods from leading papers (models and surveys)
        in SDG and financial time series \cite{Stenger24, Ang23, Boursin22}, creating a 
        comprehensive assessment toolkit based on established practices.

        \item \label{contribute:2} \textbf{Unified Statistical and Utility Measures:}
        For the first time, we integrate both statistical fidelity metrics and practical 
        utility measures in a single SDGFTS benchmark, providing a more complete 
        evaluation of synthetic data quality.

        \item \label{contribute:3} \textbf{Open Benchmark Platform:}
        We deliver an open-source benchmark framework for the research community, 
        aiming to establish a gold standard for SDGFTS model evaluation and 
        comparison.
      \end{enumerate}


\section{Preliminaries}
  \subsection{Problem Definition}
  Let us formally define the Synthetic Data Generation (SDG) problem for Financial Time Series (FTS). 
  Given a financial time series $X$ with $N$ individual series of length $T$, we represent it as a matrix:

  $X = (x_1, ..., x_n)^T$

  where each individual series $x_i$ is a $T$-dimensional vector:

  $x_i = (x_{i,1}, ..., x_{i,t})$

  and each $x_{i,t}$ corresponds to a single time point $t$ of $x_i$.

  Let $P(x_1, ..., x_n)$ denote the real distribution of the given time series $X$. The objective of SDG for FTS 
  is to generate a synthetic time series:

  $\hat{X} = (\hat{x}_1, ..., \hat{x}_n)$

  such that its distribution $P(\hat{x}_1, ..., \hat{x}_n)$ approximates $P(x_1, ..., x_n)$, while preserving key statistical 
  properties and financial characteristics of the original data. These properties include:

  \subsection{Scope of Project}
    \subsubsection{Scope of Methods}
      Our benchmark encompasses a diverse range of SDGFTS methods, from traditional parametric approaches 
      to modern deep learning architectures. We selected models based on three main criteria:
      (1) proven industry adoption, (2) research community acceptance, and (3) recent methodological innovations.

      Our evaluation includes classical parametric models, which rely on predefined statistical distributions 
      and assumptions about the underlying data generation process. These models have been extensively used 
      in financial institutions for their interpretability and theoretical foundations. 
      
      We also evaluate modern non-parametric approaches, particularly deep learning-based models that learn 
      the data distribution directly from observations without assuming a specific form. These include 
      generative adversarial networks, variational autoencoders, and diffusion models, representing the 
      cutting edge in synthetic data generation.

      \subsubsection{Scope of Datasets}
      We evaluate models on diverse financial datasets spanning:
      \begin{itemize}
        \item Stock market indices (S\&P 500, NASDAQ, TSX)
        \item Individual stock prices from major exchanges
        \item Forex trading pairs
      \end{itemize}

      \subsubsection{Scope of Evaluation Taxonomical Criteria}
      Our evaluation framework follows the taxonomy structure proposed by Stenger et al. \cite{Stenger24}, 
      incorporating various evaluation measures from different papers in the field.

      We systematically integrate evaluation metrics from multiple sources while maintaining this 
      structured taxonomical approach, ensuring comprehensive coverage of all critical aspects of 
      SDGFTS evaluation and setting a standard for future research in time series SDG as a whole.

\section{Overview of FTS methods}

  \subsection{Classical Statistical (Parametric) Methods}
  \subsection{Deep Learning-based (Non-parametric) Methods}
    \subsubsection{Generative Adversarial Networks (GANs)}
    \subsubsection{Variational Autoencoders (VAEs)}
    \subsubsection{Diffusion Models}
    \subsubsection{Others}

\section{Stonk Bench Architechture}
  \subsection{Datasets and Preprocessing}
  \subsection{Statistical Evaluation Measures}
    \subsubsection{Feature-based Distance Measures}
    These metrics quantify how well synthetic data captures the statistical properties of real data:
    
    \begin{enumerate}[label=\textbf{[M\arabic*]}]
      \item \label{metric:mdd} \textbf{Marginal Distribution Difference (MDD):} 
      Measures the overall difference between the probability distributions of real and synthetic data, 
      helping assess if the synthetic data maintains the same value ranges and frequencies.

      \item \label{metric:md} \textbf{Mean Difference (MD):}
      Compares the central tendencies of real and synthetic data, ensuring the synthetic data preserves 
      the average behavior of the time series.

      \item \label{metric:sdd} \textbf{Standard Deviation Difference (SDD):}
      Evaluates how well the synthetic data maintains the volatility characteristics of the real data by 
      comparing their spread measures.

      \item \label{metric:kd} \textbf{Kurtosis Difference (KD):}
      Assesses preservation of the "tailedness" of distributions, crucial for capturing extreme events in 
      financial data.

      \item \label{metric:acd} \textbf{AutoCorrelation Difference (ACD):}
      Measures how well temporal dependencies are preserved in the synthetic data compared to real data.
    \end{enumerate}

    \subsubsection{Visualization Methods}
    Visual analysis tools provide intuitive validation of synthetic data quality and visual interpretive comparisons 
    and contrast between real and synthetic time series \cite{Ang23}. Visual assessment is also useful for 
    presentation purposes when presenting to non-technical stakeholders.

    \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
      \item \label{metric:tsne} \textbf{t-SNE Visualization:}
      Reduces high-dimensional financial data to 2D representations, allowing visual comparison of 
      real and synthetic data structure.

      \item \label{metric:dist} \textbf{Distribution Comparison Plots:}
      Direct visual comparison of probability distributions between real and synthetic data through 
      histograms and Q-Q plots.
    \end{enumerate}

    \subsubsection{Diversity Metrics}
    These metrics ensure synthetic data provides meaningful variations:

    \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
      \item \label{metric:ed} \textbf{Euclidean Distance (ED):}
      Measures basic similarity between synthetic samples, helping assess diversity within generated data.

      \item \label{metric:dtw} \textbf{Dynamic Time Warping (DTW):}
      Captures temporal similarities while allowing for slight shifts and warps in time series patterns.
    \end{enumerate}

    \subsubsection{Efficiency Assessment}
      \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
        \item \label{metric:gentime} \textbf{Generation Time:}
        Measures computational efficiency by tracking time required to generate 500 synthetic samples, 
        crucial for practical applications.
      \end{enumerate}

    \subsubsection{Stylized Facts Verification}
      These tests verify if synthetic data exhibits key properties of financial time series:

      \begin{enumerate}[label=\textbf{[M\arabic*]}, resume]
        \item \label{metric:heavytails} \textbf{Heavy Tails:}
        Measures excess kurtosis to verify if synthetic data captures the frequent extreme events characteristic 
        of financial returns.

        \item \label{metric:autocorr} \textbf{Return Autocorrelation:}
        Checks for proper modeling of temporal dependencies in returns through lag-1 autocorrelation.

        \item \label{metric:volclustering} \textbf{Volatility Clustering:}
        Verifies if periods of high volatility tend to cluster together, a key feature of financial markets.

        \item \label{metric:longmemory} \textbf{Long Memory in Volatitly:}
        Tests for persistent autocorrelation in absolute returns, indicating proper modeling of 
        volatility persistence.

        \item \label{metric:nonstat} \textbf{Non-Stationarity Detection:}
        Ensures synthetic data maintains the non-stationary characteristics typical of financial time series.
      \end{enumerate}

  \subsection{Utility Evaluation Measures: Deep Hedging}
    Utility measures are critical for evaluating synthetic data beyond statistical metrics, 
    as they assess the practical value of generated data in real-world financial applications \cite{Boursin22}. 
    Our benchmark incorporates deep hedging as a utility measure for several key reasons:

    \begin{enumerate}[label=\textbf{[U\arabic*]}]
      \item \label{utility:application}\textbf{Real-world Application Testing:}
      Deep hedging provides a concrete way to evaluate how synthetic data performs in 
      actual financial tasks, particularly in derivatives pricing and risk management.

      \item \label{utility:industry}\textbf{Industry-relevant Metrics:}
      By comparing hedging strategies trained on synthetic versus real data, we can 
      assess the practical utility of synthetic data through metrics that matter to 
      financial practitioners, such as replication errors and hedging performance.

      \item \label{utility:validation}\textbf{Model Robustness Validation:}
      Deep hedging helps verify if synthetic data maintains the complex relationships 
      and market dynamics necessary for developing reliable trading strategies.
    \end{enumerate}
    \subsubsection{Deep Hedger Problem Defintion}
    \subsubsection{Deep Hedger Architecture}
    \subsubsection{Deep Hedger Portfolio Evaluation}

\section{Results and Analysis}
  \subsection{Statistical Evaluation Results}
  \subsection{Utility Evaluation Results}
  \subsection{Comprehensive Model Comparison}
  \subsection{Ranking Analysis}

\section{Conclusion and Future Work}
  In our research, we recognize the existing limitations in the evaluation of synthetic time series, 
  particularly the absence of a universally accepted framework. To address this, we adopt the 
  evaluation taxonomy proposed by Stenger et al. and expand upon it to create a comprehensive benchmark 
  specifically tailored for Synthetic Data Generation for Financial Time Series (SDGFTS). 
  Our contributions include the development of a consolidated evaluation framework that systematically 
  reviews and integrates various assessment methods from leading studies in the field. 
  This approach not only enhances the rigor of evaluations but also facilitates the comparison of 
  different SDGFTS models, ultimately providing a more standardized and reliable means of assessing 
  synthetic data quality.
  \subsection{Summary of Findings}
  \subsection{Implications for SDGFTS Research}
  \subsection{Current Limitations and Shortcomings}
  \subsection{Future Research Directions}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
To professor Irene Huang, University of Toronto, for her supervision and guidance throughout the project.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{stonk-bench}


%%
%% If your work has an appendix, this is the place to put it.
\appendix

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
