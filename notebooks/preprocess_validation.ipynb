{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Preprocessor Validation\n",
        "\n",
        "This notebook verifies that the modified preprocessing pipeline with PyTorch Dataset support creates the correct data structures and handles batching properly with seed support.\n",
        "\n",
        "## Key Features to Verify:\n",
        "- Time series data shape `(R, l)` where R=sequences, l=length\n",
        "- Seed-based reproducible shuffling\n",
        "- Proper PyTorch Dataset implementation\n",
        "- Efficient DataLoader batching\n",
        "- Dynamic seed changing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root added to sys.path: /Users/eddisonpham/Projects/Unified-benchmark-for-SDGFTS\n",
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path().resolve().parents[0]\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "print(\"Project root added to sys.path:\", project_root)\n",
        "\n",
        "from src.utils.preprocessing_utils import (\n",
        "    TimeSeriesDataset, \n",
        "    LogReturnTransformation,\n",
        "    create_dataloaders,\n",
        "    preprocess_data\n",
        ")\n",
        "\n",
        "from src.utils.configs_utils import get_dataset_cfgs\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Basic Preprocessing with Seed Support\n",
        "\n",
        "### Testing: \n",
        "- AAPL: `data/raw/AAPL/AAPL.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_data_shapes(train_data, valid_data, real_data, shape_labels):\n",
        "    print(f\"Data shapes:\")\n",
        "    print(f\"  Train shape: {train_data.shape} {shape_labels['train']}\")\n",
        "    print(f\"  Valid shape: {valid_data.shape} {shape_labels['valid']}\")\n",
        "    print(f\"  Real shape: {real_data.shape} {shape_labels['real']}\")\n",
        "    if 'sequence_length' in shape_labels:\n",
        "        print(f\"  Sequence length (l): {shape_labels['sequence_length']}\")\n",
        "    if 'num_channels' in shape_labels:\n",
        "        print(f\"  Number of channels (N): {shape_labels['num_channels']}\")\n",
        "    if 'total_samples' in shape_labels:\n",
        "        print(f\"  Total time-series samples (R): {shape_labels['total_samples']}\")\n",
        "\n",
        "def print_channel_statistics(train_data, valid_data, real_data):\n",
        "    \"\"\"\n",
        "    Print summary statistics (min, max, mean) for train, validation, and real data.\n",
        "    \"\"\"\n",
        "    print(f\"\\nLog return statistics:\")\n",
        "    train_min, train_max, train_mean = train_data.min(), train_data.max(), train_data.mean()\n",
        "    valid_min, valid_max, valid_mean = valid_data.min(), valid_data.max(), valid_data.mean()\n",
        "    real_min, real_max, real_mean = real_data.min(), real_data.max(), real_data.mean()\n",
        "    \n",
        "    print(f\"  Train range: [{train_min:.4f}, {train_max:.4f}] | mean: {train_mean:.4f}\")\n",
        "    print(f\"  Valid range: [{valid_min:.4f}, {valid_max:.4f}] | mean: {valid_mean:.4f}\")\n",
        "    print(f\"  Real range: [{real_min:.4f}, {real_max:.4f}] | mean: {real_mean:.4f}\")\n",
        "\n",
        "def test_non_parametric_preprocessing(train_data, valid_data, real_data, train_init, valid_init, real_init):\n",
        "    \"\"\"\n",
        "    Test non-parametric preprocessing with initial value verification\n",
        "    \"\"\"\n",
        "    assert train_data is not None and valid_data is not None and real_data is not None, \\\n",
        "        \"Preprocessing failed: train, valid, or real data is None\"\n",
        "    assert train_init is not None and valid_init is not None and real_init is not None, \\\n",
        "        \"Initial values are None\"\n",
        "\n",
        "    print(f\"\\nNon-Parametric Preprocessing successful!\")\n",
        "\n",
        "    shape_labels = {\n",
        "        'train': \"(R_train, l)\",\n",
        "        'valid': \"(R_valid, l)\",\n",
        "        'real': \"(R_real, l)\",\n",
        "        'sequence_length': train_data.shape[1],\n",
        "        'total_samples': train_data.shape[0] + valid_data.shape[0] + real_data.shape[0],\n",
        "    }\n",
        "    print_data_shapes(train_data, valid_data, real_data, shape_labels)\n",
        "    print_channel_statistics(train_data, valid_data, real_data)\n",
        "\n",
        "    scaler = LogReturnTransformation()\n",
        "    \n",
        "    reconstructed_train = scaler.inverse_transform(train_data[0], train_init[0])\n",
        "    reconstructed_valid = scaler.inverse_transform(valid_data[0], valid_init[0])\n",
        "\n",
        "    assert torch.isclose(reconstructed_train[0], train_init[0]), \"Train initial value reconstruction failed\"\n",
        "    assert torch.isclose(reconstructed_valid[0], valid_init[0]), \"Valid initial value reconstruction failed\"\n",
        "    \n",
        "    print(\"Initial value unit tests passed for non-parametric dataset.\")\n",
        "\n",
        "def test_dataset_shuffling_preserves_initial_values(data, initial_values, seed=42):\n",
        "    \"\"\"\n",
        "    Test that shuffling in TimeSeriesDataset preserves initial value positions correctly.\n",
        "    \n",
        "    Args:\n",
        "        data: Array of shape (R, l)\n",
        "        initial_values: Array of shape (R,)\n",
        "        seed: Random seed for shuffling\n",
        "    \"\"\"\n",
        "    dataset_shuffled = TimeSeriesDataset(data, shuffle=True, seed=seed, initial_values=initial_values)\n",
        "    dataset_unshuffled = TimeSeriesDataset(data, shuffle=False, seed=seed, initial_values=initial_values)\n",
        "    \n",
        "    indices = dataset_shuffled.get_original_indices()\n",
        "    \n",
        "    for i in range(min(10, len(dataset_shuffled))):\n",
        "        sample_shuffled, init_shuffled = dataset_shuffled[i]\n",
        "        actual_idx = indices[i]\n",
        "        \n",
        "        sample_original, init_original = dataset_unshuffled[actual_idx]\n",
        "        init_original = initial_values[actual_idx]\n",
        "        \n",
        "        assert torch.allclose(sample_shuffled, sample_original), \\\n",
        "            f\"Sample mismatch at position {i}: shuffled index {actual_idx}\"\n",
        "        assert torch.isclose(init_shuffled, init_original), \\\n",
        "            f\"Initial value mismatch at position {i}: shuffled index {actual_idx}\"\n",
        "    \n",
        "    print(f\"  ✓ Shuffling preserves initial value positions (tested {min(10, len(dataset_shuffled))} samples)\")\n",
        "\n",
        "def test_dataloader_batching_preserves_initial_values(data, initial_values, batch_size=32, seed=42):\n",
        "    \"\"\"\n",
        "    Test that DataLoader batching preserves initial value positions correctly.\n",
        "    \n",
        "    Args:\n",
        "        data: Array of shape (R, l)\n",
        "        initial_values: Array of shape (R,)\n",
        "        batch_size: Batch size for DataLoader\n",
        "        seed: Random seed for shuffling\n",
        "    \"\"\"\n",
        "    train_loader, _, _ = create_dataloaders(\n",
        "        data, data, data,\n",
        "        batch_size=batch_size,\n",
        "        train_seed=seed,\n",
        "        train_initial=initial_values,\n",
        "        valid_initial=initial_values,\n",
        "        test_initial=initial_values\n",
        "    )\n",
        "    \n",
        "    dataset_unshuffled = TimeSeriesDataset(data, shuffle=False, initial_values=initial_values)\n",
        "    shuffled_indices = train_loader.dataset.get_original_indices()\n",
        "    \n",
        "    batch_count = 0\n",
        "    total_samples_checked = 0\n",
        "    \n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        if batch_idx >= 3:\n",
        "            break\n",
        "        \n",
        "        batch_data, batch_initial = batch\n",
        "        \n",
        "        for i in range(batch_data.shape[0]):\n",
        "            position_in_dataset = batch_idx * batch_size + i\n",
        "            if position_in_dataset >= len(data):\n",
        "                break\n",
        "            \n",
        "            actual_original_idx = shuffled_indices[position_in_dataset]\n",
        "            sample_original, init_original = dataset_unshuffled[actual_original_idx]\n",
        "            \n",
        "            assert torch.allclose(batch_data[i], sample_original), \\\n",
        "                f\"Batch {batch_idx}, sample {i}: data mismatch (position {position_in_dataset} -> original idx {actual_original_idx})\"\n",
        "            assert torch.isclose(batch_initial[i], init_original), \\\n",
        "                f\"Batch {batch_idx}, sample {i}: initial value mismatch (position {position_in_dataset} -> original idx {actual_original_idx})\"\n",
        "            \n",
        "            total_samples_checked += 1\n",
        "        \n",
        "        batch_count += 1\n",
        "    \n",
        "    print(f\"  ✓ DataLoader batching preserves initial value positions (tested {batch_count} batches, {total_samples_checked} samples)\")\n",
        "\n",
        "def test_dataloader_reconstruction_with_initial_values(data, initial_values, batch_size=32, seed=42):\n",
        "    \"\"\"\n",
        "    Test that we can reconstruct prices from log returns using initial values from DataLoader batches.\n",
        "    \n",
        "    Args:\n",
        "        data: Log returns array of shape (R, l)\n",
        "        initial_values: Initial prices array of shape (R,)\n",
        "        batch_size: Batch size for DataLoader\n",
        "        seed: Random seed for shuffling\n",
        "    \"\"\"\n",
        "    train_loader, _, _ = create_dataloaders(\n",
        "        data, data, data,\n",
        "        batch_size=batch_size,\n",
        "        train_seed=seed,\n",
        "        train_initial=initial_values,\n",
        "        valid_initial=initial_values,\n",
        "        test_initial=initial_values\n",
        "    )\n",
        "    \n",
        "    scaler = LogReturnTransformation()\n",
        "    batch_count = 0\n",
        "    \n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        if batch_idx >= 2:\n",
        "            break\n",
        "        \n",
        "        batch_data, batch_initial = batch\n",
        "        \n",
        "        for i in range(min(5, batch_data.shape[0])):\n",
        "            log_returns = batch_data[i]\n",
        "            init_price = batch_initial[i]\n",
        "            \n",
        "            reconstructed = scaler.inverse_transform(log_returns, init_price)\n",
        "            \n",
        "            assert torch.isclose(reconstructed[0], init_price), \\\n",
        "                f\"Batch {batch_idx}, sample {i}: reconstruction failed\"\n",
        "        \n",
        "        batch_count += 1\n",
        "    \n",
        "    print(f\"  ✓ Price reconstruction from DataLoader batches works correctly (tested {batch_count} batches)\")\n",
        "\n",
        "def test_parametric_preprocessing(train_data, valid_data, real_data, train_init, valid_init, real_init):\n",
        "    \"\"\"\n",
        "    Test parametric preprocessing with initial value verification\n",
        "    \"\"\"\n",
        "    assert train_data is not None and valid_data is not None and real_data is not None, \\\n",
        "        \"Preprocessing failed: train, valid, or real data is None\"\n",
        "    assert train_init is not None and valid_init is not None and real_init is not None, \\\n",
        "        \"Initial values are None\"\n",
        "\n",
        "    print(f\"\\nParametric Preprocessing successful!\")\n",
        "\n",
        "    shape_labels = {\n",
        "        'train': \"(R_train,)\",\n",
        "        'valid': \"(R_valid,)\",\n",
        "        'real': \"(R_real,)\",\n",
        "        'sequence_length': train_data.shape[0],\n",
        "        'total_samples': train_data.shape[0] + valid_data.shape[0] + real_data.shape[0],\n",
        "    }\n",
        "    print_data_shapes(train_data, valid_data, real_data, shape_labels)\n",
        "    print_channel_statistics(train_data, valid_data, real_data)\n",
        "\n",
        "    scaler = LogReturnTransformation()\n",
        "    \n",
        "    reconstructed_train = scaler.inverse_transform(train_data, train_init)\n",
        "    reconstructed_valid = scaler.inverse_transform(valid_data, valid_init)\n",
        "    \n",
        "    assert torch.isclose(reconstructed_train[0], train_init), \"Train initial value reconstruction failed\"\n",
        "    assert torch.isclose(reconstructed_valid[0], valid_init), \"Valid initial value reconstruction failed\"\n",
        "\n",
        "    print(\"Initial value unit tests passed for parametric dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "EXAMPLE 1: Preprocessing for both parametric and non-parametric models\n",
            "============================================================\n",
            "Configuration Dataset: {'ticker': 'AAPL', 'original_data_path': '/Users/eddisonpham/Projects/Unified-benchmark-for-SDGFTS/data/raw/AAPL/AAPL.csv', 'valid_ratio': 0.1, 'test_ratio': 0.1}\n",
            "\n",
            "Starting preprocessing for non-parametric...\n",
            "====================\n",
            "Preprocessing data for AAPL\n",
            "Desired time series sample length (lag with max PACF >0): 103\n",
            "PACF at that lag: 0.040741497942971425\n",
            "\n",
            "Non-Parametric Preprocessing successful!\n",
            "Data shapes:\n",
            "  Train shape: torch.Size([8975, 103]) (R_train, l)\n",
            "  Valid shape: torch.Size([1122, 103]) (R_valid, l)\n",
            "  Real shape: torch.Size([1122, 103]) (R_real, l)\n",
            "  Sequence length (l): 103\n",
            "  Total time-series samples (R): 11219\n",
            "\n",
            "Log return statistics:\n",
            "  Train range: [-0.7312, 0.2869] | mean: 0.0006\n",
            "  Valid range: [-0.1377, 0.1132] | mean: 0.0014\n",
            "  Real range: [-0.0970, 0.1426] | mean: 0.0005\n",
            "Initial value unit tests passed for non-parametric dataset.\n",
            "\n",
            "============================================================\n",
            "Testing TimeSeriesDataset shuffling and DataLoader batching with initial values\n",
            "============================================================\n",
            "\n",
            "Test 1: Dataset shuffling preserves initial value positions\n",
            "  ✓ Shuffling preserves initial value positions (tested 10 samples)\n",
            "\n",
            "Test 2: DataLoader batching preserves initial value positions\n",
            "  ✓ DataLoader batching preserves initial value positions (tested 3 batches, 96 samples)\n",
            "\n",
            "Test 3: Price reconstruction from DataLoader batches\n",
            "  ✓ Price reconstruction from DataLoader batches works correctly (tested 2 batches)\n",
            "\n",
            "Configuration Dataset: {'ticker': 'AAPL', 'original_data_path': '/Users/eddisonpham/Projects/Unified-benchmark-for-SDGFTS/data/raw/AAPL/AAPL.csv', 'valid_ratio': 0.1, 'test_ratio': 0.1, 'is_parametric': True}\n",
            "\n",
            "Starting preprocessing for parametric...\n",
            "====================\n",
            "Preprocessing data for AAPL\n",
            "\n",
            "Parametric Preprocessing successful!\n",
            "Data shapes:\n",
            "  Train shape: torch.Size([9056]) (R_train,)\n",
            "  Valid shape: torch.Size([1132]) (R_valid,)\n",
            "  Real shape: torch.Size([1133]) (R_real,)\n",
            "  Sequence length (l): 9056\n",
            "  Total time-series samples (R): 11321\n",
            "\n",
            "Log return statistics:\n",
            "  Train range: [-0.7312, 0.2869] | mean: 0.0006\n",
            "  Valid range: [-0.1377, 0.1132] | mean: 0.0013\n",
            "  Real range: [-0.0970, 0.1426] | mean: 0.0007\n",
            "Initial value unit tests passed for parametric dataset.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"EXAMPLE 1: Preprocessing for both parametric and non-parametric models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "nonparametric_dataset_cfgs, parametric_dataset_cfgs = get_dataset_cfgs()\n",
        "\n",
        "print(f\"Configuration Dataset: {nonparametric_dataset_cfgs}\")\n",
        "print(\"\\nStarting preprocessing for non-parametric...\")\n",
        "train_data_np, valid_data_np, real_data_np, train_init_np, valid_init_np, real_init_np = preprocess_data(nonparametric_dataset_cfgs)\n",
        "\n",
        "test_non_parametric_preprocessing(train_data_np, valid_data_np, real_data_np, train_init_np, valid_init_np, real_init_np)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Testing TimeSeriesDataset shuffling and DataLoader batching with initial values\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(\"\\nTest 1: Dataset shuffling preserves initial value positions\")\n",
        "test_dataset_shuffling_preserves_initial_values(train_data_np, train_init_np, seed=42)\n",
        "\n",
        "print(\"\\nTest 2: DataLoader batching preserves initial value positions\")\n",
        "test_dataloader_batching_preserves_initial_values(train_data_np, train_init_np, batch_size=32, seed=42)\n",
        "\n",
        "print(\"\\nTest 3: Price reconstruction from DataLoader batches\")\n",
        "test_dataloader_reconstruction_with_initial_values(train_data_np, train_init_np, batch_size=32, seed=42)\n",
        "\n",
        "print(f\"\\nConfiguration Dataset: {parametric_dataset_cfgs}\")\n",
        "print(\"\\nStarting preprocessing for parametric...\")\n",
        "train_data_para, valid_data_para, real_data_para, train_init_para, valid_init_para, real_init_para = preprocess_data(parametric_dataset_cfgs)\n",
        "\n",
        "test_parametric_preprocessing(train_data_para, valid_data_para, real_data_para, train_init_para, valid_init_para, real_init_para)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: PyTorch Dataset and DataLoader Creation\n",
        "\n",
        "Now let's create PyTorch datasets and dataloaders to verify proper batching and seed support.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXAMPLE 2: PyTorch Dataset and DataLoader Creation\n",
            "============================================================\n",
            "Creating TimeSeriesDataset objects...\n",
            "Type of train_dataset: <class 'src.utils.preprocessing_utils.TimeSeriesDataset'>\n",
            "Created datasets:\n",
            "  Train dataset length: 8975\n",
            "  Valid dataset length: 1122\n",
            "  Real dataset length: 1122\n",
            "  Sample shape: torch.Size([103])\n",
            "  Sample dtype: torch.float32\n",
            "  Sample initial: 0.1283479928970337\n",
            "\n",
            "Creating DataLoaders...\n",
            "Created dataloaders:\n",
            "  Train batches: 281\n",
            "  Valid batches: 36\n",
            "  Real batches: 36\n",
            "  Batch size: 32\n",
            "\n",
            "Batch Information:\n",
            "Train Batch 1: shape torch.Size([32, 103]), dtype torch.float32\n",
            "  Value range: [-0.2624, 0.2127]\n",
            "  Initial values shape: torch.Size([32]), dtype: torch.float64\n",
            "Train Batch 2: shape torch.Size([32, 103]), dtype torch.float32\n",
            "  Value range: [-0.7312, 0.1735]\n",
            "  Initial values shape: torch.Size([32]), dtype: torch.float64\n",
            "Train Batch 3: shape torch.Size([32, 103]), dtype torch.float32\n",
            "  Value range: [-0.1390, 0.2127]\n",
            "  Initial values shape: torch.Size([32]), dtype: torch.float64\n",
            "... and 278 more batches\n",
            "\n",
            "Batch shapes are correct: torch.Size([32, 103]) == (32, 103)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXAMPLE 2: PyTorch Dataset and DataLoader Creation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Creating TimeSeriesDataset objects...\")\n",
        "train_dataset = TimeSeriesDataset(train_data_np, train_init_np, seed=42)\n",
        "valid_dataset = TimeSeriesDataset(valid_data_np, valid_init_np, seed=42)\n",
        "real_dataset = TimeSeriesDataset(real_data_np, real_init_np, seed=42)\n",
        "\n",
        "print(f\"Type of train_dataset: {type(train_dataset)}\")\n",
        "\n",
        "\n",
        "print(f\"Created datasets:\")\n",
        "print(f\"  Train dataset length: {len(train_dataset)}\")\n",
        "print(f\"  Valid dataset length: {len(valid_dataset)}\")\n",
        "print(f\"  Real dataset length: {len(real_dataset)}\")\n",
        "print(f\"  Sample shape: {train_dataset[0][0].shape}\")\n",
        "print(f\"  Sample dtype: {train_dataset[0][0].dtype}\")\n",
        "print(f\"  Sample initial: {train_dataset[0][1]}\")\n",
        "\n",
        "print(f\"\\nCreating DataLoaders...\")\n",
        "batch_size = 32\n",
        "train_loader, valid_loader, real_loader = create_dataloaders(\n",
        "    train_data_np, valid_data_np, real_data_np,\n",
        "    batch_size=batch_size,\n",
        "    train_seed=42,\n",
        "    valid_seed=42,\n",
        "    test_seed=42,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    train_initial=train_init_np,\n",
        "    valid_initial=valid_init_np,\n",
        "    test_initial=real_init_np\n",
        ")\n",
        "\n",
        "print(f\"Created dataloaders:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Valid batches: {len(valid_loader)}\")\n",
        "print(f\"  Real batches: {len(real_loader)}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "\n",
        "print(f\"\\nBatch Information:\")  \n",
        "for i, (batch, initial) in enumerate(train_loader):\n",
        "    print(f\"Train Batch {i+1}: shape {batch.shape}, dtype {batch.dtype}\")\n",
        "    batch_min = batch.min()\n",
        "    batch_max = batch.max()\n",
        "    print(f\"  Value range: [{batch_min:.4f}, {batch_max:.4f}]\")\n",
        "    print(f\"  Initial values shape: {initial.shape}, dtype: {initial.dtype}\")\n",
        "    if i >= 2:\n",
        "        print(f\"... and {len(train_loader) - 3} more batches\")\n",
        "        break\n",
        "\n",
        "first_batch, _ = next(iter(train_loader))\n",
        "expected_shape = (batch_size, train_data_np.shape[1])\n",
        "if first_batch.shape == expected_shape:\n",
        "    print(f\"\\nBatch shapes are correct: {first_batch.shape} == {expected_shape}\")\n",
        "else:\n",
        "    print(f\"\\nBatch shape mismatch: {first_batch.shape} != {expected_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Reproducible Training with Seed Control\n",
        "\n",
        "Let's verify that seeds produce reproducible and different shuffling patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXAMPLE 3: Reproducible Training with Seed Control\n",
            "============================================================\n",
            "Testing reproducibility with same seeds...\n",
            "Datasets with same seed produce identical order: True\n",
            "  First 10 indices (dataset1): [5060, 6335, 3381, 3940, 970, 2747, 7252, 1548, 7168, 6424]\n",
            "  First 10 indices (dataset2): [5060, 6335, 3381, 3940, 970, 2747, 7252, 1548, 7168, 6424]\n",
            "\n",
            "Testing different seeds produce different orders...\n",
            "Datasets with different seeds produce different order: True\n",
            "  First 10 indices (seed=42): [5060, 6335, 3381, 3940, 970, 2747, 7252, 1548, 7168, 6424]\n",
            "  First 10 indices (seed=123): [3478, 8063, 8893, 3825, 2071, 7416, 7652, 4861, 853, 2011]\n",
            "\n",
            "Testing dynamic seed changing...\n",
            "Seed change produces different order: True\n",
            "  Original (seed=42): [5060, 6335, 3381, 3940, 970, 2747, 7252, 1548, 7168, 6424]\n",
            "  New (seed=999):     [2037, 8148, 1176, 8367, 2838, 5121, 2555, 5939, 976, 6585]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXAMPLE 3: Reproducible Training with Seed Control\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Testing reproducibility with same seeds...\")\n",
        "dataset1 = TimeSeriesDataset(train_data_np, train_init_np, seed=42, shuffle=True)\n",
        "dataset2 = TimeSeriesDataset(train_data_np, train_init_np, seed=42, shuffle=True)\n",
        "\n",
        "indices1 = dataset1.get_original_indices()\n",
        "indices2 = dataset2.get_original_indices()\n",
        "\n",
        "print(f\"Datasets with same seed produce identical order: {indices1[:10] == indices2[:10]}\")\n",
        "print(f\"  First 10 indices (dataset1): {indices1[:10]}\")\n",
        "print(f\"  First 10 indices (dataset2): {indices2[:10]}\")\n",
        "\n",
        "print(f\"\\nTesting different seeds produce different orders...\")\n",
        "dataset3 = TimeSeriesDataset(train_data_np, train_init_np, seed=123, shuffle=True)\n",
        "indices3 = dataset3.get_original_indices()\n",
        "\n",
        "print(f\"Datasets with different seeds produce different order: {indices1[:10] != indices3[:10]}\")\n",
        "print(f\"  First 10 indices (seed=42): {indices1[:10]}\")\n",
        "print(f\"  First 10 indices (seed=123): {indices3[:10]}\")\n",
        "\n",
        "print(f\"\\nTesting dynamic seed changing...\")    \n",
        "original_indices = dataset1.get_original_indices()[:10]\n",
        "dataset1.set_seed(999)\n",
        "new_indices = dataset1.get_original_indices()[:10]\n",
        "\n",
        "print(f\"Seed change produces different order: {original_indices != new_indices}\")\n",
        "print(f\"  Original (seed=42): {original_indices}\")\n",
        "print(f\"  New (seed=999):     {new_indices}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
