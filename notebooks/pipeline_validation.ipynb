{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\__init__.py:44\u001b[39m\n\u001b[32m     41\u001b[39m     mlflow.mismatch._check_version_mismatch()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m IS_TRACING_SDK_ONLY:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     45\u001b[39m         artifacts,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     46\u001b[39m         client,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     47\u001b[39m         config,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     48\u001b[39m         data,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     49\u001b[39m         exceptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     50\u001b[39m         genai,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     51\u001b[39m         models,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     52\u001b[39m         projects,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     53\u001b[39m         tracking,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     54\u001b[39m     )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironment_variables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLFLOW_CONFIGURE_LOGGING\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\artifacts\\__init__.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MlflowException\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotos\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatabricks_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BAD_REQUEST, INVALID_PARAMETER_VALUE\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_store\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     _download_artifact_from_uri,\n\u001b[32m     17\u001b[39m     _get_root_uri_and_artifact_path,\n\u001b[32m     18\u001b[39m     add_databricks_profile_info_to_artifact_uri,\n\u001b[32m     19\u001b[39m     get_artifact_repository,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_artifacts\u001b[39m(\n\u001b[32m     24\u001b[39m     artifact_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     25\u001b[39m     run_id: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     tracking_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     29\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\tracking\\__init__.py:33\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_model_registry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     get_registry_uri,\n\u001b[32m     30\u001b[39m     set_registry_uri,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tracking_service\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_artifact_repo\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MlflowClient\n\u001b[32m     35\u001b[39m __all__ += [\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mget_registry_uri\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mset_registry_uri\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMlflowClient\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\tracking\\client.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     DatasetInput,\n\u001b[32m     29\u001b[39m     EvaluationDataset,\n\u001b[32m     30\u001b[39m     Experiment,\n\u001b[32m     31\u001b[39m     FileInfo,\n\u001b[32m     32\u001b[39m     LoggedModel,\n\u001b[32m     33\u001b[39m     LoggedModelInput,\n\u001b[32m     34\u001b[39m     LoggedModelOutput,\n\u001b[32m     35\u001b[39m     LoggedModelStatus,\n\u001b[32m     36\u001b[39m     Metric,\n\u001b[32m     37\u001b[39m     Param,\n\u001b[32m     38\u001b[39m     Run,\n\u001b[32m     39\u001b[39m     RunTag,\n\u001b[32m     40\u001b[39m     Span,\n\u001b[32m     41\u001b[39m     SpanStatus,\n\u001b[32m     42\u001b[39m     SpanType,\n\u001b[32m     43\u001b[39m     Trace,\n\u001b[32m     44\u001b[39m     ViewType,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_registry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelVersion, Prompt, PromptVersion, RegisteredModel\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_registry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_version_stages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALL_STAGES\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\entities\\__init__.py:131\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mEvaluationDataset\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationDataset\n\u001b[32m    133\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m EvaluationDataset\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    135\u001b[39m         \u001b[38;5;66;03m# EvaluationDataset requires mlflow.data which may not be available\u001b[39;00m\n\u001b[32m    136\u001b[39m         \u001b[38;5;66;03m# in minimal installations like mlflow-tracing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\entities\\evaluation_dataset.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation_dataset_source\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationDatasetSource\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyfunc_dataset_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyFuncConvertibleDatasetMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\data\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m suppress\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_registry\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sources \u001b[38;5;28;01mas\u001b[39;00m mlflow_data_sources\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\data\\dataset_registry.py:145\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# use contextlib suppress to ignore import errors\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_pandas\n\u001b[32m    147\u001b[39m     _dataset_registry.register_constructor(from_pandas)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\mlflow\\data\\pandas_dataset.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_source\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetSource\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\pandas\\__init__.py:61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     63\u001b[39m     ArrowDtype,\n\u001b[32m     64\u001b[39m     Int8Dtype,\n\u001b[32m     65\u001b[39m     Int16Dtype,\n\u001b[32m     66\u001b[39m     Int32Dtype,\n\u001b[32m     67\u001b[39m     Int64Dtype,\n\u001b[32m     68\u001b[39m     UInt8Dtype,\n\u001b[32m     69\u001b[39m     UInt16Dtype,\n\u001b[32m     70\u001b[39m     UInt32Dtype,\n\u001b[32m     71\u001b[39m     UInt64Dtype,\n\u001b[32m     72\u001b[39m     Float32Dtype,\n\u001b[32m     73\u001b[39m     Float64Dtype,\n\u001b[32m     74\u001b[39m     CategoricalDtype,\n\u001b[32m     75\u001b[39m     PeriodDtype,\n\u001b[32m     76\u001b[39m     IntervalDtype,\n\u001b[32m     77\u001b[39m     DatetimeTZDtype,\n\u001b[32m     78\u001b[39m     StringDtype,\n\u001b[32m     79\u001b[39m     BooleanDtype,\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     81\u001b[39m     NA,\n\u001b[32m     82\u001b[39m     isna,\n\u001b[32m     83\u001b[39m     isnull,\n\u001b[32m     84\u001b[39m     notna,\n\u001b[32m     85\u001b[39m     notnull,\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     87\u001b[39m     Index,\n\u001b[32m     88\u001b[39m     CategoricalIndex,\n\u001b[32m     89\u001b[39m     RangeIndex,\n\u001b[32m     90\u001b[39m     MultiIndex,\n\u001b[32m     91\u001b[39m     IntervalIndex,\n\u001b[32m     92\u001b[39m     TimedeltaIndex,\n\u001b[32m     93\u001b[39m     DatetimeIndex,\n\u001b[32m     94\u001b[39m     PeriodIndex,\n\u001b[32m     95\u001b[39m     IndexSlice,\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     97\u001b[39m     NaT,\n\u001b[32m     98\u001b[39m     Period,\n\u001b[32m     99\u001b[39m     period_range,\n\u001b[32m    100\u001b[39m     Timedelta,\n\u001b[32m    101\u001b[39m     timedelta_range,\n\u001b[32m    102\u001b[39m     Timestamp,\n\u001b[32m    103\u001b[39m     date_range,\n\u001b[32m    104\u001b[39m     bdate_range,\n\u001b[32m    105\u001b[39m     Interval,\n\u001b[32m    106\u001b[39m     interval_range,\n\u001b[32m    107\u001b[39m     DateOffset,\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    109\u001b[39m     to_numeric,\n\u001b[32m    110\u001b[39m     to_datetime,\n\u001b[32m    111\u001b[39m     to_timedelta,\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    113\u001b[39m     Flags,\n\u001b[32m    114\u001b[39m     Grouper,\n\u001b[32m    115\u001b[39m     factorize,\n\u001b[32m    116\u001b[39m     unique,\n\u001b[32m    117\u001b[39m     value_counts,\n\u001b[32m    118\u001b[39m     NamedAgg,\n\u001b[32m    119\u001b[39m     array,\n\u001b[32m    120\u001b[39m     Categorical,\n\u001b[32m    121\u001b[39m     set_eng_float_format,\n\u001b[32m    122\u001b[39m     Series,\n\u001b[32m    123\u001b[39m     DataFrame,\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\pandas\\core\\api.py:47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flags\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     Grouper,\n\u001b[32m     49\u001b[39m     NamedAgg,\n\u001b[32m     50\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     52\u001b[39m     CategoricalIndex,\n\u001b[32m     53\u001b[39m     DatetimeIndex,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     TimedeltaIndex,\n\u001b[32m     60\u001b[39m )\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     bdate_range,\n\u001b[32m     63\u001b[39m     date_range,\n\u001b[32m     64\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\pandas\\core\\groupby\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DataFrameGroupBy,\n\u001b[32m      3\u001b[39m     NamedAgg,\n\u001b[32m      4\u001b[39m     SeriesGroupBy,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupBy\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrouper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grouper\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:68\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     61\u001b[39m     GroupByApply,\n\u001b[32m     62\u001b[39m     maybe_mangle_lambdas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     warn_alias_replacement,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcom\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     70\u001b[39m     base,\n\u001b[32m     71\u001b[39m     ops,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     GroupBy,\n\u001b[32m     75\u001b[39m     GroupByPlot,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m     _transform_template,\n\u001b[32m     80\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\pandas\\core\\frame.py:153\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    149\u001b[39m     ensure_wrapped_if_datetimelike,\n\u001b[32m    150\u001b[39m     sanitize_array,\n\u001b[32m    151\u001b[39m     sanitize_masked_array,\n\u001b[32m    152\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    154\u001b[39m     NDFrame,\n\u001b[32m    155\u001b[39m     make_doc,\n\u001b[32m    156\u001b[39m )\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_key_length\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    159\u001b[39m     DatetimeIndex,\n\u001b[32m    160\u001b[39m     Index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m     ensure_index_from_sequences,\n\u001b[32m    165\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\.env\\Lib\\site-packages\\pandas\\core\\generic.py:196\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_docs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _shared_docs\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msorting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_indexer_indexer\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwindow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    197\u001b[39m     Expanding,\n\u001b[32m    198\u001b[39m     ExponentialMovingWindow,\n\u001b[32m    199\u001b[39m     Rolling,\n\u001b[32m    200\u001b[39m     Window,\n\u001b[32m    201\u001b[39m )\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    204\u001b[39m     DataFrameFormatter,\n\u001b[32m    205\u001b[39m     DataFrameRenderer,\n\u001b[32m    206\u001b[39m )\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprinting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pprint_thing\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1532\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1506\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1624\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:161\u001b[39m, in \u001b[36m_path_isfile\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:153\u001b[39m, in \u001b[36m_path_is_mode_type\u001b[39m\u001b[34m(path, mode)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "import yaml\n",
    "from abc import ABC, abstractmethod\n",
    "import inspect\n",
    "\n",
    "project_root = Path().resolve().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.models.base.base_model import ParametricModel, DeepLearningModel\n",
    "from src.models.parametric.gbm import GeometricBrownianMotion\n",
    "from src.models.parametric.ou_process import OrnsteinUhlenbeckProcess\n",
    "from src.models.parametric.merton_jump_diffusion import MertonJumpDiffusion\n",
    "from src.models.parametric.garch11 import GARCH11\n",
    "from src.models.parametric.de_jump_diffusion import DoubleExponentialJumpDiffusion\n",
    "from src.models.parametric.block_bootstrap import BlockBootstrap\n",
    "from src.models.non_parametric.time_gan import TimeGAN\n",
    "from src.models.non_parametric.quant_gan import QuantGAN\n",
    "\n",
    "from src.utils.display_utils import show_with_start_divider, show_with_end_divider\n",
    "from src.utils.preprocessing_utils import create_dataloaders, preprocess_data, LogReturnTransformation\n",
    "from src.utils.configs_utils import get_dataset_cfgs\n",
    "from src.utils.evaluation_classes_utils import (\n",
    "    TaxonomyEvaluator,\n",
    "    DiversityEvaluator,\n",
    "    FidelityEvaluator,\n",
    "    RuntimeEvaluator,\n",
    "    StylizedFactsEvaluator,\n",
    "    VisualAssessmentEvaluator\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedEvaluator:\n",
    "    \"\"\"\n",
    "    Unified evaluator class to initialize the MLFlow experiment and evaluate the models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        experiment_name: str,\n",
    "        nonparametric_dataset_cfgs: Dict[str, Any],\n",
    "        parametric_dataset_cfgs: Dict[str, Any]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator with MLFlow experiment.\n",
    "        \n",
    "        Args:\n",
    "            experiment_name (str): Name of the MLFlow experiment\n",
    "            nonparametric_dataset_cfgs (Dict[str, Any]): Configuration for non-parametric dataset\n",
    "            parametric_dataset_cfgs (Dict[str, Any]): Configuration for parametric dataset\n",
    "        \"\"\"\n",
    "        self.nonparametric_dataset_cfgs = nonparametric_dataset_cfgs\n",
    "        self.parametric_dataset_cfgs = parametric_dataset_cfgs\n",
    "\n",
    "        self.experiment_name = experiment_name\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        \n",
    "        self.results = {}\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.results_dir = project_root / \"results\" / f\"evaluation_{self.timestamp}\"\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def evaluate_model(\n",
    "        self,\n",
    "        model,\n",
    "        model_name: str,\n",
    "        real_data: np.ndarray,\n",
    "        train_data,\n",
    "        num_samples: int = 500,\n",
    "        generation_kwargs: Dict[str, Any] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Unified evaluation for both parametric and non-parametric models.\n",
    "\n",
    "        Args:\n",
    "            model: The type of generative model to evaluate\n",
    "            model_name: Name of the model for logging\n",
    "            real_data: Real data for comparison\n",
    "            train_data: Training data\n",
    "            generation_kwargs: Optional kwargs for model.generate() (e.g., linear_timestamps, output_length)\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing all evaluation metrics\n",
    "        \"\"\"\n",
    "        show_with_start_divider(f\"Evaluating {model_name}\")\n",
    "        generation_kwargs = generation_kwargs or {}\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_{self.timestamp}\"):\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "            mlflow.log_param(\n",
    "                \"model_type\",\n",
    "                \"parametric\" if isinstance(model, ParametricModel) else \"non_parametric\"\n",
    "            )\n",
    "\n",
    "            evaluation_results: Dict[str, Any] = {}\n",
    "\n",
    "            print(f\"Training {model_name}...\")\n",
    "            model.fit(train_data)\n",
    "            print(f\"Training {model_name} completed!\")\n",
    "\n",
    "            print(f\"\\nGenerating {num_samples} samples...\")\n",
    "            runtime_evaluator = RuntimeEvaluator(\n",
    "                generate_func=lambda n, **kwargs: model.generate(n, **generation_kwargs),\n",
    "                num_samples=num_samples,\n",
    "                generation_kwargs=generation_kwargs\n",
    "            )\n",
    "            runtime_results = runtime_evaluator.evaluate()\n",
    "            mlflow.log_metric(\n",
    "                f\"generation_time_{num_samples}_samples\",\n",
    "                runtime_results[f\"generation_time_{num_samples}_samples\"]\n",
    "            )\n",
    "            evaluation_results.update(runtime_results)\n",
    "\n",
    "            generated_data = model.generate(num_samples, **generation_kwargs)\n",
    "\n",
    "            if \"torch\" in str(type(generated_data)):\n",
    "                generated_data = generated_data.detach().cpu().numpy()\n",
    "            if \"torch\" in str(type(real_data)):\n",
    "                real_data = real_data.detach().cpu().numpy()\n",
    "            else:\n",
    "                real_data = np.asarray(real_data)\n",
    "\n",
    "            if real_data.ndim == 2:\n",
    "                l, N = real_data.shape\n",
    "                B = generated_data.shape[1]\n",
    "                if l >= B:\n",
    "                    num_windows = l - B + 1\n",
    "                    real_data_3d = np.lib.stride_tricks.sliding_window_view(real_data, (B, N), axis=(0, 1)).squeeze()\n",
    "                    idx = np.arange(real_data_3d.shape[0])\n",
    "                    np.random.shuffle(idx)\n",
    "                    real_data_3d = real_data_3d[idx]\n",
    "                    A_real = min(num_windows, num_samples)\n",
    "                    real_data = real_data_3d[:A_real]\n",
    "                else:\n",
    "                    real_data = real_data[np.newaxis, :, :]\n",
    "\n",
    "            print(f\"Generated data shape: {generated_data.shape}\")\n",
    "            print(f\"Real data shape: {real_data.shape}\")\n",
    "\n",
    "            evaluators = [\n",
    "                FidelityEvaluator(real_data, generated_data),\n",
    "                DiversityEvaluator(real_data, generated_data),\n",
    "                StylizedFactsEvaluator(real_data, generated_data),\n",
    "                VisualAssessmentEvaluator(real_data, generated_data, self.results_dir, self.timestamp)\n",
    "            ]\n",
    "\n",
    "            for evaluator in evaluators:\n",
    "                print(f\"Computing {evaluator.__class__.__name__}...\")\n",
    "                results = evaluator.evaluate(model_name) if isinstance(evaluator, VisualAssessmentEvaluator) else evaluator.evaluate()\n",
    "                \n",
    "                if results:\n",
    "                    evaluation_results.update(results)\n",
    "                    for metric_name, metric_score in results.items():\n",
    "                        if isinstance(metric_score, (int, float)):\n",
    "                            mlflow.log_metric(metric_name, metric_score)\n",
    "                            continue\n",
    "\n",
    "                        if isinstance(metric_score, (np.ndarray, list)):\n",
    "                            channel_scores = np.array(metric_score)\n",
    "                            mlflow.log_metric(f\"{metric_name}_mean\", float(np.mean(channel_scores)))\n",
    "                            mlflow.log_metric(f\"{metric_name}_std\", float(np.std(channel_scores)))\n",
    "\n",
    "            self.results[model_name] = evaluation_results\n",
    "\n",
    "            results_path = self.results_dir / f\"metrics_{model_name}.json\"\n",
    "            with open(results_path, 'w') as f:\n",
    "                json.dump(evaluation_results, f, indent=2, default=str)\n",
    "            mlflow.log_artifact(str(results_path))\n",
    "\n",
    "            print(f\"Evaluation completed for {model_name}!\")\n",
    "\n",
    "    \n",
    "    def run_complete_evaluation(self, num_samples: int = 500, seed: int = 42) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run complete evaluation on all models with 500 generated samples per model.\n",
    "        \n",
    "        Args:\n",
    "            dataset_config: Configuration for data preprocessing\n",
    "            models_config: Configuration for models\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing results for all models\n",
    "        \"\"\"\n",
    "        show_with_start_divider(\"Starting Complete Evaluation Pipeline\")\n",
    "        \n",
    "        print(\"  Preprocessing data for non-parametric models...\")\n",
    "        train_data_np, valid_data_np, _ = preprocess_data(self.nonparametric_dataset_cfgs)\n",
    "        train_data_para, valid_data_para, _ = preprocess_data(self.parametric_dataset_cfgs)\n",
    "        \n",
    "        batch_size = 32\n",
    "        train_loader, valid_loader, _ = create_dataloaders(\n",
    "            train_data_np, valid_data_np, _,\n",
    "            batch_size=batch_size,\n",
    "            train_seed=seed,\n",
    "            valid_seed=seed,\n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        num_samples_real, length, num_channels = train_data_np.shape\n",
    "        print(f\"  - Non-parametric data shape: {train_data_np.shape}\")\n",
    "        print(f\"  - Parametric data shape: {train_data_para.shape}\")\n",
    "        \n",
    "        models = {}\n",
    "        \n",
    "        models[\"GBM\"] = GeometricBrownianMotion(length=length, num_channels=num_channels)\n",
    "        models[\"OU_Process\"] = OrnsteinUhlenbeckProcess(length=length, num_channels=num_channels)\n",
    "        models[\"MJD\"] = MertonJumpDiffusion(length=length, num_channels=num_channels)\n",
    "        models[\"GARCH11\"] = GARCH11()\n",
    "        models[\"DEJD\"] = DoubleExponentialJumpDiffusion(length=length, num_channels=num_channels)\n",
    "        models[\"BlockBootstrap\"] = BlockBootstrap(length=length, num_channels=num_channels)\n",
    "\n",
    "        models[\"TimeGAN\"] = TimeGAN(\n",
    "            seq_length=length,\n",
    "            num_features=num_channels,\n",
    "            embedding_dim=64,\n",
    "            hidden_dim=128,\n",
    "            num_layers=2,\n",
    "            batch_size=32,\n",
    "            learning_rate=2e-4\n",
    "        )\n",
    "\n",
    "        models[\"QuantGAN\"] = QuantGAN(\n",
    "            seq_length=length,\n",
    "            num_features=num_channels,\n",
    "            embedding_dim=64,\n",
    "            hidden_dim=128,\n",
    "            num_layers=2,\n",
    "            batch_size=32,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            learning_rate=2e-4\n",
    "        )\n",
    "        \n",
    "        all_results = {}\n",
    "        for model_name, model in models.items():\n",
    "            try:\n",
    "                is_parametric = isinstance(model, ParametricModel)\n",
    "                \n",
    "                results = self.evaluate_model(\n",
    "                    model=model,\n",
    "                    model_name=model_name,\n",
    "                    real_data=valid_data_para if is_parametric else valid_data_np,\n",
    "                    train_data=train_data_para if is_parametric else train_loader,\n",
    "                    num_samples=num_samples,\n",
    "                    generation_kwargs={'output_length': length, 'seed': seed} if is_parametric else {}\n",
    "                )\n",
    "                all_results[model_name] = results\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating {model_name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                all_results[model_name] = {\"error\": str(e)}\n",
    "        \n",
    "        results_file = self.results_dir / \"complete_evaluation.json\"\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2, default=str)\n",
    "        mlflow.log_artifact(str(results_file))\n",
    "        \n",
    "        show_with_end_divider(\"EVALUATION COMPLETE\")\n",
    "        print(f\"Results saved to: {results_file}\")\n",
    "        print(f\"MLFlow experiment: {self.experiment_name}\")\n",
    "        \n",
    "        return all_results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the evaluation pipeline.\"\"\"\n",
    "    nonparametric_dataset_cfgs, parametric_dataset_cfgs = get_dataset_cfgs()\n",
    "    evaluator = UnifiedEvaluator(\n",
    "        experiment_name=\"TimeSeries_Generation_Comprehensive_Evaluation\",\n",
    "        nonparametric_dataset_cfgs = nonparametric_dataset_cfgs,\n",
    "        parametric_dataset_cfgs = parametric_dataset_cfgs\n",
    "    )\n",
    "    evaluator.run_complete_evaluation(num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Starting Complete Evaluation Pipeline\n",
      "  Preprocessing data for non-parametric models...\n",
      "====================\n",
      "Data preprocessing with settings:{'ticker': 'AAPL', 'original_data_path': 'C:\\\\Users\\\\14165\\\\Downloads\\\\Unified-benchmark-for-SDGFTS-main\\\\data\\\\raw\\\\AAPL\\\\AAPL.csv', 'valid_ratio': 0.15, 'do_transformation': True, 'seed': 42}\n",
      "Data shape: (11182, 125, 4)\n",
      "Preprocessing for non-parametric models done.\n",
      "====================\n",
      "\n",
      "====================\n",
      "Data preprocessing with settings:{'ticker': 'AAPL', 'original_data_path': 'C:\\\\Users\\\\14165\\\\Downloads\\\\Unified-benchmark-for-SDGFTS-main\\\\data\\\\raw\\\\AAPL\\\\AAPL.csv', 'valid_ratio': 0.15, 'is_parametric': True, 'do_transformation': True, 'seed': 42}\n",
      "Data shape: (11306, 4)\n",
      "Preprocessing for parametric models done.\n",
      "====================\n",
      "\n",
      "  - Non-parametric data shape: (9504, 125, 4)\n",
      "  - Parametric data shape: torch.Size([9610, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Evaluating GBM\n",
      "Training GBM...\n",
      "Training GBM completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1000, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for GBM!\n",
      "====================\n",
      "Evaluating OU_Process\n",
      "Training OU_Process...\n",
      "Training OU_Process completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1000, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for OU_Process!\n",
      "====================\n",
      "Evaluating Merton_Jump_Diffusion\n",
      "Training Merton_Jump_Diffusion...\n",
      "Training Merton_Jump_Diffusion completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1000, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for Merton_Jump_Diffusion!\n",
      "====================\n",
      "Evaluating GARCH11\n",
      "Training GARCH11...\n",
      "Channel 1/4 fitted: omega=4.004300e-04, alpha=0.000000e+00, beta=4.962628e-01\n",
      "Channel 2/4 fitted: omega=1.272315e-05, alpha=2.044159e-07, beta=9.795868e-01\n",
      "Channel 3/4 fitted: omega=3.696761e-04, alpha=0.000000e+00, beta=4.980727e-01\n",
      "Channel 4/4 fitted: omega=3.992134e-04, alpha=1.377828e-13, beta=4.992905e-01\n",
      "Training GARCH11 completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1000, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for GARCH11!\n",
      "====================\n",
      "Evaluating Double_Exponential_Jump_Diffusion\n",
      "Training Double_Exponential_Jump_Diffusion...\n",
      "Training Double_Exponential_Jump_Diffusion completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1000, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for Double_Exponential_Jump_Diffusion!\n",
      "====================\n",
      "Evaluating BlockBootstrap\n",
      "Training BlockBootstrap...\n",
      "Training BlockBootstrap completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1000, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for BlockBootstrap!\n",
      "====================\n",
      "Evaluating TimeGAN\n",
      "Training TimeGAN...\n",
      "Epoch 1/10, Avg Loss: 1.3827\n",
      "Epoch 2/10, Avg Loss: 1.6596\n",
      "Epoch 3/10, Avg Loss: 1.5457\n",
      "Epoch 4/10, Avg Loss: 2.3600\n",
      "Epoch 5/10, Avg Loss: 1.4958\n",
      "Epoch 6/10, Avg Loss: 1.7897\n",
      "Epoch 7/10, Avg Loss: 1.4508\n",
      "Epoch 8/10, Avg Loss: 1.3840\n",
      "Epoch 9/10, Avg Loss: 1.3934\n",
      "Epoch 10/10, Avg Loss: 1.3874\n",
      "Training TimeGAN completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1678, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for TimeGAN!\n",
      "====================\n",
      "Evaluating QuantGAN\n",
      "Training QuantGAN...\n",
      "Epoch 1/10, Avg Loss: 1.3722\n",
      "Epoch 2/10, Avg Loss: 1.3858\n",
      "Epoch 3/10, Avg Loss: 1.3864\n",
      "Epoch 4/10, Avg Loss: 1.3871\n",
      "Epoch 5/10, Avg Loss: 1.3865\n",
      "Epoch 6/10, Avg Loss: 1.3864\n",
      "Epoch 7/10, Avg Loss: 1.3862\n",
      "Epoch 8/10, Avg Loss: 1.3863\n",
      "Epoch 9/10, Avg Loss: 1.3864\n",
      "Epoch 10/10, Avg Loss: 1.3864\n",
      "Training QuantGAN completed!\n",
      "\n",
      "Generating 1000 samples...\n",
      "Generated data shape: (1000, 125, 4)\n",
      "Real data shape: (1678, 125, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for QuantGAN!\n",
      "EVALUATION COMPLETE\n",
      "====================\n",
      "\n",
      "Results saved to: C:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\results\\evaluation_20251022_225247\\complete_evaluation.json\n",
      "MLFlow experiment: TimeSeries_Generation_Comprehensive_Evaluation\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
