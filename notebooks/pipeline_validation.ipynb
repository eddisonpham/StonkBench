{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "import yaml\n",
    "from abc import ABC, abstractmethod\n",
    "import inspect\n",
    "\n",
    "project_root = Path().resolve().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.models.base.base_model import ParametricModel, DeepLearningModel\n",
    "from src.models.parametric.gbm import GeometricBrownianMotion\n",
    "from src.models.parametric.ou_process import OUProcess\n",
    "from src.models.parametric.merton_jump_diffusion import MertonJumpDiffusion\n",
    "from src.models.parametric.garch11 import GARCH11\n",
    "from src.models.parametric.de_jump_diffusion import DoubleExponentialJumpDiffusion\n",
    "from src.models.non_parametric.block_bootstrap import BlockBootstrap\n",
    "from src.models.non_parametric.time_gan import TimeGAN\n",
    "from src.models.non_parametric.quant_gan import QuantGAN\n",
    "from src.models.non_parametric.time_vae import TimeVAE\n",
    "from src.models.non_parametric.takahashi import TakahashiDiffusion\n",
    "\n",
    "from src.utils.display_utils import show_with_start_divider, show_with_end_divider\n",
    "from src.utils.preprocessing_utils import create_dataloaders, preprocess_data, LogReturnTransformation\n",
    "from src.utils.configs_utils import get_dataset_cfgs\n",
    "from src.utils.evaluation_classes_utils import (\n",
    "    TaxonomyEvaluator,\n",
    "    DiversityEvaluator,\n",
    "    FidelityEvaluator,\n",
    "    RuntimeEvaluator,\n",
    "    StylizedFactsEvaluator,\n",
    "    VisualAssessmentEvaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedEvaluator:\n",
    "    \"\"\"\n",
    "    Unified evaluator class to initialize the MLFlow experiment and evaluate the models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        experiment_name: str,\n",
    "        parametric_dataset_cfgs: Dict[str, Any],\n",
    "        non_parametric_dataset_cfgs: Dict[str, Any]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator with MLFlow experiment.\n",
    "\n",
    "        Args:\n",
    "            experiment_name (str): Name of the MLFlow experiment\n",
    "            parametric_dataset_cfgs (Dict[str, Any]): Configuration for parametric dataset\n",
    "        \"\"\"\n",
    "        self.parametric_dataset_cfgs = parametric_dataset_cfgs\n",
    "        self.non_parametric_dataset_cfgs = non_parametric_dataset_cfgs\n",
    "        self.experiment_name = experiment_name\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "        self.results = {}\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.results_dir = project_root / \"results\" / f\"evaluation_{self.timestamp}\"\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def evaluate_model(\n",
    "        self,\n",
    "        model,\n",
    "        model_name: str,\n",
    "        real_data: np.ndarray,\n",
    "        train_data,\n",
    "        generation_kwargs: Dict[str, Any] = None,\n",
    "        fit_kwargs: Dict[str, Any] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Unified evaluation for both parametric.\n",
    "\n",
    "        Args:\n",
    "            model: The type of generative model to evaluate\n",
    "            model_name: Name of the model for logging\n",
    "            real_data: Real data for comparison\n",
    "            train_data: Training data\n",
    "            generation_kwargs: Optional kwargs for model.generate()\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing all evaluation metrics\n",
    "        \"\"\"\n",
    "        show_with_start_divider(f\"Evaluating {model_name}\")\n",
    "        generation_kwargs = generation_kwargs or {}\n",
    "        num_samples = generation_kwargs.get('num_samples', 500)\n",
    "        if fit_kwargs is not None:\n",
    "            num_epochs = fit_kwargs.get('num_epochs', 1)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_{self.timestamp}\"):\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "            evaluation_results: Dict[str, Any] = {}\n",
    "\n",
    "            print(f\"Training {model_name}...\")\n",
    "            if isinstance(model, DeepLearningModel):\n",
    "                model.fit(train_data, num_epochs=num_epochs)\n",
    "            else:\n",
    "                model.fit(train_data)\n",
    "\n",
    "            print(f\"\\nGenerating {num_samples} samples...\")\n",
    "            runtime_evaluator = RuntimeEvaluator(\n",
    "                generate_func=model.generate,\n",
    "                generation_kwargs=generation_kwargs\n",
    "            )\n",
    "            runtime_results = runtime_evaluator.evaluate()\n",
    "            mlflow.log_metric(\n",
    "                f\"generation_time_{num_samples}_samples\",\n",
    "                runtime_results[f\"generation_time_{num_samples}_samples\"]\n",
    "            )\n",
    "            evaluation_results.update(runtime_results)\n",
    "\n",
    "            generated_data = model.generate(**generation_kwargs)\n",
    "            print(f\"Generated data: {generated_data}\")\n",
    "\n",
    "            if \"torch\" in str(type(generated_data)):\n",
    "                generated_data = generated_data.detach().cpu().numpy()\n",
    "            if \"torch\" in str(type(real_data)):\n",
    "                real_data = real_data.detach().cpu().numpy()\n",
    "            else:\n",
    "                real_data = np.asarray(real_data)\n",
    "\n",
    "            if real_data.ndim == 2:\n",
    "                l, N = real_data.shape\n",
    "                B = generated_data.shape[1]\n",
    "                num_windows = l - B + 1\n",
    "                real_data_3d = np.lib.stride_tricks.sliding_window_view(real_data, (B, N), axis=(0, 1)).squeeze()\n",
    "            else:\n",
    "                real_data_3d = real_data\n",
    "\n",
    "            idx = np.arange(real_data_3d.shape[0])\n",
    "            np.random.shuffle(idx)\n",
    "            real_data_3d = real_data_3d[idx]\n",
    "            A_real = min(real_data_3d.shape[0], num_samples)\n",
    "            real_data = real_data_3d[:A_real]\n",
    "\n",
    "            print(f\"Generated data shape: {generated_data.shape}\")\n",
    "            print(f\"Real data shape: {real_data.shape}\")\n",
    "\n",
    "            model_dir = self.results_dir / model_name\n",
    "            model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            evaluators = [\n",
    "                FidelityEvaluator(real_data, generated_data),\n",
    "                DiversityEvaluator(real_data, generated_data),\n",
    "                StylizedFactsEvaluator(real_data, generated_data),\n",
    "                VisualAssessmentEvaluator(real_data, generated_data, model_dir)\n",
    "            ]\n",
    "\n",
    "            all_results = {}\n",
    "\n",
    "            for evaluator in evaluators:\n",
    "                print(f\"Computing {evaluator.__class__.__name__}...\")\n",
    "                results = evaluator.evaluate()\n",
    "                if results is not None:\n",
    "                    all_results.update(results)\n",
    "\n",
    "            metrics_path = model_dir / \"metrics.json\"\n",
    "            with open(metrics_path, 'w') as f:\n",
    "                json.dump(all_results, f, indent=2, default=str)\n",
    "\n",
    "            mlflow.log_artifact(str(metrics_path))\n",
    "            print(f\"Evaluation completed for {model_name} (results saved at {metrics_path}).\")\n",
    "\n",
    "            return all_results\n",
    "\n",
    "    def run_complete_evaluation(self, num_samples: int = 500, seed: int = 42) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run complete evaluation on all models with 500 generated samples per model.\n",
    "\n",
    "        Args:\n",
    "            dataset_config: Configuration for data preprocessing\n",
    "            models_config: Configuration for models\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing results for all models\n",
    "        \"\"\"\n",
    "        show_with_start_divider(\"Starting Complete Evaluation Pipeline\")\n",
    "        train_data_para, valid_data_para, test_data_para = preprocess_data(self.parametric_dataset_cfgs)\n",
    "\n",
    "        length_para, num_channels = train_data_para.shape\n",
    "        print(f\"  - Parametric train data shape: {train_data_para.shape}\")\n",
    "        print(f\"  - Parametric valid data shape: {valid_data_para.shape}\")\n",
    "        print(f\"  - Parametric test data shape: {test_data_para.shape}\")\n",
    "\n",
    "        train_data_non_para, valid_data_non_para, test_data_non_para = preprocess_data(self.non_parametric_dataset_cfgs)\n",
    "        train_loader_non_para, valid_loader_non_para, test_loader_non_para = create_dataloaders(\n",
    "            train_data_non_para, valid_data_non_para, test_data_non_para, batch_size=32, train_seed=42, valid_seed=42, test_seed=42)\n",
    "        \n",
    "\n",
    "        num_timeseries, generation_length, num_channels = train_data_non_para.shape\n",
    "        print(f\"  - Non-parametric train data shape: {train_data_non_para.shape}\")\n",
    "        print(f\"  - Non-parametric valid data shape: {valid_data_non_para.shape}\")\n",
    "        print(f\"  - Non-parametric test data shape: {test_data_non_para.shape}\")\n",
    "\n",
    "        parametric_models = {}\n",
    "        parametric_models[\"GBM\"] = GeometricBrownianMotion(length=length_para, num_channels=num_channels)\n",
    "        parametric_models[\"OU_Process\"] = OUProcess(length=length_para, num_channels=num_channels)\n",
    "        parametric_models[\"MJD\"] = MertonJumpDiffusion(length=length_para, num_channels=num_channels)\n",
    "        parametric_models[\"GARCH11\"] = GARCH11(length=length_para, num_channels=num_channels)\n",
    "        parametric_models[\"DEJD\"] = DoubleExponentialJumpDiffusion(length=length_para, num_channels=num_channels)\n",
    "        parametric_models[\"BlockBootstrap\"] = BlockBootstrap(block_size=generation_length)\n",
    "\n",
    "        non_parametric_models = {}\n",
    "        # non_parametric_models[\"TimeGAN\"] = TimeGAN(length=generation_length, num_channels=num_channels)\n",
    "        # non_parametric_models[\"QuantGAN\"] = QuantGAN(length=generation_length, num_channels=num_channels)\n",
    "        non_parametric_models[\"TimeVAE\"] = TimeVAE(length=generation_length, num_channels=num_channels)\n",
    "        non_parametric_models[\"Takahashi\"] = TakahashiDiffusion(length=generation_length, num_channels=num_channels, num_steps=200)\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        generation_kwargs_para = {'num_samples': num_samples, 'seq_length': generation_length, 'seed': 42}\n",
    "        for model_name, model in parametric_models.items():\n",
    "            results = self.evaluate_model(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                real_data=valid_data_para,\n",
    "                train_data=train_data_para,\n",
    "                generation_kwargs=generation_kwargs_para\n",
    "            )\n",
    "            all_results[model_name] = results\n",
    "\n",
    "        # Evaluate non-parametric models on non-parametric dataset (use DataLoader and num_epochs)\n",
    "        generation_kwargs_non_para = {'num_samples': num_samples, 'seq_length': generation_length, 'seed': 42}\n",
    "        fit_kwargs_non_para = {'num_epochs': 20}\n",
    "        for model_name, model in non_parametric_models.items():\n",
    "            results = self.evaluate_model(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                real_data=valid_data_non_para,\n",
    "                train_data=train_loader_non_para,\n",
    "                generation_kwargs=generation_kwargs_non_para,\n",
    "                fit_kwargs=fit_kwargs_non_para\n",
    "            )\n",
    "            all_results[model_name] = results\n",
    "\n",
    "        results_file = self.results_dir / \"complete_evaluation.json\"\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(all_results, f, indent=2, default=str)\n",
    "        mlflow.log_artifact(str(results_file))\n",
    "\n",
    "        show_with_end_divider(\"EVALUATION COMPLETE\")\n",
    "        print(f\"Results saved to: {results_file}\")\n",
    "        print(f\"MLFlow experiment: {self.experiment_name}\")\n",
    "\n",
    "        return all_results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the evaluation pipeline.\"\"\"\n",
    "    non_parametric_dataset_cfgs, parametric_dataset_cfgs = get_dataset_cfgs()\n",
    "    evaluator = UnifiedEvaluator(\n",
    "        experiment_name=\"TimeSeries_Generation_Comprehensive_Evaluation\",\n",
    "        parametric_dataset_cfgs = parametric_dataset_cfgs,\n",
    "        non_parametric_dataset_cfgs = non_parametric_dataset_cfgs\n",
    "    )\n",
    "    evaluator.run_complete_evaluation(num_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Starting Complete Evaluation Pipeline\n",
      "====================\n",
      "Preprocessing data for AAPL\n",
      "  - Parametric train data shape: torch.Size([9050, 4])\n",
      "  - Parametric valid data shape: torch.Size([1131, 4])\n",
      "  - Parametric test data shape: torch.Size([1132, 4])\n",
      "====================\n",
      "Preprocessing data for AAPL\n",
      "  - Non-parametric train data shape: (9040, 13, 4)\n",
      "  - Non-parametric valid data shape: (1130, 13, 4)\n",
      "  - Non-parametric test data shape: (1131, 13, 4)\n",
      "====================\n",
      "Evaluating GBM\n",
      "Training GBM...\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[ 5.8227e-02,  4.0393e-02,  2.6550e-02, -6.2565e-02],\n",
      "         [ 2.0887e-02, -3.2437e-02, -6.4474e-04, -4.7541e-02],\n",
      "         [-2.1898e-02,  4.4713e-02, -1.0713e-02, -4.1509e-02],\n",
      "         ...,\n",
      "         [-4.5987e-02,  2.7238e-02, -2.4754e-02, -1.7437e-02],\n",
      "         [-3.7511e-02,  5.7398e-02, -3.4980e-02, -1.4040e-02],\n",
      "         [-2.6734e-02, -1.7014e-02,  2.8444e-03,  1.6370e-02]],\n",
      "\n",
      "        [[-1.3998e-02,  3.2475e-02, -2.2859e-02, -2.1482e-02],\n",
      "         [-4.1372e-02,  1.5601e-03, -1.2328e-03,  2.0864e-02],\n",
      "         [-2.3285e-03,  4.9954e-02, -3.3536e-02,  4.2101e-02],\n",
      "         ...,\n",
      "         [-5.0914e-02, -2.1553e-02,  3.9055e-02,  1.5102e-02],\n",
      "         [-7.4459e-02,  1.3655e-02,  2.3204e-02,  1.4559e-03],\n",
      "         [ 1.9760e-02,  1.6203e-02,  3.1339e-02, -1.2907e-02]],\n",
      "\n",
      "        [[-4.9443e-03,  2.0739e-02,  1.2259e-02,  5.9502e-03],\n",
      "         [ 8.5196e-03,  3.4664e-02,  5.5846e-04, -8.5110e-03],\n",
      "         [-4.2980e-02, -2.1415e-03, -1.6668e-02,  1.4907e-02],\n",
      "         ...,\n",
      "         [-2.8494e-02,  2.6243e-02,  4.7253e-02,  4.4112e-02],\n",
      "         [ 8.6563e-03, -5.0325e-03, -2.0519e-02,  3.7253e-03],\n",
      "         [ 1.1027e-02,  2.6488e-02, -1.2822e-02,  4.8738e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.5769e-03,  7.7186e-03,  3.4599e-02,  3.7510e-02],\n",
      "         [-7.0100e-02, -7.8348e-04, -4.0887e-02,  5.0096e-04],\n",
      "         [-1.6554e-02,  2.1866e-03, -3.7190e-03,  2.0001e-02],\n",
      "         ...,\n",
      "         [-3.2223e-02, -1.8397e-03,  2.8017e-03, -3.3220e-02],\n",
      "         [-6.0413e-02, -2.0454e-02,  1.7364e-02, -2.6187e-02],\n",
      "         [ 1.8452e-03,  9.0342e-03, -2.1566e-02, -1.7907e-02]],\n",
      "\n",
      "        [[ 3.1849e-02,  6.5103e-03, -2.1187e-02,  8.1392e-03],\n",
      "         [-1.6092e-02,  1.5753e-03,  7.4751e-03,  1.0346e-02],\n",
      "         [ 2.5213e-02,  2.5092e-02, -3.3410e-02,  2.3991e-02],\n",
      "         ...,\n",
      "         [-3.4740e-02,  1.5024e-02, -3.9783e-03,  1.1101e-02],\n",
      "         [-5.4578e-02, -5.3425e-03, -1.1043e-02,  1.0387e-02],\n",
      "         [-4.3223e-02,  5.0062e-03, -5.3548e-02,  2.6440e-03]],\n",
      "\n",
      "        [[ 1.4864e-02,  9.9542e-03,  8.3130e-03,  2.0903e-02],\n",
      "         [ 8.6373e-02,  6.6887e-02,  1.8800e-03, -7.4825e-03],\n",
      "         [ 1.0899e-02, -8.6811e-03,  8.5669e-05,  3.4635e-03],\n",
      "         ...,\n",
      "         [ 7.8133e-03, -2.2776e-02,  4.1881e-02, -4.7739e-02],\n",
      "         [ 1.3296e-02, -3.0021e-02,  1.3947e-02,  2.6699e-02],\n",
      "         [-1.6702e-02,  7.1634e-03,  1.7760e-02,  1.5866e-02]]],\n",
      "       dtype=torch.float64)\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for GBM (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/GBM/metrics.json).\n",
      "====================\n",
      "Evaluating OU_Process\n",
      "Training OU_Process...\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[ 0.0582,  0.0401,  0.0264, -0.0625],\n",
      "         [-0.0291, -0.0016, -0.0246, -0.0180],\n",
      "         [-0.0734,  0.0350, -0.0188,  0.0108],\n",
      "         ...,\n",
      "         [ 0.0438,  0.0151, -0.0129,  0.0054],\n",
      "         [-0.0262, -0.0516,  0.0144,  0.0663],\n",
      "         [-0.0190, -0.0085, -0.0290, -0.0074]],\n",
      "\n",
      "        [[ 0.0209, -0.0322, -0.0006, -0.0475],\n",
      "         [ 0.0064,  0.0070, -0.0242,  0.0379],\n",
      "         [ 0.0016, -0.0018,  0.0296, -0.0222],\n",
      "         ...,\n",
      "         [ 0.0031, -0.0071,  0.0197, -0.0132],\n",
      "         [ 0.0056, -0.0209, -0.0357,  0.0670],\n",
      "         [ 0.0011, -0.0249, -0.0075, -0.0348]],\n",
      "\n",
      "        [[-0.0219,  0.0444, -0.0107, -0.0415],\n",
      "         [ 0.0044,  0.0219, -0.0376,  0.0177],\n",
      "         [-0.0681,  0.0094,  0.0086, -0.0357],\n",
      "         ...,\n",
      "         [ 0.0049, -0.0011, -0.0102,  0.0098],\n",
      "         [ 0.0198,  0.0123, -0.0195, -0.0034],\n",
      "         [ 0.0300,  0.0304, -0.0135, -0.0066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0015,  0.0075,  0.0143, -0.0440],\n",
      "         [-0.0213, -0.0136,  0.0030, -0.0148],\n",
      "         [ 0.0001,  0.0115,  0.0309,  0.0099],\n",
      "         ...,\n",
      "         [ 0.0297,  0.0673, -0.0071, -0.0225],\n",
      "         [-0.0037,  0.0675,  0.0119, -0.0436],\n",
      "         [ 0.0078, -0.0149,  0.0427, -0.0488]],\n",
      "\n",
      "        [[-0.0381,  0.0240,  0.0027,  0.0305],\n",
      "         [-0.0124,  0.0189, -0.0334,  0.0107],\n",
      "         [ 0.0354,  0.0431,  0.0301,  0.0013],\n",
      "         ...,\n",
      "         [ 0.0307, -0.0441, -0.0515, -0.0179],\n",
      "         [-0.0421, -0.0048, -0.0424, -0.0495],\n",
      "         [ 0.0133, -0.0304,  0.0100,  0.0255]],\n",
      "\n",
      "        [[ 0.0312, -0.0316,  0.0286,  0.0142],\n",
      "         [-0.0166,  0.0056,  0.0212,  0.0573],\n",
      "         [ 0.0483,  0.0041,  0.0195,  0.0021],\n",
      "         ...,\n",
      "         [-0.0470,  0.0150,  0.0017, -0.0089],\n",
      "         [ 0.0241,  0.0408,  0.0149,  0.0034],\n",
      "         [-0.0167,  0.0118,  0.0190,  0.0159]]])\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for OU_Process (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/OU_Process/metrics.json).\n",
      "====================\n",
      "Evaluating MJD\n",
      "Training MJD...\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: [[[ 1.32350959e-02 -3.39338795e-02  1.69941754e-02  2.35452307e-02]\n",
      "  [ 5.57926143e-04  2.17973739e-02 -1.53124839e-02 -3.34670431e-02]\n",
      "  [-5.50961236e-02 -4.14589520e-02 -2.20000024e-02  3.54059709e-02]\n",
      "  ...\n",
      "  [-4.33860956e-04 -2.92796193e-02 -1.84517040e-03  4.70128168e-02]\n",
      "  [-1.20356337e-02 -2.00182408e-02 -9.64391446e-05  4.90674399e-04]\n",
      "  [ 3.38449438e-02 -2.85012549e-02 -9.95523190e-03 -1.15323497e-02]]\n",
      "\n",
      " [[-3.08304603e-03  3.38608943e-02  8.30968603e-03 -1.79658540e-03]\n",
      "  [ 2.14853798e-02  1.69633749e-03  9.89072000e-03  2.91484417e-02]\n",
      "  [-6.74587662e-06  1.86363080e-02 -1.77530028e-02  4.49520696e-02]\n",
      "  ...\n",
      "  [-3.91855119e-03 -5.96936300e-03 -1.96246870e-02 -5.84856194e-03]\n",
      "  [ 2.07900361e-04  3.05427938e-02  5.42744703e-03 -3.01621930e-02]\n",
      "  [ 7.71510738e-03  1.75938450e-02  2.37662162e-02 -1.63485061e-03]]\n",
      "\n",
      " [[ 1.71149463e-02  3.54253058e-02 -1.34521530e-02 -2.36427763e-02]\n",
      "  [-3.78053436e-02 -1.27469189e-02 -4.77713862e-03 -1.67031127e-02]\n",
      "  [ 2.81257684e-02  1.79921715e-02 -5.39235016e-02  4.51221592e-02]\n",
      "  ...\n",
      "  [-2.24955918e-02  1.75788184e-02 -1.82346521e-02 -3.48528224e-03]\n",
      "  [ 2.09904426e-03  1.80495681e-02  3.87772600e-02  2.78699887e-03]\n",
      "  [ 1.81692165e-02  1.61805497e-02  1.28775747e-02  4.65489902e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.42129155e-03 -3.09750297e-02  3.00144650e-02  4.56455289e-03]\n",
      "  [ 6.55977958e-03  2.04365289e-03 -2.91060080e-02 -7.28889861e-04]\n",
      "  [-1.33032997e-02 -1.38590753e-03  5.07940584e-02  3.41983169e-02]\n",
      "  ...\n",
      "  [-2.54118291e-02  2.28849868e-03  1.13532335e-02 -2.38697639e-02]\n",
      "  [-2.12629727e-02 -4.60815278e-04 -1.70518546e-02  6.17633276e-02]\n",
      "  [ 4.46318927e-02 -1.81972610e-02  1.42197724e-02  4.25561130e-02]]\n",
      "\n",
      " [[-2.20321086e-02 -6.89883049e-03 -1.77542031e-02  1.46396309e-02]\n",
      "  [-1.12181346e-02  2.66792999e-03 -6.02667070e-03  2.80020207e-02]\n",
      "  [ 1.43481100e-02  3.12896966e-02  2.64946205e-02 -3.23223544e-02]\n",
      "  ...\n",
      "  [ 4.47663815e-02  4.55235342e-02 -3.16636639e-03  7.81749573e-03]\n",
      "  [-6.41448674e-03  8.92558305e-05 -1.18450321e-02  4.20240883e-02]\n",
      "  [ 7.38855436e-02  2.73705280e-02 -3.10965812e-02  2.23229277e-03]]\n",
      "\n",
      " [[-3.50660301e-02 -1.31161132e-02 -4.84051005e-02  2.29219198e-03]\n",
      "  [-2.01528753e-02 -1.57156320e-03  1.11810435e-02 -1.80309802e-02]\n",
      "  [-3.29154807e-02 -2.35105952e-02  6.29877729e-03 -1.47122721e-02]\n",
      "  ...\n",
      "  [-1.60621919e-02 -2.82539909e-02 -1.10830736e-02 -2.11646522e-02]\n",
      "  [-1.77445306e-02 -3.26094954e-02 -2.49377460e-02 -1.66751745e-03]\n",
      "  [ 3.26895672e-02  2.35849186e-02  1.99847760e-02  4.72077253e-02]]]\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for MJD (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/MJD/metrics.json).\n",
      "====================\n",
      "Evaluating GARCH11\n",
      "Training GARCH11...\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[ 0.0347, -0.0037, -0.0151, -0.0088],\n",
      "         [ 0.0267, -0.0270,  0.0258,  0.0145],\n",
      "         [ 0.0170,  0.0003, -0.0081,  0.0190],\n",
      "         ...,\n",
      "         [ 0.0264,  0.0130,  0.0094, -0.0229],\n",
      "         [ 0.0308, -0.0062, -0.0101,  0.0303],\n",
      "         [-0.0011,  0.0139, -0.0148,  0.0122]],\n",
      "\n",
      "        [[ 0.0271, -0.0199,  0.0101, -0.0202],\n",
      "         [ 0.0050,  0.0004, -0.0045, -0.0123],\n",
      "         [ 0.0068,  0.0258,  0.0107, -0.0179],\n",
      "         ...,\n",
      "         [-0.0003, -0.0158,  0.0112,  0.0103],\n",
      "         [ 0.0035, -0.0222,  0.0068, -0.0117],\n",
      "         [ 0.0094,  0.0025,  0.0329, -0.0120]],\n",
      "\n",
      "        [[ 0.0170,  0.0126,  0.0112, -0.0289],\n",
      "         [-0.0106, -0.0044,  0.0291,  0.0303],\n",
      "         [-0.0187, -0.0052, -0.0232,  0.0088],\n",
      "         ...,\n",
      "         [ 0.0211,  0.0185, -0.0177,  0.0040],\n",
      "         [-0.0081, -0.0359,  0.0025, -0.0156],\n",
      "         [-0.0051,  0.0110, -0.0089, -0.0277]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0204,  0.0026, -0.0006,  0.0264],\n",
      "         [ 0.0151,  0.0217,  0.0168,  0.0076],\n",
      "         [-0.0090,  0.0181, -0.0231, -0.0014],\n",
      "         ...,\n",
      "         [-0.0207, -0.0085,  0.0360,  0.0291],\n",
      "         [ 0.0223, -0.0370,  0.0195, -0.0061],\n",
      "         [ 0.0095,  0.0084,  0.0080,  0.0119]],\n",
      "\n",
      "        [[ 0.0099, -0.0035,  0.0130, -0.0077],\n",
      "         [-0.0049, -0.0075,  0.0162, -0.0158],\n",
      "         [-0.0104,  0.0143,  0.0102,  0.0064],\n",
      "         ...,\n",
      "         [ 0.0022, -0.0008,  0.0036, -0.0157],\n",
      "         [ 0.0106,  0.0051,  0.0019, -0.0221],\n",
      "         [-0.0330, -0.0028, -0.0140, -0.0021]],\n",
      "\n",
      "        [[ 0.0078,  0.0147,  0.0004,  0.0158],\n",
      "         [ 0.0119,  0.0010, -0.0170,  0.0194],\n",
      "         [-0.0062,  0.0003, -0.0132,  0.0152],\n",
      "         ...,\n",
      "         [ 0.0193, -0.0147, -0.0104, -0.0362],\n",
      "         [-0.0039, -0.0165,  0.0235, -0.0062],\n",
      "         [-0.0104, -0.0012,  0.0083, -0.0124]]])\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for GARCH11 (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/GARCH11/metrics.json).\n",
      "====================\n",
      "Evaluating DEJD\n",
      "Training DEJD...\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[ 3.6869e-02,  2.2091e-02,  1.5118e-02, -4.1669e-02],\n",
      "         [ 1.2046e-02,  8.6142e-03, -9.8863e-03, -7.8962e-03],\n",
      "         [ 2.2173e-02, -8.5672e-03, -1.4904e-02,  1.5262e-03],\n",
      "         ...,\n",
      "         [-2.3991e-02, -2.1531e-02,  1.0097e-02, -7.3254e-03],\n",
      "         [ 7.1747e-03, -8.5509e-03, -2.8718e-02, -1.5051e-02],\n",
      "         [ 3.4780e-02, -2.6838e-02,  1.5413e-04,  8.3459e-03]],\n",
      "\n",
      "        [[ 1.3300e-02, -1.8128e-02,  3.4313e-04, -3.1628e-02],\n",
      "         [ 4.2196e-03, -1.1121e-02, -9.8450e-03, -2.1125e-02],\n",
      "         [ 9.2233e-03,  7.2924e-03,  8.5072e-03,  4.3390e-04],\n",
      "         ...,\n",
      "         [ 1.4028e-02,  2.6095e-02, -2.8900e-02,  1.5533e-02],\n",
      "         [ 2.1782e-02,  8.1533e-03,  3.4774e-02,  4.6403e-02],\n",
      "         [ 1.5463e-02, -7.8983e-03,  6.0708e-04, -1.4652e-02]],\n",
      "\n",
      "        [[-1.3706e-02,  2.4476e-02, -5.1267e-03, -2.7597e-02],\n",
      "         [ 9.2377e-03,  8.1736e-03, -2.3690e-02,  1.4564e-02],\n",
      "         [-2.9580e-02,  2.8234e-02, -2.8653e-02,  3.7296e-02],\n",
      "         ...,\n",
      "         [ 9.0605e-03, -2.3090e-04,  9.6565e-03,  6.5498e-03],\n",
      "         [-3.0338e-01, -2.5708e-03,  4.5430e-03, -3.6386e-04],\n",
      "         [-3.9374e-02, -8.0085e-04,  2.0348e-02,  1.3334e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.1615e-04,  3.9351e-03,  8.4931e-03, -2.9307e-02],\n",
      "         [ 3.1975e-03,  2.4893e-03,  1.2323e-02, -3.5556e-02],\n",
      "         [ 2.8926e-02,  1.1328e-02,  8.8850e-03,  8.6120e-03],\n",
      "         ...,\n",
      "         [ 1.8876e-03,  4.7508e-03,  1.6905e-03, -3.3457e-02],\n",
      "         [ 1.9598e-02, -1.1515e-02,  3.5785e-03,  7.0078e-03],\n",
      "         [ 3.9251e-03, -1.6905e-02, -1.4346e-02,  1.3827e-02]],\n",
      "\n",
      "        [[-2.3916e-02,  1.3111e-02,  2.1611e-03,  2.0528e-02],\n",
      "         [-2.2048e-02, -6.9362e-04,  9.3191e-03,  1.2815e-03],\n",
      "         [ 1.0172e-02,  8.5892e-03, -1.7617e-02, -1.6387e-02],\n",
      "         ...,\n",
      "         [-8.1087e-03,  1.9586e-02, -8.8415e-03,  1.2222e-02],\n",
      "         [ 5.6925e-03, -1.5949e-02,  1.8654e-02,  2.7177e-02],\n",
      "         [ 5.6896e-04,  7.9475e-03, -7.2710e-03, -2.3735e-03]],\n",
      "\n",
      "        [[ 1.9820e-02, -1.7813e-02,  1.6272e-02,  9.6312e-03],\n",
      "         [-7.6664e-03, -5.0235e-03,  1.6260e-02,  2.4130e-02],\n",
      "         [-1.8013e-03, -1.0964e-02,  1.4233e-02, -3.4525e-02],\n",
      "         ...,\n",
      "         [-2.5300e-02, -9.8601e-03, -1.8687e-02,  8.2432e-03],\n",
      "         [ 7.5040e-03, -2.1375e-02, -1.5327e-02, -2.5999e-02],\n",
      "         [-2.9117e-02, -6.4337e-03,  5.3168e-03,  3.8829e-02]]])\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/src/models/parametric/de_jump_diffusion.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_returns = torch.tensor(log_returns, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for DEJD (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/DEJD/metrics.json).\n",
      "====================\n",
      "Evaluating BlockBootstrap\n",
      "Training BlockBootstrap...\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[ 1.0702e-02,  3.7046e-02, -2.8480e-02, -1.2395e-02],\n",
      "         [ 4.7317e-03, -2.2058e-02, -5.7947e-03,  2.7573e-02],\n",
      "         [-8.9035e-03, -1.1214e-02, -1.7167e-02, -2.5150e-03],\n",
      "         ...,\n",
      "         [-5.3985e-03, -2.3809e-02, -4.2283e-02, -3.6472e-02],\n",
      "         [ 2.5631e-02, -2.8513e-02, -1.4349e-02,  4.6482e-02],\n",
      "         [ 4.8734e-03, -1.2473e-02,  3.9847e-02, -1.8840e-01]],\n",
      "\n",
      "        [[ 2.0508e-02, -3.8502e-04,  2.1505e-02, -2.9313e-02],\n",
      "         [ 6.1593e-03, -7.7114e-04,  1.5830e-02, -9.1990e-03],\n",
      "         [ 1.5665e-02, -3.0735e-02,  4.6041e-02,  1.1485e-02],\n",
      "         ...,\n",
      "         [-2.6656e-02, -3.3403e-03,  7.1977e-02, -3.1814e-02],\n",
      "         [ 7.1778e-03,  1.0560e-03,  5.8440e-02,  4.6321e-02],\n",
      "         [-1.2142e-02,  1.2412e-02,  6.3450e-02,  4.1064e-03]],\n",
      "\n",
      "        [[ 2.4332e-02,  5.4265e-03, -1.0364e-02, -2.5316e-02],\n",
      "         [-2.4332e-02, -9.9094e-03,  1.5506e-02,  0.0000e+00],\n",
      "         [-1.6318e-02, -4.3608e-03, -1.0309e-02,  5.0007e-02],\n",
      "         ...,\n",
      "         [ 1.5383e-02, -4.1704e-03,  0.0000e+00, -2.2675e-02],\n",
      "         [ 2.7747e-03, -8.9779e-03,  4.8445e-03,  2.2675e-02],\n",
      "         [ 1.7834e-02, -7.6834e-03,  1.4388e-02,  2.6549e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.6149e-03, -9.1788e-03,  1.5404e-02, -7.5838e-02],\n",
      "         [ 4.2565e-02, -6.1987e-03,  3.0758e-02, -3.7045e-02],\n",
      "         [ 1.8348e-02, -3.4344e-03, -5.1691e-03,  3.7045e-02],\n",
      "         ...,\n",
      "         [ 3.5716e-02,  7.0417e-03, -1.6685e-02, -1.3244e-02],\n",
      "         [ 2.5974e-02, -6.4513e-03, -2.8553e-02, -4.7794e-02],\n",
      "         [ 0.0000e+00, -3.4511e-02, -1.2395e-02,  1.0434e-02]],\n",
      "\n",
      "        [[-1.2403e-02,  2.4660e-03,  4.3685e-04,  2.1713e-02],\n",
      "         [ 3.1096e-02, -2.5928e-02, -1.1205e-02,  1.7741e-02],\n",
      "         [-1.3256e-02, -1.3833e-02,  1.3243e-03, -3.2165e-02],\n",
      "         ...,\n",
      "         [ 1.8235e-02,  1.2166e-02,  6.5107e-04,  1.0776e-02],\n",
      "         [-3.7845e-03,  6.3554e-03,  9.2802e-03, -1.8390e-02],\n",
      "         [ 7.9612e-03,  3.6992e-02,  2.9006e-02, -8.3049e-02]],\n",
      "\n",
      "        [[-1.5037e-02, -7.1680e-03, -1.0702e-02,  2.5431e-02],\n",
      "         [-7.6042e-03,  1.7825e-02,  2.1987e-02,  7.6053e-03],\n",
      "         [-7.6623e-03, -3.5396e-03,  1.5415e-03,  2.5683e-02],\n",
      "         ...,\n",
      "         [-7.9046e-03,  6.8962e-03, -1.8422e-02,  1.6861e-04],\n",
      "         [ 1.5747e-02,  2.7119e-02, -3.1121e-02,  7.6403e-03],\n",
      "         [ 0.0000e+00, -4.4452e-02, -4.9580e-03,  3.1733e-03]]],\n",
      "       dtype=torch.float64)\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for BlockBootstrap (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/BlockBootstrap/metrics.json).\n",
      "====================\n",
      "Evaluating TimeVAE\n",
      "Training TimeVAE...\n",
      "TimeVAE Epoch 1/20 - Loss: 0.4876 | Recon Loss: 0.1607 | KL Loss: 0.0054\n",
      "TimeVAE Epoch 2/20 - Loss: 0.2781 | Recon Loss: 0.0927 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 3/20 - Loss: 0.2716 | Recon Loss: 0.0905 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 4/20 - Loss: 0.2679 | Recon Loss: 0.0893 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 5/20 - Loss: 0.2654 | Recon Loss: 0.0885 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 6/20 - Loss: 0.2641 | Recon Loss: 0.0880 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 7/20 - Loss: 0.2633 | Recon Loss: 0.0878 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 8/20 - Loss: 0.2628 | Recon Loss: 0.0876 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 9/20 - Loss: 0.2625 | Recon Loss: 0.0875 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 10/20 - Loss: 0.2621 | Recon Loss: 0.0874 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 11/20 - Loss: 0.2617 | Recon Loss: 0.0872 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 12/20 - Loss: 0.2615 | Recon Loss: 0.0872 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 13/20 - Loss: 0.2612 | Recon Loss: 0.0871 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 14/20 - Loss: 0.2610 | Recon Loss: 0.0870 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 15/20 - Loss: 0.2609 | Recon Loss: 0.0870 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 16/20 - Loss: 0.2609 | Recon Loss: 0.0870 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 17/20 - Loss: 0.2607 | Recon Loss: 0.0869 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 18/20 - Loss: 0.2606 | Recon Loss: 0.0869 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 19/20 - Loss: 0.2606 | Recon Loss: 0.0869 | KL Loss: 0.0000\n",
      "TimeVAE Epoch 20/20 - Loss: 0.2605 | Recon Loss: 0.0868 | KL Loss: 0.0000\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[0.0028, 0.0034, 0.0029, 0.0022],\n",
      "         [0.0023, 0.0029, 0.0032, 0.0037],\n",
      "         [0.0024, 0.0030, 0.0031, 0.0035],\n",
      "         ...,\n",
      "         [0.0025, 0.0031, 0.0030, 0.0031],\n",
      "         [0.0026, 0.0032, 0.0030, 0.0029],\n",
      "         [0.0022, 0.0016, 0.0035, 0.0033]],\n",
      "\n",
      "        [[0.0028, 0.0034, 0.0029, 0.0022],\n",
      "         [0.0023, 0.0029, 0.0032, 0.0037],\n",
      "         [0.0024, 0.0030, 0.0031, 0.0035],\n",
      "         ...,\n",
      "         [0.0025, 0.0031, 0.0030, 0.0031],\n",
      "         [0.0026, 0.0032, 0.0030, 0.0029],\n",
      "         [0.0022, 0.0016, 0.0035, 0.0033]],\n",
      "\n",
      "        [[0.0028, 0.0034, 0.0029, 0.0022],\n",
      "         [0.0023, 0.0029, 0.0032, 0.0037],\n",
      "         [0.0024, 0.0030, 0.0031, 0.0035],\n",
      "         ...,\n",
      "         [0.0025, 0.0031, 0.0030, 0.0031],\n",
      "         [0.0026, 0.0032, 0.0030, 0.0029],\n",
      "         [0.0022, 0.0016, 0.0035, 0.0033]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0028, 0.0034, 0.0029, 0.0022],\n",
      "         [0.0023, 0.0029, 0.0032, 0.0037],\n",
      "         [0.0024, 0.0030, 0.0031, 0.0035],\n",
      "         ...,\n",
      "         [0.0025, 0.0031, 0.0030, 0.0031],\n",
      "         [0.0026, 0.0032, 0.0030, 0.0029],\n",
      "         [0.0022, 0.0016, 0.0035, 0.0033]],\n",
      "\n",
      "        [[0.0028, 0.0034, 0.0029, 0.0022],\n",
      "         [0.0023, 0.0029, 0.0032, 0.0037],\n",
      "         [0.0024, 0.0030, 0.0031, 0.0035],\n",
      "         ...,\n",
      "         [0.0025, 0.0031, 0.0030, 0.0031],\n",
      "         [0.0026, 0.0032, 0.0030, 0.0029],\n",
      "         [0.0022, 0.0016, 0.0035, 0.0033]],\n",
      "\n",
      "        [[0.0028, 0.0034, 0.0029, 0.0022],\n",
      "         [0.0023, 0.0029, 0.0032, 0.0037],\n",
      "         [0.0024, 0.0030, 0.0031, 0.0035],\n",
      "         ...,\n",
      "         [0.0025, 0.0031, 0.0030, 0.0031],\n",
      "         [0.0026, 0.0032, 0.0030, 0.0029],\n",
      "         [0.0022, 0.0016, 0.0035, 0.0033]]])\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for TimeVAE (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/TimeVAE/metrics.json).\n",
      "====================\n",
      "Evaluating Takahashi\n",
      "Training Takahashi...\n",
      "TakahashiDiffusion epoch 1/20, Loss: 0.195127\n",
      "TakahashiDiffusion epoch 2/20, Loss: 0.046326\n",
      "TakahashiDiffusion epoch 3/20, Loss: 0.034612\n",
      "TakahashiDiffusion epoch 4/20, Loss: 0.030763\n",
      "TakahashiDiffusion epoch 5/20, Loss: 0.027511\n",
      "TakahashiDiffusion epoch 6/20, Loss: 0.025626\n",
      "TakahashiDiffusion epoch 7/20, Loss: 0.026913\n",
      "TakahashiDiffusion epoch 8/20, Loss: 0.025543\n",
      "TakahashiDiffusion epoch 9/20, Loss: 0.022782\n",
      "TakahashiDiffusion epoch 10/20, Loss: 0.023751\n",
      "TakahashiDiffusion epoch 11/20, Loss: 0.021801\n",
      "TakahashiDiffusion epoch 12/20, Loss: 0.022516\n",
      "TakahashiDiffusion epoch 13/20, Loss: 0.024276\n",
      "TakahashiDiffusion epoch 14/20, Loss: 0.022731\n",
      "TakahashiDiffusion epoch 15/20, Loss: 0.021073\n",
      "TakahashiDiffusion epoch 16/20, Loss: 0.020254\n",
      "TakahashiDiffusion epoch 17/20, Loss: 0.022106\n",
      "TakahashiDiffusion epoch 18/20, Loss: 0.020092\n",
      "TakahashiDiffusion epoch 19/20, Loss: 0.021304\n",
      "TakahashiDiffusion epoch 20/20, Loss: 0.021393\n",
      "\n",
      "Generating 500 samples...\n",
      "Generated data: tensor([[[ 1.2853,  0.7315,  0.2580,  1.7315],\n",
      "         [ 0.8018, -2.4411, -0.4830, -0.3937],\n",
      "         [-1.0456,  1.0510,  0.3681, -0.2782],\n",
      "         ...,\n",
      "         [-1.4673,  1.2559, -1.9654, -0.8007],\n",
      "         [-1.7770,  0.6671, -0.5541,  0.3792],\n",
      "         [ 0.7108,  0.1056,  2.4882, -0.0081]],\n",
      "\n",
      "        [[ 0.7027, -1.6814, -0.5082, -0.0363],\n",
      "         [ 1.2637,  0.2529,  1.8020,  0.1359],\n",
      "         [-0.7454,  1.8267,  0.5962,  0.0746],\n",
      "         ...,\n",
      "         [ 1.3624, -1.3817,  0.1679,  2.0395],\n",
      "         [-0.0755, -0.1851, -0.2726,  0.3374],\n",
      "         [ 0.3065,  0.7372, -0.1384, -2.2607]],\n",
      "\n",
      "        [[ 0.7541, -2.5311, -0.1622, -1.5711],\n",
      "         [ 0.5943,  0.4970, -0.8308,  0.6190],\n",
      "         [-0.7968,  1.1405,  0.4112, -0.2660],\n",
      "         ...,\n",
      "         [ 0.8569, -0.0651,  0.8101, -0.7657],\n",
      "         [ 0.4039,  0.8963,  1.2922, -1.1306],\n",
      "         [-0.7976,  0.4901, -0.9137, -1.6045]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8800, -2.1818, -2.1765,  1.4157],\n",
      "         [-0.8529, -1.4698,  0.4990, -0.8913],\n",
      "         [-0.8183, -1.2629, -1.0268,  0.3628],\n",
      "         ...,\n",
      "         [-0.7067,  1.5697, -1.6328,  0.9491],\n",
      "         [-1.1583,  1.8771, -2.0042, -2.1444],\n",
      "         [ 0.4228, -3.1822, -2.6789, -2.0036]],\n",
      "\n",
      "        [[ 1.3546,  3.1280, -0.2959,  1.4079],\n",
      "         [-0.1452, -0.2457, -0.3206,  0.1615],\n",
      "         [-0.9601, -1.0664,  4.0955, -2.1952],\n",
      "         ...,\n",
      "         [ 0.6508, -0.4969,  0.9084,  1.3726],\n",
      "         [-0.0788,  0.4892, -2.6401,  0.6599],\n",
      "         [-0.4597,  1.4836, -0.7405,  0.9881]],\n",
      "\n",
      "        [[-1.8271, -0.0562,  0.6959, -2.6832],\n",
      "         [-0.7451,  1.3782,  0.8607, -0.5075],\n",
      "         [-0.0793,  1.1999,  0.5305,  0.7122],\n",
      "         ...,\n",
      "         [ 2.3688,  1.4501,  0.4923, -2.2396],\n",
      "         [-0.1026,  0.2828,  1.2773,  1.1693],\n",
      "         [-1.1124,  0.5323, -0.7381, -1.0742]]])\n",
      "Generated data shape: (500, 13, 4)\n",
      "Real data shape: (500, 13, 4)\n",
      "Computing FidelityEvaluator...\n",
      "Computing DiversityEvaluator...\n",
      "Computing StylizedFactsEvaluator...\n",
      "Computing VisualAssessmentEvaluator...\n",
      "Evaluation completed for Takahashi (results saved at /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/Takahashi/metrics.json).\n",
      "EVALUATION COMPLETE\n",
      "====================\n",
      "\n",
      "Results saved to: /Users/uyenlamho/Documents/vscode/CSCD94F25/Unified-benchmark-for-SDGFTS/results/evaluation_20251031_114743/complete_evaluation.json\n",
      "MLFlow experiment: TimeSeries_Generation_Comprehensive_Evaluation\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
