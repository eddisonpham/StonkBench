{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Hedging Models Test\n",
        "\n",
        "This notebook tests the four deep hedging models on synthetic data generated from parametric models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "project_root = Path().resolve().parents[0]\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from src.models.parametric.gbm import GeometricBrownianMotion\n",
        "from src.models.parametric.ou_process import OUProcess\n",
        "from src.models.parametric.merton_jump_diffusion import MertonJumpDiffusion\n",
        "from src.models.parametric.garch11 import GARCH11\n",
        "from src.models.parametric.de_jump_diffusion import DoubleExponentialJumpDiffusion\n",
        "from src.models.non_parametric.block_bootstrap import BlockBootstrap\n",
        "\n",
        "from src.deep_hedgers.feedforward_layers import FeedforwardDeepHedger\n",
        "from src.deep_hedgers.feedforward_time import FeedforwardTimeDeepHedger\n",
        "from src.deep_hedgers.rnn_hedger import RNNDeepHedger\n",
        "from src.deep_hedgers.lstm_hedger import LSTMDeepHedger\n",
        "\n",
        "from src.utils.preprocessing_utils import preprocess_data\n",
        "from src.utils.configs_utils import get_dataset_cfgs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================\n",
            "Preprocessing data for AAPL\n",
            "====================\n",
            "Preprocessing data for AAPL\n",
            "Parametric train data shape: torch.Size([9044, 4])\n",
            "Parametric valid data shape: torch.Size([1131, 4])\n",
            "Non-parametric train data shape: (9035, 13, 4)\n",
            "Non-parametric valid data shape: (1129, 13, 4)\n"
          ]
        }
      ],
      "source": [
        "# Load configuration\n",
        "non_parametric_dataset_cfgs, parametric_dataset_cfgs = get_dataset_cfgs()\n",
        "\n",
        "# Preprocess real data for parametric models\n",
        "train_data_para, valid_data_para, test_data_para = preprocess_data(parametric_dataset_cfgs)\n",
        "\n",
        "# Preprocess real data for non-parametric models (block bootstrap)\n",
        "train_data_non_para, valid_data_non_para, test_data_non_para = preprocess_data(non_parametric_dataset_cfgs)\n",
        "\n",
        "print(f\"Parametric train data shape: {train_data_para.shape}\")\n",
        "print(f\"Parametric valid data shape: {valid_data_para.shape}\")\n",
        "print(f\"Non-parametric train data shape: {train_data_non_para.shape}\")\n",
        "print(f\"Non-parametric valid data shape: {valid_data_non_para.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_initial_prices_from_original_data(original_data_path, log_returns_windows, window_size, channel_idx=0):\n",
        "    \"\"\"\n",
        "    Extract initial prices for each window from original price data.\n",
        "    \n",
        "    Args:\n",
        "        original_data_path: Path to original CSV file with price data\n",
        "        log_returns_windows: Log returns windows of shape (R, L, N)\n",
        "        window_size: Size of each window (L)\n",
        "        channel_idx: Index of channel to extract (0 for Open)\n",
        "    \n",
        "    Returns:\n",
        "        Initial prices for each window, shape (R,)\n",
        "    \"\"\"\n",
        "    # Read original price data\n",
        "    df = pd.read_csv(original_data_path)\n",
        "    REQUIRED_COLUMNS = ['Open', 'High', 'Low', 'Close']\n",
        "    original_prices = df[REQUIRED_COLUMNS].values  # (T, N)\n",
        "    \n",
        "    # Extract the channel we need (Open channel)\n",
        "    prices_channel = original_prices[:, channel_idx]  # (T,)\n",
        "    \n",
        "    # Windows are created from log returns with step=1\n",
        "    # Window i: log_returns[i:i+L] corresponds to prices[i:i+L+1], initial = prices[i]\n",
        "    R = log_returns_windows.shape[0]\n",
        "    initial_prices = np.zeros(R)\n",
        "    \n",
        "    max_start_idx = len(prices_channel) - window_size - 1\n",
        "    \n",
        "    for i in range(R):\n",
        "        if i <= max_start_idx:\n",
        "            initial_prices[i] = prices_channel[i]\n",
        "        else:\n",
        "            initial_prices[i] = prices_channel[min(i, max_start_idx)] if max_start_idx >= 0 else prices_channel[0]\n",
        "    \n",
        "    return initial_prices\n",
        "\n",
        "def log_returns_to_prices(log_returns, original_data_path=None, initial_prices=None, channel_idx=0):\n",
        "    \"\"\"\n",
        "    Convert log returns to prices, using initial prices from original data.\n",
        "    \n",
        "    Args:\n",
        "        log_returns: Array of shape (R, L, N) or (L, N) of log returns\n",
        "        original_data_path: Path to original CSV file (optional, to extract initial prices)\n",
        "        initial_prices: Pre-computed initial prices, shape (R,) for 3D or scalar for 2D (optional)\n",
        "        channel_idx: Channel index to use (0 for Open)\n",
        "    \n",
        "    Returns:\n",
        "        prices: Array of same shape as log_returns but with prices\n",
        "    \"\"\"\n",
        "    if isinstance(log_returns, torch.Tensor):\n",
        "        log_returns_np = log_returns.cpu().numpy()\n",
        "        return_tensor = True\n",
        "    else:\n",
        "        log_returns_np = np.asarray(log_returns)\n",
        "        return_tensor = False\n",
        "    \n",
        "    if log_returns_np.ndim == 2:\n",
        "        # Single time series (L, N)\n",
        "        L, N = log_returns_np.shape\n",
        "        prices = np.zeros((L + 1, N))\n",
        "        \n",
        "        if initial_prices is not None:\n",
        "            initial_prices = np.asarray(initial_prices)\n",
        "            if initial_prices.ndim == 0 or initial_prices.shape == ():\n",
        "                prices[0] = initial_prices\n",
        "            elif initial_prices.shape == (N,):\n",
        "                prices[0] = initial_prices\n",
        "            else:\n",
        "                prices[0] = initial_prices[channel_idx] if channel_idx < len(initial_prices) else 1.0\n",
        "        elif original_data_path is not None:\n",
        "            # Get initial price from original data\n",
        "            df = pd.read_csv(original_data_path)\n",
        "            REQUIRED_COLUMNS = ['Open', 'High', 'Low', 'Close']\n",
        "            original_prices = df[REQUIRED_COLUMNS].values\n",
        "            prices[0] = original_prices[0, channel_idx] if len(original_prices) > 0 else 1.0\n",
        "        else:\n",
        "            prices[0] = 1.0\n",
        "        \n",
        "        for t in range(L):\n",
        "            prices[t + 1] = prices[t] * np.exp(log_returns_np[t])\n",
        "        prices = prices[1:]  # Remove initial price\n",
        "        \n",
        "    elif log_returns_np.ndim == 3:\n",
        "        # Multiple time series (R, L, N)\n",
        "        R, L, N = log_returns_np.shape\n",
        "        prices = np.zeros((R, L + 1, N))\n",
        "        \n",
        "        if initial_prices is not None:\n",
        "            initial_prices = np.asarray(initial_prices)\n",
        "            if initial_prices.shape == (R,):\n",
        "                # One initial price per sample\n",
        "                prices[:, 0, channel_idx] = initial_prices\n",
        "                # Use same initial price for all channels\n",
        "                for ch in range(N):\n",
        "                    if ch != channel_idx:\n",
        "                        prices[:, 0, ch] = initial_prices\n",
        "            elif initial_prices.shape == (R, N):\n",
        "                prices[:, 0] = initial_prices\n",
        "            else:\n",
        "                # Scalar initial price\n",
        "                prices[:, 0] = initial_prices\n",
        "        elif original_data_path is not None:\n",
        "            # Get initial prices from original data\n",
        "            initial_prices_array = get_initial_prices_from_original_data(\n",
        "                original_data_path, log_returns_np, L, channel_idx\n",
        "            )\n",
        "            prices[:, 0, channel_idx] = initial_prices_array\n",
        "            # Use same initial price for all channels\n",
        "            for ch in range(N):\n",
        "                if ch != channel_idx:\n",
        "                    prices[:, 0, ch] = initial_prices_array\n",
        "        else:\n",
        "            # Use default initial price of 1.0\n",
        "            prices[:, 0] = 1.0\n",
        "        \n",
        "        for t in range(L):\n",
        "            prices[:, t + 1] = prices[:, t] * np.exp(log_returns_np[:, t])\n",
        "        prices = prices[:, 1:]  # Remove initial price\n",
        "    else:\n",
        "        raise ValueError(f\"Expected 2D or 3D array, got {log_returns_np.ndim}D\")\n",
        "    \n",
        "    if return_tensor:\n",
        "        return torch.from_numpy(prices).float()\n",
        "    return prices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 500 samples of length 13...\n",
            "\n",
            "Fitting parametric models...\n",
            "Fitting GBM...\n",
            "Fitting OU Process...\n",
            "Fitting MJD...\n",
            "Fitting GARCH11...\n",
            "Fitting DEJD...\n",
            "\n",
            "Fitting Block Bootstrap...\n",
            "\n",
            "Generating synthetic data...\n",
            "Generating GBM...\n",
            "Generating OU Process...\n",
            "Generating MJD...\n",
            "Generating GARCH11...\n",
            "Generating DEJD...\n",
            "Generating Block Bootstrap...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\\src\\models\\parametric\\de_jump_diffusion.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  log_returns = torch.tensor(log_returns, device=self.device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Synthetic data generation complete!\n",
            "GBM: torch.Size([500, 13, 4])\n",
            "OU Process: torch.Size([500, 13, 4])\n",
            "MJD: torch.Size([500, 13, 4])\n",
            "GARCH11: torch.Size([500, 13, 4])\n",
            "DEJD: torch.Size([500, 13, 4])\n",
            "BlockBootstrap: torch.Size([500, 13, 4])\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic data from parametric models\n",
        "length_para, num_channels = train_data_para.shape\n",
        "generation_length = train_data_non_para.shape[1]  # L from non-parametric data\n",
        "num_samples = 500\n",
        "seed = 42\n",
        "\n",
        "print(f\"Generating {num_samples} samples of length {generation_length}...\")\n",
        "\n",
        "# Initialize parametric models\n",
        "parametric_models = {}\n",
        "parametric_models[\"GBM\"] = GeometricBrownianMotion(length=length_para, num_channels=num_channels)\n",
        "parametric_models[\"OU Process\"] = OUProcess(length=length_para, num_channels=num_channels)\n",
        "parametric_models[\"MJD\"] = MertonJumpDiffusion(length=length_para, num_channels=num_channels)\n",
        "parametric_models[\"GARCH11\"] = GARCH11(length=length_para, num_channels=num_channels)\n",
        "parametric_models[\"DEJD\"] = DoubleExponentialJumpDiffusion(length=length_para, num_channels=num_channels)\n",
        "\n",
        "# Initialize block bootstrap\n",
        "block_bootstrap = BlockBootstrap(block_size=generation_length)\n",
        "\n",
        "# Fit models\n",
        "print(\"\\nFitting parametric models...\")\n",
        "for name, model in parametric_models.items():\n",
        "    print(f\"Fitting {name}...\")\n",
        "    model.fit(train_data_para)\n",
        "\n",
        "# Fit block bootstrap\n",
        "print(\"\\nFitting Block Bootstrap...\")\n",
        "# Convert train_data_para to format expected by block bootstrap\n",
        "if isinstance(train_data_para, torch.Tensor):\n",
        "    block_bootstrap.fit(train_data_para)\n",
        "else:\n",
        "    block_bootstrap.fit(torch.from_numpy(train_data_para).float())\n",
        "\n",
        "# Generate synthetic data\n",
        "synthetic_data = {}\n",
        "generation_kwargs = {'num_samples': num_samples, 'seq_length': generation_length, 'seed': seed}\n",
        "\n",
        "print(\"\\nGenerating synthetic data...\")\n",
        "for name, model in parametric_models.items():\n",
        "    print(f\"Generating {name}...\")\n",
        "    syn_data = model.generate(**generation_kwargs)\n",
        "    if isinstance(syn_data, torch.Tensor):\n",
        "        synthetic_data[name] = syn_data\n",
        "    else:\n",
        "        synthetic_data[name] = torch.from_numpy(syn_data).float()\n",
        "\n",
        "# Generate block bootstrap data\n",
        "print(\"Generating Block Bootstrap...\")\n",
        "syn_data_bb = block_bootstrap.generate(**generation_kwargs)\n",
        "synthetic_data[\"BlockBootstrap\"] = syn_data_bb if isinstance(syn_data_bb, torch.Tensor) else torch.from_numpy(syn_data_bb).float()\n",
        "\n",
        "print(\"\\nSynthetic data generation complete!\")\n",
        "for name, data in synthetic_data.items():\n",
        "    print(f\"{name}: {data.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting log returns to prices...\n",
            "Mean initial price from real data: 4.4411\n",
            "GBM prices shape: (500, 13, 4)\n",
            "OU Process prices shape: (500, 13, 4)\n",
            "MJD prices shape: (500, 13, 4)\n",
            "GARCH11 prices shape: (500, 13, 4)\n",
            "DEJD prices shape: (500, 13, 4)\n",
            "BlockBootstrap prices shape: (500, 13, 4)\n",
            "Real prices shape: (1129, 13, 4)\n"
          ]
        }
      ],
      "source": [
        "# Convert log returns to prices for hedging\n",
        "# Extract open channel and convert to prices using initial prices from real data\n",
        "print(\"Converting log returns to prices...\")\n",
        "\n",
        "# Get original data path\n",
        "original_data_path = non_parametric_dataset_cfgs.get('original_data_path')\n",
        "\n",
        "# Real data prices (using validation set)\n",
        "real_log_returns = valid_data_non_para  # (R, L, N)\n",
        "if isinstance(real_log_returns, torch.Tensor):\n",
        "    real_log_returns = real_log_returns.cpu().numpy()\n",
        "real_prices = log_returns_to_prices(real_log_returns, original_data_path=original_data_path, channel_idx=0)\n",
        "\n",
        "# Get mean initial price from real data for synthetic data\n",
        "real_train_log_returns = train_data_non_para\n",
        "if isinstance(real_train_log_returns, torch.Tensor):\n",
        "    real_train_log_returns = real_train_log_returns.cpu().numpy()\n",
        "real_initial_prices = get_initial_prices_from_original_data(\n",
        "    original_data_path, real_train_log_returns, real_train_log_returns.shape[1], channel_idx=0\n",
        ")\n",
        "mean_initial_price = np.mean(real_initial_prices)\n",
        "print(f\"Mean initial price from real data: {mean_initial_price:.4f}\")\n",
        "\n",
        "# Synthetic data prices - use mean initial price from real data\n",
        "synthetic_prices = {}\n",
        "for name, syn_log_returns in synthetic_data.items():\n",
        "    # Convert to numpy if tensor\n",
        "    if isinstance(syn_log_returns, torch.Tensor):\n",
        "        syn_log_returns = syn_log_returns.cpu().numpy()\n",
        "    \n",
        "    # Use mean initial price for all synthetic samples\n",
        "    syn_prices = log_returns_to_prices(\n",
        "        syn_log_returns, \n",
        "        initial_prices=np.ones(syn_log_returns.shape[0]) * mean_initial_price,\n",
        "        channel_idx=0\n",
        "    )\n",
        "    synthetic_prices[name] = syn_prices\n",
        "    print(f\"{name} prices shape: {syn_prices.shape}\")\n",
        "\n",
        "print(f\"Real prices shape: {real_prices.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using strike price: 4.4411 (mean initial price)\n",
            "Deep hedging models initialized:\n",
            "  - Feedforward_L-1\n",
            "  - Feedforward_Time\n",
            "  - RNN\n",
            "  - LSTM\n"
          ]
        }
      ],
      "source": [
        "# Initialize deep hedging models\n",
        "seq_length = generation_length\n",
        "hidden_size = 64\n",
        "strike = mean_initial_price  # At-the-money call option (use mean initial price)\n",
        "\n",
        "print(f\"Using strike price: {strike:.4f} (mean initial price)\")\n",
        "\n",
        "hedgers = {\n",
        "    'Feedforward_L-1': FeedforwardDeepHedger(seq_length=seq_length, hidden_size=hidden_size, strike=strike),\n",
        "    'Feedforward_Time': FeedforwardTimeDeepHedger(seq_length=seq_length, hidden_size=hidden_size, strike=strike),\n",
        "    'RNN': RNNDeepHedger(seq_length=seq_length, hidden_size=hidden_size, strike=strike),\n",
        "    'LSTM': LSTMDeepHedger(seq_length=seq_length, hidden_size=hidden_size, strike=strike)\n",
        "}\n",
        "\n",
        "print(\"Deep hedging models initialized:\")\n",
        "for name in hedgers.keys():\n",
        "    print(f\"  - {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training deep hedgers on GBM synthetic data...\n",
            "Data shape: (500, 13, 4)\n",
            "Using open channel only (extracting first channel)\n",
            "\n",
            "============================================================\n",
            "Training Feedforward_L-1...\n",
            "============================================================\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhedger_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mhedger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43msyn_prices_open\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Evaluate on synthetic data\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhedger_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on synthetic data...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Unified-benchmark-for-SDGFTS-main\\src\\deep_hedgers\\base_hedger.py:174\u001b[39m, in \u001b[36mBaseDeepHedger.fit\u001b[39m\u001b[34m(self, data, num_epochs, batch_size, learning_rate, verbose)\u001b[39m\n\u001b[32m    171\u001b[39m optimizer.zero_grad()\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Forward pass: compute deltas\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m deltas = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_prices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m    177\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.compute_loss(batch_prices, deltas)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Unified-benchmark-for-SDGFTS-main\\src\\deep_hedgers\\feedforward_layers.py:70\u001b[39m, in \u001b[36mFeedforwardDeepHedger.forward\u001b[39m\u001b[34m(self, prices)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Process each time step's price independently\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Input: prices[:, :-1] shape (batch_size, L-1)\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Reshape to (batch_size * (L-1), 1)\u001b[39;00m\n\u001b[32m     69\u001b[39m input_prices = prices[:, :-\u001b[32m1\u001b[39m].unsqueeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch_size, L-1, 1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m input_flat = \u001b[43minput_prices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size * (L-1), 1)\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Forward through network: produces one delta per price\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Output shape: (batch_size * (L-1), 1)\u001b[39;00m\n\u001b[32m     74\u001b[39m output_flat = \u001b[38;5;28mself\u001b[39m.network(input_flat)\n",
            "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ],
      "source": [
        "# Train deep hedgers on synthetic data\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Test on GBM synthetic data\n",
        "test_model_name = 'GBM'\n",
        "syn_prices_test = synthetic_prices[test_model_name]\n",
        "\n",
        "print(f\"\\nTraining deep hedgers on {test_model_name} synthetic data...\")\n",
        "print(f\"Data shape: {syn_prices_test.shape}\")\n",
        "print(f\"Using open channel only (extracting first channel)\")\n",
        "\n",
        "# Extract open channel (index 0) and convert to torch tensors\n",
        "syn_prices_open = syn_prices_test[:, :, 0]  # (R, L)\n",
        "if isinstance(syn_prices_open, np.ndarray):\n",
        "    syn_prices_open = torch.from_numpy(syn_prices_open).float()\n",
        "elif isinstance(syn_prices_open, torch.Tensor):\n",
        "    syn_prices_open = syn_prices_open.float()\n",
        "\n",
        "real_prices_open = real_prices[:, :, 0]  # (R, L)\n",
        "if isinstance(real_prices_open, np.ndarray):\n",
        "    real_prices_open = torch.from_numpy(real_prices_open).float()\n",
        "elif isinstance(real_prices_open, torch.Tensor):\n",
        "    real_prices_open = real_prices_open.float()\n",
        "\n",
        "for hedger_name, hedger in hedgers.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {hedger_name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    hedger.fit(\n",
        "        syn_prices_open,\n",
        "        num_epochs=num_epochs,\n",
        "        batch_size=batch_size,\n",
        "        learning_rate=learning_rate,\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    # Evaluate on synthetic data\n",
        "    print(f\"\\nEvaluating {hedger_name} on synthetic data...\")\n",
        "    eval_results_syn = hedger.evaluate(syn_prices_open)\n",
        "    \n",
        "    # Evaluate on real data\n",
        "    print(f\"Evaluating {hedger_name} on real data...\")\n",
        "    eval_results_real = hedger.evaluate(real_prices_open)\n",
        "    \n",
        "    results[hedger_name] = {\n",
        "        'synthetic': eval_results_syn,\n",
        "        'real': eval_results_real\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{hedger_name} Results:\")\n",
        "    print(f\"  Synthetic - MSE: {eval_results_syn['mse_X']:.6f}, Mean X: {eval_results_syn['mean_X']:.6f}\")\n",
        "    print(f\"  Real - MSE: {eval_results_real['mse_X']:.6f}, Mean X: {eval_results_real['mean_X']:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display results summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DEEP HEDGING RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for hedger_name, result in results.items():\n",
        "    print(f\"\\n{hedger_name}:\")\n",
        "    print(f\"  Premium: {result['synthetic']['premium']:.6f}\")\n",
        "    print(f\"  Synthetic Data:\")\n",
        "    print(f\"    MSE(X): {result['synthetic']['mse_X']:.6f}\")\n",
        "    print(f\"    Mean(X): {result['synthetic']['mean_X']:.6f}\")\n",
        "    print(f\"    Std(X): {result['synthetic']['std_X']:.6f}\")\n",
        "    print(f\"  Real Data:\")\n",
        "    print(f\"    MSE(X): {result['real']['mse_X']:.6f}\")\n",
        "    print(f\"    Mean(X): {result['real']['mean_X']:.6f}\")\n",
        "    print(f\"    Std(X): {result['real']['std_X']:.6f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
