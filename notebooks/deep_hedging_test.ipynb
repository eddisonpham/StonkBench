{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Hedging Models Test - Utility-Based Evaluation\n",
    "\n",
    "This notebook tests the four deep hedging models on synthetic data using utility-based evaluation methods:\n",
    "\n",
    "1. **Augmented Testing**: Mix synthetic with real training data (50/50), train hedger, compare with real-only\n",
    "2. **Algorithm Comparison**: Train 4 hedgers on both real and synthetic data, evaluate on test sets\n",
    "\n",
    "Results are saved to the latest  directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddisonpham/Projects/Unified-benchmark-for-SDGFTS/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "project_root = Path().resolve().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.models.parametric.gbm import GeometricBrownianMotion\n",
    "from src.models.parametric.ou_process import OUProcess\n",
    "from src.models.parametric.merton_jump_diffusion import MertonJumpDiffusion\n",
    "from src.models.parametric.garch11 import GARCH11\n",
    "from src.models.parametric.de_jump_diffusion import DoubleExponentialJumpDiffusion\n",
    "from src.models.non_parametric.block_bootstrap import BlockBootstrap\n",
    "from src.models.non_parametric.time_vae import TimeVAE\n",
    "from src.models.non_parametric.quant_gan import QuantGAN\n",
    "from src.models.non_parametric.takahashi import TakahashiDiffusion\n",
    "\n",
    "from src.hedging_models.deep_hedgers.feedforward_layers import FeedforwardLayers\n",
    "from src.hedging_models.deep_hedgers.feedforward_time import FeedforwardTime\n",
    "from src.hedging_models.deep_hedgers.rnn_hedger import RNN\n",
    "from src.hedging_models.deep_hedgers.lstm_hedger import LSTM\n",
    "\n",
    "from src.hedging_models.non_deep_hedgers.black_scholes import BlackScholes\n",
    "from src.hedging_models.non_deep_hedgers.delta_gamma import DeltaGamma\n",
    "from src.hedging_models.non_deep_hedgers.linear_regression import LinearRegression\n",
    "from src.hedging_models.non_deep_hedgers.xgboost import XGBoost\n",
    "\n",
    "from src.utils.preprocessing_utils import preprocess_data, create_dataloaders\n",
    "from src.utils.configs_utils import get_dataset_cfgs\n",
    "from src.taxonomies.utility import (\n",
    "    AugmentedTestingEvaluator,\n",
    "    AlgorithmComparisonEvaluator\n",
    ")\n",
    "from src.utils.metric_plot_utils import find_latest_evaluation_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Preprocessing data for AAPL\n",
      "====================\n",
      "Preprocessing data for AAPL\n",
      "Desired time series sample length (lag with max PACF >0): 103\n",
      "PACF at that lag: 0.04074734125599129\n",
      "Real data shapes:\n",
      "  Train: torch.Size([8981, 103])\n",
      "  Val: torch.Size([1123, 103])\n",
      "  Test: torch.Size([1123, 103])\n",
      "Sequence length: 103\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "non_parametric_dataset_cfgs, parametric_dataset_cfgs = get_dataset_cfgs()\n",
    "\n",
    "train_data_para, valid_data_para, test_data_para, train_init_para, valid_init_para, test_init_para = preprocess_data(\n",
    "    parametric_dataset_cfgs\n",
    ")\n",
    "\n",
    "(\n",
    "    train_data_non_para,\n",
    "    valid_data_non_para,\n",
    "    test_data_non_para,\n",
    "    train_init_non_para,\n",
    "    valid_init_non_para,\n",
    "    test_init_non_para,\n",
    ") = preprocess_data(non_parametric_dataset_cfgs)\n",
    "\n",
    "# Get configuration\n",
    "original_data_path = non_parametric_dataset_cfgs.get(\"original_data_path\")\n",
    "seq_length = train_data_non_para.shape[1]\n",
    "\n",
    "print(f\"Real data shapes:\")\n",
    "print(f\"  Train: {train_data_non_para.shape}\")\n",
    "print(f\"  Val: {valid_data_non_para.shape}\")\n",
    "print(f\"  Test: {test_data_non_para.shape}\")\n",
    "print(f\"Sequence length: {seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 samples of length 103...\n",
      "Fitting parametric models...\n",
      "Fitting GBM...\n",
      "mu: 0.0005921594767344989, sigma: 0.029982834528274226\n",
      "Fitting DEJD...\n",
      "mu: 0.10447647009804578, sigma: 0.018963797049591412, lam: 0.10283570561624186, p: 0.5450643776824035, eta1: 15.493428897886261, eta2: 14.601712934992657, kappa: 1.0084483516750737\n",
      "Creating DataLoaders for non-parametric deep learning models...\n",
      "Fitting non-parametric deep learning models...\n",
      "Generating synthetic data from parametric models...\n",
      "Generating GBM...\n",
      "Generating DEJD...\n",
      "Generating synthetic data from non-parametric deep learning models...\n",
      "Synthetic data generation complete!\n",
      "GBM: torch.Size([10000, 103])\n",
      "DEJD: torch.Size([10000, 103])\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data for all models\n",
    "num_samples = 10000\n",
    "seed = 42\n",
    "generation_length = seq_length\n",
    "\n",
    "print(f\"Generating {num_samples} samples of length {generation_length}...\")\n",
    "\n",
    "# Initialize parametric models\n",
    "parametric_models = {}\n",
    "parametric_models[\"GBM\"] = GeometricBrownianMotion()\n",
    "# parametric_models[\"OU Process\"] = OUProcess()\n",
    "# parametric_models[\"MJD\"] = MertonJumpDiffusion()\n",
    "# parametric_models[\"GARCH11\"] = GARCH11()\n",
    "parametric_models[\"DEJD\"] = DoubleExponentialJumpDiffusion()\n",
    "\n",
    "block_bootstrap = BlockBootstrap(block_size=generation_length)\n",
    "\n",
    "# Fit parametric models\n",
    "print(\"Fitting parametric models...\")\n",
    "for name, model in parametric_models.items():\n",
    "    print(f\"Fitting {name}...\")\n",
    "    model.fit(train_data_para)\n",
    "\n",
    "\n",
    "print(\"Creating DataLoaders for non-parametric deep learning models...\")\n",
    "train_loader_non_para, _, _ = create_dataloaders(\n",
    "    train_data_non_para,\n",
    "    valid_data_non_para,\n",
    "    test_data_non_para,\n",
    "    batch_size=128,\n",
    "    train_seed=seed,\n",
    "    train_initial=None,\n",
    "    valid_initial=None,\n",
    "    test_initial=None\n",
    ")\n",
    "\n",
    "# Initialize non-parametric deep learning models\n",
    "non_parametric_models = {}\n",
    "# non_parametric_models[\"TimeVAE\"] = TimeVAE(\n",
    "#     seq_len=seq_length,\n",
    "#     input_dim=1,\n",
    "#     latent_dim=30,\n",
    "#     hidden_dim=128,\n",
    "#     lr=1e-4,\n",
    "#     device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# )\n",
    "# non_parametric_models[\"QuantGAN\"] = QuantGAN()\n",
    "# non_parametric_models[\"TakahashiDiffusion\"] = TakahashiDiffusion(\n",
    "#     length=None,\n",
    "#     num_channels=1,\n",
    "#     num_steps=100,\n",
    "#     beta_start=0.0001,\n",
    "#     beta_end=0.02,\n",
    "#     wavelet='haar',\n",
    "#     lr=1e-5\n",
    "# )\n",
    "\n",
    "# Fit non-parametric deep learning models\n",
    "print(\"Fitting non-parametric deep learning models...\")\n",
    "for name, model in non_parametric_models.items():\n",
    "    print(f\"Fitting {name}...\")\n",
    "    model.fit(train_loader_non_para, num_epochs=10)\n",
    "\n",
    "# Generate synthetic data (univariate)\n",
    "synthetic_data = {}\n",
    "generation_kwargs = {\"num_samples\": num_samples, \"generation_length\": generation_length, \"seed\": seed}\n",
    "\n",
    "print(\"Generating synthetic data from parametric models...\")\n",
    "for name, model in parametric_models.items():\n",
    "    print(f\"Generating {name}...\")\n",
    "    syn_data = model.generate(**generation_kwargs)\n",
    "    if syn_data.ndim == 3:\n",
    "        syn_data = syn_data[:, :, 0]\n",
    "    synthetic_data[name] = syn_data\n",
    "\n",
    "print(\"Generating synthetic data from non-parametric deep learning models...\")\n",
    "for name, model in non_parametric_models.items():\n",
    "    print(f\"Generating {name}...\")\n",
    "    syn_data = model.generate(**generation_kwargs)\n",
    "    if syn_data.ndim == 3:\n",
    "        syn_data = syn_data[:, :, 0]\n",
    "    elif syn_data.ndim == 1:\n",
    "        syn_data = syn_data.reshape(-1, generation_length)\n",
    "    synthetic_data[name] = syn_data\n",
    "\n",
    "print(\"Synthetic data generation complete!\")\n",
    "for name, data in synthetic_data.items():\n",
    "    print(f\"{name}: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM splits - Train: torch.Size([8000, 103]), Val: torch.Size([1000, 103]), Test: torch.Size([1000, 103])\n",
      "DEJD splits - Train: torch.Size([8000, 103]), Val: torch.Size([1000, 103]), Test: torch.Size([1000, 103])\n"
     ]
    }
   ],
   "source": [
    "# Split synthetic data into train/val/test\n",
    "def split_data(data, train_ratio=0.8, val_ratio=0.1):\n",
    "    R = data.shape[0]\n",
    "    train_end = int(R * train_ratio)\n",
    "    val_end = int(R * (train_ratio + val_ratio))\n",
    "    return data[:train_end], data[train_end:val_end], data[val_end:]\n",
    "\n",
    "synthetic_splits = {}\n",
    "for name, data in synthetic_data.items():\n",
    "    train, val, test = split_data(data)\n",
    "    synthetic_splits[name] = {\n",
    "        \"train\": train,\n",
    "        \"val\": val,\n",
    "        \"test\": test\n",
    "    }\n",
    "    print(f\"{name} splits - Train: {train.shape}, Val: {val.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluation directory: /Users/eddisonpham/Projects/Unified-benchmark-for-SDGFTS/results/evaluation_20251128_172242\n"
     ]
    }
   ],
   "source": [
    "# Find latest evaluation directory or create new one\n",
    "try:\n",
    "    latest_eval_dir = find_latest_evaluation_folder()\n",
    "    print(f\"Found latest evaluation directory: {latest_eval_dir}\")\n",
    "except FileNotFoundError:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    latest_eval_dir = project_root / \"results\" / f\"evaluation_{timestamp}\"\n",
    "    latest_eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created new evaluation directory: {latest_eval_dir}\")\n",
    "\n",
    "eval_dir = Path(latest_eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AUGMENTED TESTING EVALUATION\n",
      "================================================================================\n",
      "================================================================================\n",
      "Evaluating GBM\n",
      "================================================================================\n",
      "[AugmentedTestingEvaluator] Initialization started...\n",
      "[AugmentedTestingEvaluator] Converting log returns to prices for real training data...\n",
      "[AugmentedTestingEvaluator] Converting log returns to prices for real validation data...\n",
      "[AugmentedTestingEvaluator] Converting log returns to prices for synthetic training data...\n",
      "[AugmentedTestingEvaluator] Initialization complete.\n",
      "Evaluating Feedforward_L-1...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 28.476090\n",
      "Epoch 2/2, Loss: 26.528441\n",
      "Training completed. Final premium: 0.254263\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 56.664745\n",
      "Epoch 2/2, Loss: 45.214780\n",
      "Training completed. Final premium: 0.128314\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating Feedforward_Time...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 26.151184\n",
      "Epoch 2/2, Loss: 17.430227\n",
      "Training completed. Final premium: 0.205697\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 46.380268\n",
      "Epoch 2/2, Loss: 34.111111\n",
      "Training completed. Final premium: 0.121697\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating RNN...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 23.400183\n",
      "Epoch 2/2, Loss: 21.966850\n",
      "Training completed. Final premium: 0.252555\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 48.509978\n",
      "Epoch 2/2, Loss: 43.753622\n",
      "Training completed. Final premium: 0.131646\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating LSTM...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 23.136383\n",
      "Epoch 2/2, Loss: 21.273787\n",
      "Training completed. Final premium: 0.252451\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 49.743199\n",
      "Epoch 2/2, Loss: 43.413692\n",
      "Training completed. Final premium: 0.129127\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating BlackScholes...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Estimated premium: 0.5226\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Estimated premium: 0.5216\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating DeltaGamma...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Estimated premium: 0.3449\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Estimated premium: 0.3442\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating LinearRegression...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "LinearRegression premium set to: 1.5876\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "LinearRegression premium set to: 2.6838\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating XGBoost...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "================================================================================\n",
      "Evaluating DEJD\n",
      "================================================================================\n",
      "[AugmentedTestingEvaluator] Initialization started...\n",
      "[AugmentedTestingEvaluator] Converting log returns to prices for real training data...\n",
      "[AugmentedTestingEvaluator] Converting log returns to prices for real validation data...\n",
      "[AugmentedTestingEvaluator] Converting log returns to prices for synthetic training data...\n",
      "[AugmentedTestingEvaluator] Initialization complete.\n",
      "Evaluating Feedforward_L-1...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 27.453945\n",
      "Epoch 2/2, Loss: 20.683935\n",
      "Training completed. Final premium: 0.216320\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 56.664745\n",
      "Epoch 2/2, Loss: 45.214780\n",
      "Training completed. Final premium: 0.128314\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating Feedforward_Time...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 26.456850\n",
      "Epoch 2/2, Loss: 19.294926\n",
      "Training completed. Final premium: 0.214869\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 46.380268\n",
      "Epoch 2/2, Loss: 34.111111\n",
      "Training completed. Final premium: 0.121697\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating RNN...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 23.686018\n",
      "Epoch 2/2, Loss: 22.137431\n",
      "Training completed. Final premium: 0.254649\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 48.509978\n",
      "Epoch 2/2, Loss: 43.753622\n",
      "Training completed. Final premium: 0.131646\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating LSTM...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Epoch 1/2, Loss: 23.897940\n",
      "Epoch 2/2, Loss: 22.385216\n",
      "Training completed. Final premium: 0.255281\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Epoch 1/2, Loss: 49.743199\n",
      "Epoch 2/2, Loss: 43.413692\n",
      "Training completed. Final premium: 0.129127\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating BlackScholes...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Estimated premium: 0.5515\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Estimated premium: 0.5216\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating DeltaGamma...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "Estimated premium: 0.3454\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "Estimated premium: 0.3442\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating LinearRegression...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "LinearRegression premium set to: 1.5790\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "LinearRegression premium set to: 2.6838\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Evaluating XGBoost...\n",
      "[AugmentedTestingEvaluator] Starting evaluation procedure...\n",
      "[AugmentedTestingEvaluator] Mixing 8981 real and 8981 synthetic training samples (50/50)...\n",
      "[AugmentedTestingEvaluator] Training hedger on mixed (synthetic + real) data...\n",
      "[AugmentedTestingEvaluator] Training hedger on real data only...\n",
      "[AugmentedTestingEvaluator] Evaluating both hedgers on real validation set...\n",
      "[AugmentedTestingEvaluator] Computing metrics for mixed and real-only hedgers...\n",
      "[AugmentedTestingEvaluator] Evaluation complete.\n",
      "Augmented Testing Evaluation Complete!\n"
     ]
    }
   ],
   "source": [
    "# Run Augmented Testing Evaluation for each model\n",
    "print(\"=\"*80)\n",
    "print(\"AUGMENTED TESTING EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "augmented_results = {}\n",
    "\n",
    "# Deep learning hedging models\n",
    "hedger_classes = {\n",
    "    \"Feedforward_L-1\": FeedforwardLayers,\n",
    "    \"Feedforward_Time\": FeedforwardTime,\n",
    "    \"RNN\": RNN,\n",
    "    \"LSTM\": LSTM\n",
    "}\n",
    "\n",
    "# Non-deep learning hedging models\n",
    "hedger_classes.update({\n",
    "    \"BlackScholes\": BlackScholes,\n",
    "    \"DeltaGamma\": DeltaGamma,\n",
    "    \"LinearRegression\": LinearRegression,\n",
    "    \"XGBoost\": XGBoost\n",
    "})\n",
    "\n",
    "for model_name, syn_data in synthetic_data.items():\n",
    "    print(f\"{\"=\"*80}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{\"=\"*80}\")\n",
    "    \n",
    "    evaluator = AugmentedTestingEvaluator(\n",
    "        real_train_log_returns=train_data_non_para,\n",
    "        real_val_log_returns=valid_data_non_para,\n",
    "        real_train_initial=train_init_non_para,\n",
    "        real_val_initial=valid_init_non_para,\n",
    "        synthetic_train_log_returns=syn_data,\n",
    "        seq_length=seq_length,\n",
    "        num_epochs=2,\n",
    "        batch_size=128,\n",
    "        learning_rate=1e-3\n",
    "    )\n",
    "    \n",
    "    model_results = {}\n",
    "    for hedger_name, hedger_class in hedger_classes.items():\n",
    "        print(f\"Evaluating {hedger_name}...\")\n",
    "        results = evaluator.evaluate(hedger_class)\n",
    "        model_results[hedger_name] = results\n",
    "    \n",
    "    augmented_results[model_name] = model_results\n",
    "\n",
    "print(\"Augmented Testing Evaluation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ALGORITHM COMPARISON EVALUATION\n",
      "================================================================================\n",
      "================================================================================\n",
      "Evaluating GBM\n",
      "================================================================================\n",
      "[AlgorithmComparisonEvaluator] Initialization started...\n",
      "Converting log returns to prices for real data...\n",
      "[AlgorithmComparisonEvaluator] Converting log returns to prices for synthetic data...\n",
      "[AlgorithmComparisonEvaluator] Initialization complete.\n",
      "[AlgorithmComparisonEvaluator] Starting evaluation procedure for all hedging models...\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating Feedforward_L-1 ---\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_L-1 on real data...\n",
      "Epoch 1/2, Loss: 56.348771\n",
      "Epoch 2/2, Loss: 52.362722\n",
      "Training completed. Final premium: 0.136745\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_L-1 on synthetic data...\n",
      "Epoch 1/2, Loss: 0.461165\n",
      "Epoch 2/2, Loss: 0.115399\n",
      "Training completed. Final premium: 0.088098\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_L-1 on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_L-1 on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for Feedforward_L-1 on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with Feedforward_L-1 ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating Feedforward_Time ---\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_Time on real data...\n",
      "Epoch 1/2, Loss: 41.758996\n",
      "Epoch 2/2, Loss: 35.527645\n",
      "Training completed. Final premium: 0.124328\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_Time on synthetic data...\n",
      "Epoch 1/2, Loss: 0.328188\n",
      "Epoch 2/2, Loss: 0.111980\n",
      "Training completed. Final premium: 0.100039\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_Time on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_Time on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for Feedforward_Time on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with Feedforward_Time ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating RNN ---\n",
      "[AlgorithmComparisonEvaluator] Training RNN on real data...\n",
      "Epoch 1/2, Loss: 47.778916\n",
      "Epoch 2/2, Loss: 42.343392\n",
      "Training completed. Final premium: 0.129735\n",
      "[AlgorithmComparisonEvaluator] Training RNN on synthetic data...\n",
      "Epoch 1/2, Loss: 0.549884\n",
      "Epoch 2/2, Loss: 0.233865\n",
      "Training completed. Final premium: 0.112146\n",
      "[AlgorithmComparisonEvaluator] Evaluating RNN on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating RNN on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for RNN on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with RNN ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating LSTM ---\n",
      "[AlgorithmComparisonEvaluator] Training LSTM on real data...\n",
      "Epoch 1/2, Loss: 51.071772\n",
      "Epoch 2/2, Loss: 43.506871\n",
      "Training completed. Final premium: 0.127485\n",
      "[AlgorithmComparisonEvaluator] Training LSTM on synthetic data...\n",
      "Epoch 1/2, Loss: 0.368058\n",
      "Epoch 2/2, Loss: 0.236127\n",
      "Training completed. Final premium: 0.116096\n",
      "[AlgorithmComparisonEvaluator] Evaluating LSTM on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating LSTM on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for LSTM on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with LSTM ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating BlackScholes ---\n",
      "[AlgorithmComparisonEvaluator] Training BlackScholes on real data...\n",
      "Estimated premium: 0.5216\n",
      "[AlgorithmComparisonEvaluator] Training BlackScholes on synthetic data...\n",
      "Estimated premium: 0.5235\n",
      "[AlgorithmComparisonEvaluator] Evaluating BlackScholes on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating BlackScholes on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for BlackScholes on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with BlackScholes ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating DeltaGamma ---\n",
      "[AlgorithmComparisonEvaluator] Training DeltaGamma on real data...\n",
      "Estimated premium: 0.3442\n",
      "[AlgorithmComparisonEvaluator] Training DeltaGamma on synthetic data...\n",
      "Estimated premium: 0.3455\n",
      "[AlgorithmComparisonEvaluator] Evaluating DeltaGamma on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating DeltaGamma on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for DeltaGamma on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with DeltaGamma ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating LinearRegression ---\n",
      "[AlgorithmComparisonEvaluator] Training LinearRegression on real data...\n",
      "LinearRegression premium set to: 2.6838\n",
      "[AlgorithmComparisonEvaluator] Training LinearRegression on synthetic data...\n",
      "LinearRegression premium set to: 0.5006\n",
      "[AlgorithmComparisonEvaluator] Evaluating LinearRegression on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating LinearRegression on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for LinearRegression on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with LinearRegression ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating XGBoost ---\n",
      "[AlgorithmComparisonEvaluator] Training XGBoost on real data...\n",
      "[AlgorithmComparisonEvaluator] Training XGBoost on synthetic data...\n",
      "[AlgorithmComparisonEvaluator] Evaluating XGBoost on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating XGBoost on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for XGBoost on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with XGBoost ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] Evaluation of all hedgers complete.\n",
      "================================================================================\n",
      "Evaluating DEJD\n",
      "================================================================================\n",
      "[AlgorithmComparisonEvaluator] Initialization started...\n",
      "Converting log returns to prices for real data...\n",
      "[AlgorithmComparisonEvaluator] Converting log returns to prices for synthetic data...\n",
      "[AlgorithmComparisonEvaluator] Initialization complete.\n",
      "[AlgorithmComparisonEvaluator] Starting evaluation procedure for all hedging models...\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating Feedforward_L-1 ---\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_L-1 on real data...\n",
      "Epoch 1/2, Loss: 56.490913\n",
      "Epoch 2/2, Loss: 54.512914\n",
      "Training completed. Final premium: 0.139504\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_L-1 on synthetic data...\n",
      "Epoch 1/2, Loss: 0.855244\n",
      "Epoch 2/2, Loss: 0.259116\n",
      "Training completed. Final premium: 0.086196\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_L-1 on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_L-1 on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for Feedforward_L-1 on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with Feedforward_L-1 ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating Feedforward_Time ---\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_Time on real data...\n",
      "Epoch 1/2, Loss: 41.758996\n",
      "Epoch 2/2, Loss: 35.527645\n",
      "Training completed. Final premium: 0.124328\n",
      "[AlgorithmComparisonEvaluator] Training Feedforward_Time on synthetic data...\n",
      "Epoch 1/2, Loss: 0.714136\n",
      "Epoch 2/2, Loss: 0.158278\n",
      "Training completed. Final premium: 0.082814\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_Time on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating Feedforward_Time on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for Feedforward_Time on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with Feedforward_Time ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating RNN ---\n",
      "[AlgorithmComparisonEvaluator] Training RNN on real data...\n",
      "Epoch 1/2, Loss: 47.778916\n",
      "Epoch 2/2, Loss: 42.343392\n",
      "Training completed. Final premium: 0.129735\n",
      "[AlgorithmComparisonEvaluator] Training RNN on synthetic data...\n",
      "Epoch 1/2, Loss: 0.766533\n",
      "Epoch 2/2, Loss: 0.264701\n",
      "Training completed. Final premium: 0.096337\n",
      "[AlgorithmComparisonEvaluator] Evaluating RNN on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating RNN on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for RNN on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with RNN ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating LSTM ---\n",
      "[AlgorithmComparisonEvaluator] Training LSTM on real data...\n",
      "Epoch 1/2, Loss: 51.071772\n",
      "Epoch 2/2, Loss: 43.506871\n",
      "Training completed. Final premium: 0.127485\n",
      "[AlgorithmComparisonEvaluator] Training LSTM on synthetic data...\n",
      "Epoch 1/2, Loss: 0.432521\n",
      "Epoch 2/2, Loss: 0.259855\n",
      "Training completed. Final premium: 0.107434\n",
      "[AlgorithmComparisonEvaluator] Evaluating LSTM on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating LSTM on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for LSTM on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with LSTM ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating BlackScholes ---\n",
      "[AlgorithmComparisonEvaluator] Training BlackScholes on real data...\n",
      "Estimated premium: 0.5216\n",
      "[AlgorithmComparisonEvaluator] Training BlackScholes on synthetic data...\n",
      "Estimated premium: 0.5804\n",
      "[AlgorithmComparisonEvaluator] Evaluating BlackScholes on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating BlackScholes on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for BlackScholes on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with BlackScholes ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating DeltaGamma ---\n",
      "[AlgorithmComparisonEvaluator] Training DeltaGamma on real data...\n",
      "Estimated premium: 0.3442\n",
      "[AlgorithmComparisonEvaluator] Training DeltaGamma on synthetic data...\n",
      "Estimated premium: 0.3459\n",
      "[AlgorithmComparisonEvaluator] Evaluating DeltaGamma on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating DeltaGamma on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for DeltaGamma on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with DeltaGamma ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating LinearRegression ---\n",
      "[AlgorithmComparisonEvaluator] Training LinearRegression on real data...\n",
      "LinearRegression premium set to: 2.6838\n",
      "[AlgorithmComparisonEvaluator] Training LinearRegression on synthetic data...\n",
      "LinearRegression premium set to: 0.4707\n",
      "[AlgorithmComparisonEvaluator] Evaluating LinearRegression on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating LinearRegression on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for LinearRegression on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with LinearRegression ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] --- Evaluating XGBoost ---\n",
      "[AlgorithmComparisonEvaluator] Training XGBoost on real data...\n",
      "[AlgorithmComparisonEvaluator] Training XGBoost on synthetic data...\n",
      "[AlgorithmComparisonEvaluator] Evaluating XGBoost on real test set...\n",
      "[AlgorithmComparisonEvaluator] Evaluating XGBoost on synthetic test set...\n",
      "[AlgorithmComparisonEvaluator] Computing metrics for XGBoost on real and synthetic test sets...\n",
      "[AlgorithmComparisonEvaluator] --- Done with XGBoost ---\n",
      "\n",
      "[AlgorithmComparisonEvaluator] Evaluation of all hedgers complete.\n",
      "Algorithm Comparison Evaluation Complete!\n"
     ]
    }
   ],
   "source": [
    "# Run Algorithm Comparison Evaluation for each model\n",
    "print(\"=\"*80)\n",
    "print(\"ALGORITHM COMPARISON EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "algorithm_comparison_results = {}\n",
    "\n",
    "for model_name, splits in synthetic_splits.items():\n",
    "    print(f\"{\"=\"*80}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{\"=\"*80}\")\n",
    "    \n",
    "    evaluator = AlgorithmComparisonEvaluator(\n",
    "        real_train_log_returns=train_data_non_para,\n",
    "        real_val_log_returns=valid_data_non_para,\n",
    "        real_test_log_returns=test_data_non_para,\n",
    "        synthetic_train_log_returns=splits[\"train\"],\n",
    "        synthetic_val_log_returns=splits[\"val\"],\n",
    "        synthetic_test_log_returns=splits[\"test\"],\n",
    "        real_train_initial=train_init_non_para,\n",
    "        real_val_initial=valid_init_non_para,\n",
    "        real_test_initial=test_init_non_para,\n",
    "        seq_length=seq_length,\n",
    "        num_epochs=2,\n",
    "        batch_size=128,\n",
    "        learning_rate=1e-3\n",
    "    )\n",
    "    \n",
    "    results = evaluator.evaluate()\n",
    "    algorithm_comparison_results[model_name] = results\n",
    "\n",
    "print(\"Algorithm Comparison Evaluation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: /Users/eddisonpham/Projects/Unified-benchmark-for-SDGFTS/results/evaluation_20251128_172242/deep_hedging_utility_results.json\n",
      "All results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save all results to evaluation directory\n",
    "all_results = {\n",
    "    \"augmented_testing\": augmented_results,\n",
    "    \"algorithm_comparison\": algorithm_comparison_results,\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"config\": {\n",
    "        \"seq_length\": seq_length,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"original_data_path\": str(original_data_path),\n",
    "        \"hedger_classes\": list(hedger_classes.keys())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_file = eval_dir / \"deep_hedging_utility_results.json\"\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(all_results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")\n",
    "\n",
    "# Also save individual model results\n",
    "for model_name in synthetic_data.keys():\n",
    "    model_dir = eval_dir / model_name\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    model_results = {\n",
    "        \"augmented_testing\": augmented_results.get(model_name, {}),\n",
    "        \"algorithm_comparison\": algorithm_comparison_results.get(model_name, {})\n",
    "    }\n",
    "    \n",
    "    model_file = model_dir / \"utility_results.json\"\n",
    "    with open(model_file, \"w\") as f:\n",
    "        json.dump(model_results, f, indent=2, default=str)\n",
    "\n",
    "print(\"All results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
