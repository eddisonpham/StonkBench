{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Preprocessor Verification\n",
        "\n",
        "This notebook verifies that the modified preprocessing pipeline with PyTorch Dataset support creates the correct data structures and handles batching properly with seed support.\n",
        "\n",
        "## Key Features to Verify:\n",
        "- Time series data shape `(R, l, N)` where R=sequences, l=length, N=variables\n",
        "- Seed-based reproducible shuffling\n",
        "- Proper PyTorch Dataset implementation\n",
        "- Efficient DataLoader batching\n",
        "- Dynamic seed changing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current path: c:\\Users\\14165\\Downloads\\Unified-benchmark-for-SDGFTS-main\n",
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "print(f\"Current path: {PROJECT_ROOT}\")\n",
        "\n",
        "from data.preprocess import (\n",
        "    preprocess_data, \n",
        "    load_preprocessed_data,\n",
        "    create_dataset_from_preprocessed,\n",
        ")\n",
        "\n",
        "from utils.preprocess_utils import (\n",
        "    TimeSeriesDataset,\n",
        "    create_dataloaders\n",
        ")\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Basic Preprocessing with Seed Support\n",
        "\n",
        "### Testing: \n",
        "- GOOG: `data/GOOG/GOOG.csv`\n",
        "- mvt-ts: `data/mvt-ts-data/exchange_rate.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# INSERT_YOUR_CODE\n",
        "\n",
        "def run_basic_preprocessing_example(train_data, valid_data):\n",
        "    \"\"\"\n",
        "    Run Example 1: Basic Preprocessing with Seed Support.\n",
        "    This function sets up the configuration, runs preprocessing, and prints summary statistics.\n",
        "    \"\"\"\n",
        "    if train_data is not None and valid_data is not None:\n",
        "        print(f\"\\nPreprocessing successful!\")\n",
        "        print(f\"Data shapes:\")\n",
        "        print(f\"  Train shape: {train_data.shape} (R_train, l, N)\")\n",
        "        print(f\"  Valid shape: {valid_data.shape} (R_valid, l, N)\")\n",
        "        print(f\"  Sequence length (l): {train_data.shape[1]}\")\n",
        "        print(f\"  Number of variables (N): {train_data.shape[2]}\")\n",
        "        print(f\"  Total sequences (R): {train_data.shape[0] + valid_data.shape[0]}\")\n",
        "        \n",
        "        print(f\"\\nData statistics:\")\n",
        "        print(f\"  Train data range: [{train_data.min():.4f}, {train_data.max():.4f}]\")\n",
        "        print(f\"  Valid data range: [{valid_data.min():.4f}, {valid_data.max():.4f}]\")\n",
        "        print(f\"  Train data mean: {train_data.mean():.4f}\")\n",
        "        print(f\"  Valid data mean: {valid_data.mean():.4f}\")\n",
        "        \n",
        "        # Verify normalization (should be in range [0, 1])\n",
        "        if train_data.min() >= 0 and train_data.max() <= 1:\n",
        "            print(f\"  Normalization successful: data in range [0, 1]\")\n",
        "        else:\n",
        "            print(f\"  Normalization issue: data outside [0, 1] range\")\n",
        "            \n",
        "    else:\n",
        "        print(\"Preprocessing failed...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "EXAMPLE 1: Basic Preprocessing with Seed Support\n",
            "============================================================\n",
            "Configuration GOOG Dataset: {'original_data_path': 'GOOG/GOOG.csv', 'output_ori_path': './preprocessed/', 'dataset_name': 'goog_stock', 'valid_ratio': 0.1, 'do_normalization': True, 'seed': 42}\n",
            "\n",
            "Starting preprocessing...\n",
            "====================\n",
            "Data preprocessing with settings:{'original_data_path': 'GOOG/GOOG.csv', 'output_ori_path': './preprocessed/', 'dataset_name': 'goog_stock', 'valid_ratio': 0.1, 'do_normalization': True, 'seed': 42}\n",
            "Data shape: (1132, 125, 5)\n",
            "Preprocessing done. Preprocessed files saved to ./preprocessed/goog_stock.\n",
            "====================\n",
            "\n",
            "Configuration MVT TS Dataset: {'original_data_path': 'GOOG/GOOG.csv', 'output_ori_path': './preprocessed/', 'dataset_name': 'goog_stock', 'valid_ratio': 0.1, 'do_normalization': True, 'seed': 42}\n",
            "\n",
            "Starting preprocessing...\n",
            "====================\n",
            "Data preprocessing with settings:{'original_data_path': 'mvt-ts-data/exchange_rate.txt', 'output_ori_path': './preprocessed/', 'dataset_name': 'mvt_ts', 'valid_ratio': 0.1, 'do_normalization': True, 'seed': 42}\n",
            "Data shape: (7464, 125, 8)\n",
            "Preprocessing done. Preprocessed files saved to ./preprocessed/mvt_ts.\n",
            "====================\n",
            "\n",
            "\n",
            "Preprocessing successful!\n",
            "Data shapes:\n",
            "  Train shape: (1018, 125, 5) (R_train, l, N)\n",
            "  Valid shape: (114, 125, 5) (R_valid, l, N)\n",
            "  Sequence length (l): 125\n",
            "  Number of variables (N): 5\n",
            "  Total sequences (R): 1132\n",
            "\n",
            "Data statistics:\n",
            "  Train data range: [0.0000, 1.0000]\n",
            "  Valid data range: [-0.0265, 1.2043]\n",
            "  Train data mean: 0.3676\n",
            "  Valid data mean: 0.3695\n",
            "  Normalization successful: data in range [0, 1]\n",
            "\n",
            "Preprocessing successful!\n",
            "Data shapes:\n",
            "  Train shape: (6717, 125, 8) (R_train, l, N)\n",
            "  Valid shape: (747, 125, 8) (R_valid, l, N)\n",
            "  Sequence length (l): 125\n",
            "  Number of variables (N): 8\n",
            "  Total sequences (R): 7464\n",
            "\n",
            "Data statistics:\n",
            "  Train data range: [0.0000, 1.0000]\n",
            "  Valid data range: [-0.0528, 1.2755]\n",
            "  Train data mean: 0.4286\n",
            "  Valid data mean: 0.4245\n",
            "  Normalization successful: data in range [0, 1]\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"EXAMPLE 1: Basic Preprocessing with Seed Support\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "\n",
        "config_goog = {\n",
        "    'original_data_path': 'GOOG/GOOG.csv',\n",
        "    'output_ori_path': './preprocessed/',\n",
        "    'dataset_name': 'goog_stock',\n",
        "    'valid_ratio': 0.1,\n",
        "    'do_normalization': True,\n",
        "    'seed': 42  # Reproducible shuffling\n",
        "}\n",
        "\n",
        "config_mvt = {\n",
        "    'original_data_path': 'mvt-ts-data/exchange_rate.txt',\n",
        "    'output_ori_path': './preprocessed/',\n",
        "    'dataset_name': 'mvt_ts',\n",
        "    'valid_ratio': 0.1,\n",
        "    'do_normalization': True,\n",
        "    'seed': 42  # Reproducible shuffling\n",
        "}\n",
        "\n",
        "print(f\"Configuration GOOG Dataset: {config_goog}\")\n",
        "print(\"\\nStarting preprocessing...\")\n",
        "train_data_goog, valid_data_goog = preprocess_data(config_goog)\n",
        "\n",
        "print(f\"Configuration MVT TS Dataset: {config_goog}\")\n",
        "print(\"\\nStarting preprocessing...\")\n",
        "train_data_mvt, valid_data_mvt = preprocess_data(config_mvt)\n",
        "\n",
        "run_basic_preprocessing_example(train_data_goog, valid_data_goog)\n",
        "run_basic_preprocessing_example(train_data_mvt, valid_data_mvt)\n",
        "\n",
        "# Reset each train/valid to None\n",
        "# train_data_goog = None\n",
        "# valid_data_goog = None\n",
        "# train_data_mvt = None\n",
        "# valid_data_mvt = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: PyTorch Dataset and DataLoader Creation\n",
        "\n",
        "Now let's create PyTorch datasets and dataloaders to verify proper batching and seed support.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXAMPLE 2: PyTorch Dataset and DataLoader Creation\n",
            "============================================================\n",
            "Creating TimeSeriesDataset objects...\n",
            "Created datasets:\n",
            "  Train dataset length: 1018\n",
            "  Valid dataset length: 114\n",
            "  Sample shape: torch.Size([125, 5])\n",
            "  Sample dtype: torch.float32\n",
            "  Sample is PyTorch tensor: <class 'torch.Tensor'>\n",
            "\n",
            "Creating DataLoaders...\n",
            "Created dataloaders:\n",
            "  Train batches: 32\n",
            "  Valid batches: 4\n",
            "  Batch size: 32\n",
            "\n",
            "Batch Information:\n",
            "Batch 1: shape torch.Size([32, 125, 5]), dtype torch.float32\n",
            "  Range: [0.0000, 1.0000]\n",
            "Batch 2: shape torch.Size([32, 125, 5]), dtype torch.float32\n",
            "  Range: [0.0000, 1.0000]\n",
            "Batch 3: shape torch.Size([32, 125, 5]), dtype torch.float32\n",
            "  Range: [0.0000, 1.0000]\n",
            "... and 29 more batches\n",
            "\n",
            "Batch shapes are correct: torch.Size([32, 125, 5]) == (32, 125, 5)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXAMPLE 2: PyTorch Dataset and DataLoader Creation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if train_data_goog is None or valid_data_goog is None:\n",
        "    print(\"Cannot proceed - no preprocessed data available\")\n",
        "else:\n",
        "    # Create datasets with different seeds for reproducible shuffling\n",
        "    print(\"Creating TimeSeriesDataset objects...\")\n",
        "    train_dataset = TimeSeriesDataset(train_data_goog, seed=42)\n",
        "    valid_dataset = TimeSeriesDataset(valid_data_goog, seed=123)\n",
        "    \n",
        "    print(f\"Created datasets:\")\n",
        "    print(f\"  Train dataset length: {len(train_dataset)}\")\n",
        "    print(f\"  Valid dataset length: {len(valid_dataset)}\")\n",
        "    print(f\"  Sample shape: {train_dataset[0].shape}\")\n",
        "    print(f\"  Sample dtype: {train_dataset[0].dtype}\")\n",
        "    \n",
        "    # Verify the sample is a PyTorch tensor\n",
        "    sample = train_dataset[0]\n",
        "    if isinstance(sample, torch.Tensor):\n",
        "        print(f\"  Sample is PyTorch tensor: {type(sample)}\")\n",
        "    else:\n",
        "        print(f\"  Sample is not PyTorch tensor: {type(sample)}\")\n",
        "    \n",
        "    # Create dataloaders\n",
        "    print(f\"\\nCreating DataLoaders...\")\n",
        "    batch_size = 32\n",
        "    train_loader, valid_loader = create_dataloaders(\n",
        "        train_data_goog, valid_data_goog,\n",
        "        batch_size=batch_size,\n",
        "        train_seed=42,\n",
        "        valid_seed=123,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    \n",
        "    print(f\"Created dataloaders:\")\n",
        "    print(f\"  Train batches: {len(train_loader)}\")\n",
        "    print(f\"  Valid batches: {len(valid_loader)}\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    \n",
        "    # Demonstrate batching\n",
        "    print(f\"\\nBatch Information:\")\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        print(f\"Batch {i+1}: shape {batch.shape}, dtype {batch.dtype}\")\n",
        "        print(f\"  Range: [{batch.min():.4f}, {batch.max():.4f}]\")\n",
        "        if i >= 2:  # Show only first 3 batches\n",
        "            print(f\"... and {len(train_loader) - 3} more batches\")\n",
        "            break\n",
        "    \n",
        "    # Verify batch shapes are correct\n",
        "    first_batch = next(iter(train_loader))\n",
        "    expected_shape = (batch_size, train_data_goog.shape[1], train_data_goog.shape[2])\n",
        "    if first_batch.shape == expected_shape:\n",
        "        print(f\"\\nBatch shapes are correct: {first_batch.shape} == {expected_shape}\")\n",
        "    else:\n",
        "        print(f\"\\nBatch shape mismatch: {first_batch.shape} != {expected_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Reproducible Training with Seed Control\n",
        "\n",
        "Let's verify that seeds produce reproducible and different shuffling patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXAMPLE 3: Reproducible Training with Seed Control\n",
            "============================================================\n",
            "Testing reproducibility with same seeds...\n",
            "Datasets with same seed produce identical order: True\n",
            "  First 10 indices (dataset1): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "  First 10 indices (dataset2): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "\n",
            "Testing different seeds produce different orders...\n",
            "Datasets with different seeds produce different order: True\n",
            "  First 10 indices (seed=42): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "  First 10 indices (seed=123): [936, 244, 526, 469, 573, 712, 847, 257, 635, 672]\n",
            "\n",
            "Testing dynamic seed changing...\n",
            "Seed change produces different order: True\n",
            "  Original (seed=42): [272, 859, 927, 365, 1014, 290, 790, 211, 946, 894]\n",
            "  New (seed=999):     [700, 859, 964, 373, 390, 946, 156, 416, 352, 107]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXAMPLE 3: Reproducible Training with Seed Control\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if train_data_goog is None:\n",
        "    print(\"Cannot proceed - no preprocessed data available\")\n",
        "else:\n",
        "    # Test reproducibility with same seeds\n",
        "    print(\"Testing reproducibility with same seeds...\")\n",
        "    dataset1 = TimeSeriesDataset(train_data_goog, seed=42)\n",
        "    dataset2 = TimeSeriesDataset(train_data_goog, seed=42)\n",
        "    \n",
        "    # Check if the order is identical\n",
        "    indices1 = dataset1.get_original_indices()\n",
        "    indices2 = dataset2.get_original_indices()\n",
        "    \n",
        "    print(f\"Datasets with same seed produce identical order: {indices1[:10] == indices2[:10]}\")\n",
        "    print(f\"  First 10 indices (dataset1): {indices1[:10]}\")\n",
        "    print(f\"  First 10 indices (dataset2): {indices2[:10]}\")\n",
        "    \n",
        "    # Test different seeds produce different orders\n",
        "    print(f\"\\nTesting different seeds produce different orders...\")\n",
        "    dataset3 = TimeSeriesDataset(train_data_goog, seed=123)\n",
        "    indices3 = dataset3.get_original_indices()\n",
        "    \n",
        "    print(f\"Datasets with different seeds produce different order: {indices1[:10] != indices3[:10]}\")\n",
        "    print(f\"  First 10 indices (seed=42): {indices1[:10]}\")\n",
        "    print(f\"  First 10 indices (seed=123): {indices3[:10]}\")\n",
        "    \n",
        "    # Test dynamic seed changing\n",
        "    print(f\"\\nTesting dynamic seed changing...\")\n",
        "    original_indices = dataset1.get_original_indices()[:10]\n",
        "    dataset1.set_seed(999)\n",
        "    new_indices = dataset1.get_original_indices()[:10]\n",
        "    \n",
        "    print(f\"Seed change produces different order: {original_indices != new_indices}\")\n",
        "    print(f\"  Original (seed=42): {original_indices}\")\n",
        "    print(f\"  New (seed=999):     {new_indices}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
